{
  "master": {
    "tasks": [
      {
        "id": 19,
        "title": "ê°œë°œ í™˜ê²½ ì„¤ì • ë° í”„ë¡œì íŠ¸ êµ¬ì¡°í™”",
        "description": "Python 3.11+ ê°€ìƒí™˜ê²½ ì„¤ì •, í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜, í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„ ë° Git ì €ì¥ì†Œ ì´ˆê¸°í™”",
        "details": "1. Python 3.11+ ì„¤ì¹˜ í™•ì¸ ë° ê°€ìƒí™˜ê²½ ìƒì„±: `python -m venv venv`\n2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pandas 2.1+, numpy 1.24+, TA-Lib 0.4.28+, websockets 11.0+, sqlalchemy 2.0+, fastapi 0.104+, uvicorn 0.23+, psycopg2-binary 2.9.9+, redis 5.0+\n3. requirements.txt ìƒì„±\n4. í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„:\n```\nqb/\n  â”œâ”€â”€ api/            # FastAPI ì„œë²„\n  â”œâ”€â”€ collectors/     # ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ\n  â”œâ”€â”€ database/       # DB ëª¨ë¸ ë° ì—°ê²°\n  â”œâ”€â”€ strategies/     # íŠ¸ë ˆì´ë”© ì „ëµ\n  â”œâ”€â”€ backtesting/    # ë°±í…ŒìŠ¤íŒ… ì—”ì§„\n  â”œâ”€â”€ risk/           # ë¦¬ìŠ¤í¬ ê´€ë¦¬\n  â”œâ”€â”€ orders/         # ì£¼ë¬¸ ê´€ë¦¬\n  â”œâ”€â”€ utils/          # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n  â”œâ”€â”€ config/         # ì„¤ì • íŒŒì¼\n  â””â”€â”€ tests/          # í…ŒìŠ¤íŠ¸ ì½”ë“œ\n```\n5. Git ì €ì¥ì†Œ ì´ˆê¸°í™”: `git init`\n6. .gitignore íŒŒì¼ ìƒì„± (API í‚¤, í™˜ê²½ ë³€ìˆ˜, ê°€ìƒí™˜ê²½ ë“± ì œì™¸)\n7. í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ë¥¼ ìœ„í•œ python-dotenv ì„¤ì •\n8. ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì„±: loguru ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n<info added on 2025-07-25T05:53:53.475Z>\n9. ì½”ë”© ê·œì¹™ ì„¤ì •:\n   - QB Trading System ì „ìš© ì½”ë”© ê·œì¹™ íŒŒì¼ ìƒì„± (.cursor/rules/qb_trading_rules.mdc)\n   - ê¸°ë³¸ ì„¤ê³„ ì›ì¹™: KISS, YAGNI, DRY ì ìš©\n   - ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ê·œì¹™ (Redis Pub/Sub) ì •ì˜\n   - ê¸ˆìœµ ë°ì´í„° ì²˜ë¦¬ í‘œì¤€í™” (Decimal íƒ€ì…, UTC ì‹œê°„)\n   - ì•ˆì „ì„± ë° ì‹ ë¢°ì„± í™•ë³´ (ì—ëŸ¬ ì²˜ë¦¬, ë¡œê¹… í‘œì¤€)\n   - ë³´ì•ˆ ê´€ë ¨ ê·œì¹™ (API í‚¤ ê´€ë¦¬, ì…ë ¥ ê²€ì¦)\n   - í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œë¼ì¸\n   - ì½”ë“œ êµ¬ì¡° ë° ë„¤ì´ë° ì»¨ë²¤ì…˜ í‘œì¤€í™”\n</info added on 2025-07-25T05:53:53.475Z>",
        "testStrategy": "1. ê°€ìƒí™˜ê²½ í™œì„±í™” ë° ì˜ì¡´ì„± ì„¤ì¹˜ í…ŒìŠ¤íŠ¸\n2. ê° ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸\n3. í”„ë¡œì íŠ¸ êµ¬ì¡° ê²€ì¦\n4. Git ì €ì¥ì†Œ ì´ˆê¸° ì»¤ë°‹ ë° í‘¸ì‹œ í…ŒìŠ¤íŠ¸\n5. ë¡œê¹… ì‹œìŠ¤í…œ ì‘ë™ í™•ì¸",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "PostgreSQL ë° TimescaleDB ì„¤ì •",
        "description": "ì‹œê³„ì—´ ë°ì´í„° ìµœì í™”ë¥¼ ìœ„í•œ PostgreSQL ë° TimescaleDB ì„¤ì¹˜, ì„¤ì • ë° ìŠ¤í‚¤ë§ˆ êµ¬í˜„",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "medium",
        "details": "1. PostgreSQL 15+ ì„¤ì¹˜ ë° ì„¤ì •\n2. TimescaleDB 2.11+ í™•ì¥ ì„¤ì¹˜\n3. ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±: `CREATE DATABASE qb_trading;`\n4. TimescaleDB í™•ì¥ í™œì„±í™”: `CREATE EXTENSION IF NOT EXISTS timescaledb;`\n5. ìŠ¤í‚¤ë§ˆ êµ¬í˜„:\n   - PRDì— ëª…ì‹œëœ stock_prices í…Œì´ë¸” ìƒì„±\n   - trades í…Œì´ë¸” ìƒì„±\n   - strategy_performance í…Œì´ë¸” ìƒì„±\n   - ì¶”ê°€ í•„ìš” í…Œì´ë¸”: stocks_metadata, risk_metrics, system_logs\n6. í•˜ì´í¼í…Œì´ë¸” ì„¤ì • ë° ì••ì¶• ì •ì±… êµ¬ì„±:\n```sql\nSELECT create_hypertable('stock_prices', 'time');\nALTER TABLE stock_prices SET (timescaledb.compress, timescaledb.compress_segmentby = 'symbol');\nSELECT add_compression_policy('stock_prices', INTERVAL '7 days');\n```\n7. ì¸ë±ìŠ¤ ìƒì„±:\n```sql\nCREATE INDEX idx_stock_prices_symbol ON stock_prices(symbol, time DESC);\nCREATE INDEX idx_trades_symbol ON trades(symbol, timestamp DESC);\n```\n8. ë°±ì—… ì •ì±… ì„¤ì •\n9. SQLAlchemy ORM ëª¨ë¸ êµ¬í˜„ (database/models.py)\n10. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„ (database/connection.py)\n\n**ê°œë°œ ìˆœì„œ ì°¸ê³ :**\n1. ìš°ì„  Redis + ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ë¡œ íŠ¸ë ˆì´ë”© ì‹œì‘\n2. ì‹œìŠ¤í…œ ì•ˆì •í™” í›„ PostgreSQL ì¶”ê°€í•˜ì—¬ ë°ì´í„° ì˜ì†ì„± í™•ë³´",
        "testStrategy": "1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸\n2. í…Œì´ë¸” ìƒì„± ë° ìŠ¤í‚¤ë§ˆ ê²€ì¦\n3. ìƒ˜í”Œ ë°ì´í„° ì‚½ì… ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n4. í•˜ì´í¼í…Œì´ë¸” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‹œê³„ì—´ ì¿¼ë¦¬ ì„±ëŠ¥)\n5. ì••ì¶• ì •ì±… í…ŒìŠ¤íŠ¸\n6. SQLAlchemy ORM ëª¨ë¸ CRUD í…ŒìŠ¤íŠ¸\n7. ë°±ì—… ë° ë³µì› í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Redis ìºì‹œ ì„¤ì • ë° ì‹¤ì‹œê°„ ë°ì´í„° ë²„í¼ë§",
        "description": "ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ Redis ìºì‹œ ì„¤ì • ë° ë°ì´í„° ë²„í¼ë§ ì‹œìŠ¤í…œ êµ¬í˜„, ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ ë° ìº”ë“¤/ì§€í‘œ ë°ì´í„° ê´€ë¦¬ í¬í•¨",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "high",
        "details": "1. Redis 7.0+ ì„¤ì¹˜ ë° ì„¤ì •\n2. Python redis-py í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n3. ì‹¤ì‹œê°„ ë°ì´í„° ë²„í¼ë§ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ì„¤ê³„:\n   - market:SYMBOL (Hash) - ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°\n   - candles:SYMBOL:1m (List) - ìµœê·¼ 200ê°œ ìº”ë“¤\n   - indicators:SYMBOL (Hash) - ê¸°ìˆ ì  ì§€í‘œ ìºì‹œ\n   - ì‹¤ì‹œê°„ í˜¸ê°€ ë°ì´í„°: Sorted Set êµ¬ì¡°\n   - ìµœê·¼ ì²´ê²° ë‚´ì—­: List êµ¬ì¡° (ì œí•œëœ ê¸¸ì´)\n4. ë°ì´í„° ë§Œë£Œ ì •ì±… ì„¤ì • (TTL)\n5. Redis Pub/Sub ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„:\n   - market_data_received: ì‹œì¥ ë°ì´í„° ìˆ˜ì‹  ì´ë²¤íŠ¸\n   - trading_signal: íŠ¸ë ˆì´ë”© ì‹ í˜¸ ì´ë²¤íŠ¸\n   - order_executed: ì£¼ë¬¸ ì‹¤í–‰ ì´ë²¤íŠ¸\n   - risk_alert: ë¦¬ìŠ¤í¬ ì•Œë¦¼ ì´ë²¤íŠ¸\n6. Redis ì—°ê²° í’€ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„ (utils/redis_manager.py):\n```python\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0):\n        self.pool = redis.ConnectionPool(host=host, port=port, db=db)\n        self.redis = redis.Redis(connection_pool=self.pool)\n        \n    def set_market_data(self, symbol, market_data):\n        # ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ì €ì¥ ë¡œì§\n        self.redis.hset(f\"market:{symbol}\", mapping=market_data)\n        self.redis.expire(f\"market:{symbol}\", 86400)  # 1ì¼ í›„ ë§Œë£Œ\n        \n    def get_market_data(self, symbol):\n        return self.redis.hgetall(f\"market:{symbol}\")\n        \n    def add_candle(self, symbol, timeframe, candle_data):\n        # ìº”ë“¤ ë°ì´í„° ì¶”ê°€ (ìµœëŒ€ 200ê°œ ìœ ì§€)\n        key = f\"candles:{symbol}:{timeframe}\"\n        self.redis.lpush(key, json.dumps(candle_data))\n        self.redis.ltrim(key, 0, 199)  # ìµœê·¼ 200ê°œë§Œ ìœ ì§€\n        \n    def cache_indicator(self, symbol, indicator_name, value):\n        # ê¸°ìˆ ì  ì§€í‘œ ìºì‹±\n        self.redis.hset(f\"indicators:{symbol}\", indicator_name, json.dumps(value))\n        \n    def publish_event(self, channel, message):\n        # ì´ë²¤íŠ¸ ë°œí–‰\n        self.redis.publish(channel, json.dumps(message))\n```\n7. ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ êµ¬í˜„ (JSON ë˜ëŠ” MessagePack)\n8. Redis ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ í™•ì¸ ê¸°ëŠ¥ êµ¬í˜„\n9. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” (20-25MB ëª©í‘œ):\n   - ë°ì´í„° ì••ì¶• ê¸°ë²• ì ìš©\n   - ë¶ˆí•„ìš”í•œ ë°ì´í„° ìë™ ì œê±° ì •ì±… ì„¤ì •\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë„êµ¬ êµ¬í˜„",
        "testStrategy": "1. Redis ì—°ê²° ë° ê¸°ë³¸ ì‘ë™ í…ŒìŠ¤íŠ¸\n2. ë°ì´í„° êµ¬ì¡°ë³„ CRUD ì‘ì—… í…ŒìŠ¤íŠ¸\n3. Pub/Sub ì±„ë„ ë©”ì‹œì§€ ì „ì†¡ ë° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸\n4. ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n5. ì—°ê²° í’€ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n6. ì§ë ¬í™”/ì—­ì§ë ¬í™” ì •í™•ì„± í…ŒìŠ¤íŠ¸\n7. TTL ì •ì±… ì‘ë™ í™•ì¸\n8. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ (20-25MB ëª©í‘œ ë‹¬ì„± í™•ì¸)\n9. ìº”ë“¤ ë°ì´í„° ê´€ë¦¬ í…ŒìŠ¤íŠ¸ (200ê°œ ì œí•œ í™•ì¸)\n10. ê¸°ìˆ ì  ì§€í‘œ ìºì‹± ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n11. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "Redis ì„¤ì¹˜ ë° ê¸°ë³¸ ì—°ê²° ì„¤ì •",
            "description": "Redis 7.0+ ì„¤ì¹˜ ë° Python redis-py í´ë¼ì´ì–¸íŠ¸ ì„¤ì •, ê¸°ë³¸ ì—°ê²° í’€ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„",
            "dependencies": [],
            "details": "1. Redis 7.0+ ì„¤ì¹˜ ë° ê¸°ë³¸ ì„¤ì •:\n   - Linux: `sudo apt install redis-server`\n   - macOS: `brew install redis`\n   - ì„¤ì • íŒŒì¼ ìˆ˜ì •: `/etc/redis/redis.conf`\n     - ë©”ëª¨ë¦¬ ì œí•œ: `maxmemory 25mb`\n     - ë©”ëª¨ë¦¬ ì •ì±…: `maxmemory-policy allkeys-lru`\n\n2. Python redis-py í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜:\n   - `pip install redis==5.0.0`\n\n3. utils/redis_manager.py íŒŒì¼ ìƒì„± ë° ê¸°ë³¸ ì—°ê²° í’€ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„:\n```python\nimport redis\nimport json\nimport logging\nfrom typing import Dict, Any, List, Optional\n\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0, password=None):\n        self.logger = logging.getLogger(__name__)\n        self.pool = redis.ConnectionPool(\n            host=host, \n            port=port, \n            db=db,\n            password=password,\n            decode_responses=True  # ìë™ìœ¼ë¡œ ë°”ì´íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë””ì½”ë”©\n        )\n        self.redis = redis.Redis(connection_pool=self.pool)\n        self.logger.info(f\"Redis connection pool initialized: {host}:{port} DB:{db}\")\n        \n    def ping(self) -> bool:\n        \"\"\"Redis ì„œë²„ ì—°ê²° í™•ì¸\"\"\"\n        try:\n            return self.redis.ping()\n        except Exception as e:\n            self.logger.error(f\"Redis connection error: {e}\")\n            return False\n            \n    def get_info(self) -> Dict[str, Any]:\n        \"\"\"Redis ì„œë²„ ì •ë³´ ì¡°íšŒ\"\"\"\n        try:\n            return self.redis.info()\n        except Exception as e:\n            self.logger.error(f\"Failed to get Redis info: {e}\")\n            return {}\n            \n    def get_memory_stats(self) -> Dict[str, Any]:\n        \"\"\"Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ\"\"\"\n        try:\n            info = self.redis.info('memory')\n            return {\n                'used_memory_human': info.get('used_memory_human'),\n                'used_memory_peak_human': info.get('used_memory_peak_human'),\n                'maxmemory_human': info.get('maxmemory_human'),\n                'maxmemory_policy': info.get('maxmemory_policy')\n            }\n        except Exception as e:\n            self.logger.error(f\"Failed to get memory stats: {e}\")\n            return {}\n```\n<info added on 2025-07-25T06:37:18.644Z>\n4. êµ¬í˜„ ì™„ë£Œ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n   - Redis 8.0.3 ì„¤ì¹˜ ì™„ë£Œ (Homebrew ì‚¬ìš©)\n   - redis-py 5.2.0 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ (conda í™˜ê²½)\n   - RedisManager í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ (qb/utils/redis_manager.py)\n   - ì—°ê²° í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n     - Redis ì„œë²„ ì—°ê²°: ì„±ê³µ\n     - ì„œë²„ ì •ë³´: Redis 8.0.3, ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ 1ê°œ\n     - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 888.55K ì‚¬ìš© ì¤‘\n     - ê¸°ë³¸ ë°ì´í„° ì €ì¥/ì¡°íšŒ: ì •ìƒ ì‘ë™\n\n5. í•´ê²°ëœ ê¸°ìˆ ì  ì´ìŠˆ:\n   - conda í™˜ê²½ì—ì„œ redis ëª¨ë“ˆ import ë¬¸ì œ í•´ê²°\n   - conda install redis-py ëª…ë ¹ìœ¼ë¡œ ì •ìƒ ì„¤ì¹˜\n   - $CONDA_PREFIX/bin/python ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì§„í–‰\n</info added on 2025-07-25T06:37:18.644Z>",
            "status": "done",
            "testStrategy": "1. Redis ì„œë²„ ì„¤ì¹˜ ë° ì‹¤í–‰ í™•ì¸:\n   - `redis-cli ping` ëª…ë ¹ìœ¼ë¡œ PONG ì‘ë‹µ í™•ì¸\n   - `redis-cli info` ëª…ë ¹ìœ¼ë¡œ ì„œë²„ ì •ë³´ í™•ì¸\n\n2. RedisManager í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸:\n```python\nimport unittest\nfrom utils.redis_manager import RedisManager\n\nclass TestRedisManager(unittest.TestCase):\n    def setUp(self):\n        self.redis_manager = RedisManager()\n        \n    def test_connection(self):\n        self.assertTrue(self.redis_manager.ping())\n        \n    def test_get_info(self):\n        info = self.redis_manager.get_info()\n        self.assertIsInstance(info, dict)\n        self.assertIn('redis_version', info)\n        \n    def test_get_memory_stats(self):\n        stats = self.redis_manager.get_memory_stats()\n        self.assertIsInstance(stats, dict)\n        self.assertIn('used_memory_human', stats)\n```"
          },
          {
            "id": 2,
            "title": "ë°ì´í„° êµ¬ì¡° ì„¤ê³„ ë° CRUD ë©”ì„œë“œ êµ¬í˜„",
            "description": "ì‹¤ì‹œê°„ ë°ì´í„° ë²„í¼ë§ì„ ìœ„í•œ Redis ë°ì´í„° êµ¬ì¡° ì„¤ê³„ ë° CRUD ë©”ì„œë“œ êµ¬í˜„",
            "dependencies": [
              "21.1"
            ],
            "details": "RedisManager í´ë˜ìŠ¤ì— ë‹¤ìŒ ë°ì´í„° êµ¬ì¡° ê´€ë ¨ ë©”ì„œë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:\n\n```python\n# utils/redis_manager.pyì— ì¶”ê°€\n\n# ì‹œì¥ ë°ì´í„° ê´€ë ¨ ë©”ì„œë“œ\ndef set_market_data(self, symbol: str, market_data: Dict[str, Any], ttl: int = 86400) -> bool:\n    \"\"\"ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ì €ì¥\"\"\"\n    try:\n        # ë¬¸ìì—´ ê°’ìœ¼ë¡œ ë³€í™˜ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬\n        processed_data = {k: json.dumps(v) if isinstance(v, (dict, list)) else str(v) \n                         for k, v in market_data.items()}\n        self.redis.hset(f\"market:{symbol}\", mapping=processed_data)\n        if ttl > 0:\n            self.redis.expire(f\"market:{symbol}\", ttl)  # TTL ì„¤ì •\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to set market data for {symbol}: {e}\")\n        return False\n\ndef get_market_data(self, symbol: str) -> Dict[str, Any]:\n    \"\"\"ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ì¡°íšŒ\"\"\"\n    try:\n        data = self.redis.hgetall(f\"market:{symbol}\")\n        # JSON ë¬¸ìì—´ì„ ê°ì²´ë¡œ ë³€í™˜ ì‹œë„\n        for k, v in data.items():\n            try:\n                data[k] = json.loads(v)\n            except (json.JSONDecodeError, TypeError):\n                pass  # ì¼ë°˜ ë¬¸ìì—´ì€ ê·¸ëŒ€ë¡œ ìœ ì§€\n        return data\n    except Exception as e:\n        self.logger.error(f\"Failed to get market data for {symbol}: {e}\")\n        return {}\n\n# ìº”ë“¤ ë°ì´í„° ê´€ë ¨ ë©”ì„œë“œ\ndef add_candle(self, symbol: str, timeframe: str, candle_data: Dict[str, Any], \n              max_candles: int = 200) -> bool:\n    \"\"\"ìº”ë“¤ ë°ì´í„° ì¶”ê°€ (ìµœëŒ€ ê°œìˆ˜ ì œí•œ)\"\"\"\n    try:\n        key = f\"candles:{symbol}:{timeframe}\"\n        self.redis.lpush(key, json.dumps(candle_data))\n        self.redis.ltrim(key, 0, max_candles - 1)  # ìµœê·¼ max_candlesê°œë§Œ ìœ ì§€\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to add candle for {symbol}:{timeframe}: {e}\")\n        return False\n\ndef get_candles(self, symbol: str, timeframe: str, limit: int = 200) -> List[Dict[str, Any]]:\n    \"\"\"ìº”ë“¤ ë°ì´í„° ì¡°íšŒ\"\"\"\n    try:\n        candles = self.redis.lrange(f\"candles:{symbol}:{timeframe}\", 0, limit - 1)\n        return [json.loads(candle) for candle in candles]\n    except Exception as e:\n        self.logger.error(f\"Failed to get candles for {symbol}:{timeframe}: {e}\")\n        return []\n\n# ê¸°ìˆ ì  ì§€í‘œ ê´€ë ¨ ë©”ì„œë“œ\ndef cache_indicator(self, symbol: str, indicator_name: str, value: Any, ttl: int = 3600) -> bool:\n    \"\"\"ê¸°ìˆ ì  ì§€í‘œ ìºì‹±\"\"\"\n    try:\n        self.redis.hset(f\"indicators:{symbol}\", indicator_name, json.dumps(value))\n        if ttl > 0:\n            self.redis.expire(f\"indicators:{symbol}\", ttl)\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to cache indicator {indicator_name} for {symbol}: {e}\")\n        return False\n\ndef get_indicator(self, symbol: str, indicator_name: str) -> Any:\n    \"\"\"ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ\"\"\"\n    try:\n        value = self.redis.hget(f\"indicators:{symbol}\", indicator_name)\n        return json.loads(value) if value else None\n    except Exception as e:\n        self.logger.error(f\"Failed to get indicator {indicator_name} for {symbol}: {e}\")\n        return None\n\n# í˜¸ê°€ ë°ì´í„° ê´€ë ¨ ë©”ì„œë“œ\ndef update_orderbook(self, symbol: str, price: float, quantity: float, \n                   is_bid: bool, ttl: int = 300) -> bool:\n    \"\"\"í˜¸ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸ (Sorted Set ì‚¬ìš©)\"\"\"\n    try:\n        key = f\"orderbook:{symbol}:{'bids' if is_bid else 'asks'}\"\n        # ê°€ê²©ì„ ì ìˆ˜ë¡œ ì‚¬ìš© (ë§¤ìˆ˜ëŠ” ë†’ì€ ê°€ê²©ì´ ìš°ì„ , ë§¤ë„ëŠ” ë‚®ì€ ê°€ê²©ì´ ìš°ì„ )\n        score = price if is_bid else -price\n        self.redis.zadd(key, {json.dumps({'price': price, 'quantity': quantity}): score})\n        if ttl > 0:\n            self.redis.expire(key, ttl)\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to update orderbook for {symbol}: {e}\")\n        return False\n\ndef get_orderbook(self, symbol: str, side: str, limit: int = 10) -> List[Dict[str, float]]:\n    \"\"\"í˜¸ê°€ ë°ì´í„° ì¡°íšŒ\"\"\"\n    try:\n        if side not in ['bids', 'asks']:\n            raise ValueError(\"Side must be 'bids' or 'asks'\")\n            \n        key = f\"orderbook:{symbol}:{side}\"\n        # ë§¤ìˆ˜ëŠ” ë‚´ë¦¼ì°¨ìˆœ, ë§¤ë„ëŠ” ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬\n        if side == 'bids':\n            items = self.redis.zrevrange(key, 0, limit - 1, withscores=True)\n        else:\n            items = self.redis.zrange(key, 0, limit - 1, withscores=True)\n            \n        result = []\n        for item, score in items:\n            order = json.loads(item)\n            result.append(order)\n        return result\n    except Exception as e:\n        self.logger.error(f\"Failed to get orderbook for {symbol}: {e}\")\n        return []\n\n# ìµœê·¼ ì²´ê²° ë‚´ì—­ ê´€ë ¨ ë©”ì„œë“œ\ndef add_trade(self, symbol: str, trade_data: Dict[str, Any], max_trades: int = 100) -> bool:\n    \"\"\"ìµœê·¼ ì²´ê²° ë‚´ì—­ ì¶”ê°€\"\"\"\n    try:\n        key = f\"trades:{symbol}\"\n        self.redis.lpush(key, json.dumps(trade_data))\n        self.redis.ltrim(key, 0, max_trades - 1)  # ìµœê·¼ max_tradesê°œë§Œ ìœ ì§€\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to add trade for {symbol}: {e}\")\n        return False\n\ndef get_recent_trades(self, symbol: str, limit: int = 50) -> List[Dict[str, Any]]:\n    \"\"\"ìµœê·¼ ì²´ê²° ë‚´ì—­ ì¡°íšŒ\"\"\"\n    try:\n        trades = self.redis.lrange(f\"trades:{symbol}\", 0, limit - 1)\n        return [json.loads(trade) for trade in trades]\n    except Exception as e:\n        self.logger.error(f\"Failed to get recent trades for {symbol}: {e}\")\n        return []\n```\n<info added on 2025-07-25T06:48:16.864Z>\n## êµ¬í˜„ ì™„ë£Œ ë³´ê³ \n\n### 1. ğŸ“Š ì‹œì¥ ë°ì´í„° ê´€ë¦¬ (Hash êµ¬ì¡°)\n- `set_market_data()` - ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ì €ì¥ (TTL ì§€ì›)\n- `get_market_data()` - JSON ìë™ ë³€í™˜ê³¼ í•¨ê»˜ ì¡°íšŒ\n- í…ŒìŠ¤íŠ¸: âœ… ë³µí•© ë°ì´í„° êµ¬ì¡°(dict í¬í•¨) ì €ì¥/ì¡°íšŒ ì„±ê³µ\n\n### 2. ğŸ•¯ï¸ ìº”ë“¤ ë°ì´í„° ê´€ë¦¬ (List êµ¬ì¡°)  \n- `add_candle()` - ìº”ë“¤ ë°ì´í„° ì¶”ê°€ (ìµœëŒ€ 200ê°œ ì œí•œ)\n- `get_candles()` - ì‹œê³„ì—´ ìˆœì„œë¡œ ìº”ë“¤ ì¡°íšŒ\n- í…ŒìŠ¤íŠ¸: âœ… 5ê°œ ìº”ë“¤ ì €ì¥ í›„ ìµœì‹ ìˆœ ì¡°íšŒ ì„±ê³µ\n\n### 3. ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ ìºì‹± (Hash êµ¬ì¡°)\n- `cache_indicator()` - ê¸°ìˆ ì  ì§€í‘œ ìºì‹± (TTL ì§€ì›)  \n- `get_indicator()` - íŠ¹ì • ì§€í‘œ ì¡°íšŒ\n- í…ŒìŠ¤íŠ¸: âœ… MA, RSI ë“± ë³µí•© ì§€í‘œ ìºì‹±/ì¡°íšŒ ì„±ê³µ\n\n### 4. ğŸ“‹ í˜¸ê°€ ë°ì´í„° ê´€ë¦¬ (Sorted Set êµ¬ì¡°)\n- `update_orderbook()` - í˜¸ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸\n- `get_orderbook()` - ë§¤ìˆ˜/ë§¤ë„ í˜¸ê°€ ê°€ê²©ìˆœ ì¡°íšŒ\n- **ë¬¸ì œ í•´ê²°**: ë§¤ë„ í˜¸ê°€ ì •ë ¬ ë¡œì§ ìˆ˜ì • (ë‚®ì€ ê°€ê²© ìš°ì„ )\n- í…ŒìŠ¤íŠ¸: âœ… ë§¤ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ, ë§¤ë„ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ ì„±ê³µ\n\n### 5. ğŸ”„ ìµœê·¼ ì²´ê²° ë‚´ì—­ ê´€ë¦¬ (List êµ¬ì¡°)\n- `add_trade()` - ìµœê·¼ ì²´ê²° ë‚´ì—­ ì¶”ê°€ (ìµœëŒ€ 100ê°œ ì œí•œ)\n- `get_recent_trades()` - ìµœê·¼ ê±°ë˜ ì‹œê°„ìˆœ ì¡°íšŒ\n- í…ŒìŠ¤íŠ¸: âœ… 5ê°œ ê±°ë˜ ì €ì¥ í›„ ìµœì‹ ìˆœ ì¡°íšŒ ì„±ê³µ\n\n### ğŸ”§ ê¸°ìˆ ì  íŠ¹ì§•:\n- **JSON ìë™ ë³€í™˜**: ë³µí•© ë°ì´í„° íƒ€ì… ìë™ ì§ë ¬í™”/ì—­ì§ë ¬í™”\n- **TTL ì§€ì›**: ì‹œì¥ ë°ì´í„°(24ì‹œê°„), ì§€í‘œ(1ì‹œê°„), í˜¸ê°€(5ë¶„) ìë™ ë§Œë£Œ\n- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: max_candles, max_trades íŒŒë¼ë¯¸í„°ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ\n- **íƒ€ì… ì•ˆì „ì„±**: ëª¨ë“  ë©”ì„œë“œì— íƒ€ì… íŒíŠ¸ ë° ì˜ˆì™¸ ì²˜ë¦¬\n\n### ğŸ§ª ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n**5/5 ëª¨ë“  ë°ì´í„° êµ¬ì¡° CRUD í…ŒìŠ¤íŠ¸ í†µê³¼!**\n- ì‹œì¥ ë°ì´í„°: âœ… ì €ì¥/ì¡°íšŒ ì„±ê³µ\n- ìº”ë“¤ ë°ì´í„°: âœ… ì‹œê³„ì—´ ê´€ë¦¬ ì„±ê³µ  \n- ê¸°ìˆ ì  ì§€í‘œ: âœ… ìºì‹± ì‹œìŠ¤í…œ ì„±ê³µ\n- í˜¸ê°€ ë°ì´í„°: âœ… ê°€ê²©ìˆœ ì •ë ¬ ì„±ê³µ\n- ì²´ê²° ë‚´ì—­: âœ… ìµœì‹ ìˆœ ê´€ë¦¬ ì„±ê³µ\n\nğŸš€ **ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„ ì™„ë£Œ**: Task 21.3 \"Redis Pub/Sub ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„\"ìœ¼ë¡œ ì§„í–‰\n</info added on 2025-07-25T06:48:16.864Z>",
            "status": "done",
            "testStrategy": "1. ë°ì´í„° êµ¬ì¡°ë³„ CRUD ì‘ì—… í…ŒìŠ¤íŠ¸:\n```python\nimport unittest\nimport time\nfrom utils.redis_manager import RedisManager\n\nclass TestRedisDataStructures(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        self.symbol = 'BTCUSDT'\n        \n    def test_market_data(self):\n        # ì‹œì¥ ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n        market_data = {\n            'price': '50000.0',\n            'volume': '1000.5',\n            'change': '2.5',\n            'details': {'high': 51000, 'low': 49000}\n        }\n        self.assertTrue(self.redis.set_market_data(self.symbol, market_data))\n        retrieved = self.redis.get_market_data(self.symbol)\n        self.assertEqual(retrieved['price'], '50000.0')\n        self.assertEqual(retrieved['details']['high'], 51000)\n        \n    def test_candles(self):\n        # ìº”ë“¤ ë°ì´í„° ì¶”ê°€ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n        for i in range(5):\n            candle = {\n                'timestamp': int(time.time()) - i * 60,\n                'open': 50000 + i,\n                'high': 50100 + i,\n                'low': 49900 + i,\n                'close': 50050 + i,\n                'volume': 100 + i\n            }\n            self.assertTrue(self.redis.add_candle(self.symbol, '1m', candle))\n            \n        candles = self.redis.get_candles(self.symbol, '1m')\n        self.assertEqual(len(candles), 5)\n        self.assertEqual(candles[0]['open'], 50004)  # ê°€ì¥ ìµœê·¼ ìº”ë“¤\n        \n    def test_indicators(self):\n        # ì§€í‘œ ìºì‹± ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n        indicator = {'ma_20': 49500, 'ma_50': 48000, 'rsi': 65}\n        self.assertTrue(self.redis.cache_indicator(self.symbol, 'moving_averages', indicator))\n        retrieved = self.redis.get_indicator(self.symbol, 'moving_averages')\n        self.assertEqual(retrieved['ma_20'], 49500)\n        self.assertEqual(retrieved['rsi'], 65)\n        \n    def test_orderbook(self):\n        # í˜¸ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n        # ë§¤ìˆ˜ í˜¸ê°€ ì¶”ê°€\n        self.redis.update_orderbook(self.symbol, 49900, 1.5, True)\n        self.redis.update_orderbook(self.symbol, 49800, 2.5, True)\n        self.redis.update_orderbook(self.symbol, 50000, 1.0, True)\n        \n        # ë§¤ë„ í˜¸ê°€ ì¶”ê°€\n        self.redis.update_orderbook(self.symbol, 50100, 1.2, False)\n        self.redis.update_orderbook(self.symbol, 50200, 2.0, False)\n        \n        bids = self.redis.get_orderbook(self.symbol, 'bids')\n        asks = self.redis.get_orderbook(self.symbol, 'asks')\n        \n        self.assertEqual(len(bids), 3)\n        self.assertEqual(len(asks), 2)\n        self.assertEqual(bids[0]['price'], 50000)  # ìµœê³  ë§¤ìˆ˜ê°€\n        self.assertEqual(asks[0]['price'], 50100)  # ìµœì € ë§¤ë„ê°€\n        \n    def test_recent_trades(self):\n        # ìµœê·¼ ì²´ê²° ë‚´ì—­ ì¶”ê°€ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n        for i in range(5):\n            trade = {\n                'timestamp': int(time.time()) - i,\n                'price': 50000 + i * 10,\n                'quantity': 0.1 + i * 0.01,\n                'side': 'buy' if i % 2 == 0 else 'sell'\n            }\n            self.assertTrue(self.redis.add_trade(self.symbol, trade))\n            \n        trades = self.redis.get_recent_trades(self.symbol)\n        self.assertEqual(len(trades), 5)\n        self.assertEqual(trades[0]['price'], 50040)  # ê°€ì¥ ìµœê·¼ ê±°ë˜\n        self.assertEqual(trades[0]['side'], 'sell')\n```"
          },
          {
            "id": 3,
            "title": "Redis Pub/Sub ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "Redis Pub/Sub ê¸°ëŠ¥ì„ í™œìš©í•œ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„ ë° ì´ë²¤íŠ¸ ì±„ë„ ì„¤ì •",
            "dependencies": [
              "21.2"
            ],
            "details": "RedisManager í´ë˜ìŠ¤ì— Pub/Sub ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê³  ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤:\n\n```python\n# utils/redis_manager.pyì— ì¶”ê°€\n\n# Pub/Sub ì´ë²¤íŠ¸ ê´€ë ¨ ë©”ì„œë“œ\ndef publish_event(self, channel: str, message: Dict[str, Any]) -> bool:\n    \"\"\"ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n    try:\n        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€\n        if 'timestamp' not in message:\n            message['timestamp'] = int(time.time() * 1000)  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„\n            \n        result = self.redis.publish(channel, json.dumps(message))\n        self.logger.debug(f\"Published event to {channel}: {message}\")\n        return result > 0  # êµ¬ë…ì ìˆ˜ ë°˜í™˜\n    except Exception as e:\n        self.logger.error(f\"Failed to publish event to {channel}: {e}\")\n        return False\n\ndef subscribe(self, channels: List[str]):\n    \"\"\"ì±„ë„ êµ¬ë… (ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©)\"\"\"\n    try:\n        pubsub = self.redis.pubsub()\n        pubsub.subscribe(*channels)\n        self.logger.info(f\"Subscribed to channels: {channels}\")\n        return pubsub\n    except Exception as e:\n        self.logger.error(f\"Failed to subscribe to channels {channels}: {e}\")\n        return None\n```\n\nì´ì œ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” ë³„ë„ì˜ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n\n```python\n# utils/event_bus.py\n\nimport json\nimport asyncio\nimport logging\nfrom typing import Dict, List, Callable, Any, Optional\nfrom datetime import datetime\nfrom utils.redis_manager import RedisManager\n\nclass EventBus:\n    \"\"\"Redis Pub/Sub ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ\"\"\"\n    \n    # ì •ì˜ëœ ì´ë²¤íŠ¸ ì±„ë„\n    CHANNELS = {\n        'MARKET_DATA': 'market_data_received',\n        'TRADING_SIGNAL': 'trading_signal',\n        'ORDER_EXECUTED': 'order_executed',\n        'RISK_ALERT': 'risk_alert',\n        'SYSTEM_STATUS': 'system_status',\n        'ERROR': 'error'\n    }\n    \n    def __init__(self, redis_manager: RedisManager):\n        self.redis = redis_manager\n        self.logger = logging.getLogger(__name__)\n        self.handlers = {channel: [] for channel in self.CHANNELS.values()}\n        self.running = False\n        self.pubsub = None\n        self.listener_task = None\n        \n    async def start(self):\n        \"\"\"ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘\"\"\"\n        if self.running:\n            return\n            \n        self.pubsub = self.redis.subscribe(list(self.CHANNELS.values()))\n        if not self.pubsub:\n            self.logger.error(\"Failed to initialize pubsub\")\n            return False\n            \n        self.running = True\n        self.listener_task = asyncio.create_task(self._message_listener())\n        self.logger.info(\"Event bus started\")\n        return True\n        \n    async def stop(self):\n        \"\"\"ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€\"\"\"\n        if not self.running:\n            return\n            \n        self.running = False\n        if self.listener_task:\n            self.listener_task.cancel()\n            try:\n                await self.listener_task\n            except asyncio.CancelledError:\n                pass\n                \n        if self.pubsub:\n            await self.pubsub.unsubscribe()\n            await self.pubsub.close()\n            \n        self.logger.info(\"Event bus stopped\")\n        \n    def register_handler(self, channel: str, handler: Callable[[Dict[str, Any]], None]):\n        \"\"\"ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        if channel not in self.CHANNELS.values():\n            self.logger.warning(f\"Unknown channel: {channel}\")\n            return False\n            \n        self.handlers[channel].append(handler)\n        self.logger.debug(f\"Handler registered for channel: {channel}\")\n        return True\n        \n    def publish(self, channel: str, data: Dict[str, Any]) -> bool:\n        \"\"\"ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        if channel not in self.CHANNELS.values():\n            self.logger.warning(f\"Unknown channel: {channel}\")\n            return False\n            \n        return self.redis.publish_event(channel, data)\n        \n    async def _message_listener(self):\n        \"\"\"ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ë£¨í”„\"\"\"\n        self.logger.info(\"Message listener started\")\n        \n        while self.running:\n            try:\n                message = await self.pubsub.get_message(ignore_subscribe_messages=True, timeout=1.0)\n                if message is None:\n                    await asyncio.sleep(0.01)  # CPU ì‚¬ìš©ëŸ‰ ê°ì†Œ\n                    continue\n                    \n                channel = message['channel']\n                data = json.loads(message['data'])\n                \n                # í•¸ë“¤ëŸ¬ í˜¸ì¶œ\n                for handler in self.handlers.get(channel, []):\n                    try:\n                        handler(data)\n                    except Exception as e:\n                        self.logger.error(f\"Error in handler for {channel}: {e}\")\n                        \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in message listener: {e}\")\n                await asyncio.sleep(1)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸°\n                \n        self.logger.info(\"Message listener stopped\")\n```\n\nì´ë²¤íŠ¸ ë²„ìŠ¤ ì‚¬ìš© ì˜ˆì‹œ:\n\n```python\n# ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‚¬ìš© ì˜ˆì‹œ\nasync def example_usage():\n    # ì´ˆê¸°í™”\n    redis_manager = RedisManager()\n    event_bus = EventBus(redis_manager)\n    \n    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ì˜\n    def market_data_handler(data):\n        print(f\"Market data received: {data}\")\n        \n    def trading_signal_handler(data):\n        print(f\"Trading signal received: {data}\")\n        \n    # í•¸ë“¤ëŸ¬ ë“±ë¡\n    event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], market_data_handler)\n    event_bus.register_handler(EventBus.CHANNELS['TRADING_SIGNAL'], trading_signal_handler)\n    \n    # ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘\n    await event_bus.start()\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], {\n        'symbol': 'BTCUSDT',\n        'price': 50000,\n        'volume': 1000\n    })\n    \n    event_bus.publish(EventBus.CHANNELS['TRADING_SIGNAL'], {\n        'symbol': 'BTCUSDT',\n        'action': 'BUY',\n        'price': 50000,\n        'quantity': 0.1,\n        'reason': 'MA crossover'\n    })\n    \n    # 5ì´ˆ ëŒ€ê¸° í›„ ì¢…ë£Œ\n    await asyncio.sleep(5)\n    await event_bus.stop()\n```\n<info added on 2025-07-25T07:23:23.241Z>\nRedis Pub/Sub ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ êµ¬í˜„ì— ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤:\n\n1. ì´ë²¤íŠ¸ íƒ€ì… í™•ì¥ - ê¸°ì¡´ 6ê°œ ì±„ë„ì—ì„œ ì‹œì¥ ë°ì´í„°, ê¸°ìˆ ì  ë¶„ì„, ì „ëµ, ì£¼ë¬¸, ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì‹œìŠ¤í…œ ê´€ë ¨ ì´ë²¤íŠ¸ë¡œ ì„¸ë¶„í™”\n\n2. Event ë°ì´í„° í´ë˜ìŠ¤ êµ¬í˜„:\n```python\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\nfrom typing import Any, Dict, Optional\n\n@dataclass\nclass Event:\n    \"\"\"êµ¬ì¡°í™”ëœ ì´ë²¤íŠ¸ ë©”ì‹œì§€ í¬ë§·\"\"\"\n    event_type: str\n    source: str\n    data: Dict[str, Any]\n    timestamp: int = None\n    \n    def __post_init__(self):\n        if self.timestamp is None:\n            self.timestamp = int(datetime.now().timestamp() * 1000)\n            \n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n```\n\n3. ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ ì•ˆì „í•œ êµ¬ë…ì ê´€ë¦¬:\n```python\nfrom threading import RLock\n\nclass EventBus:\n    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€\n    def __init__(self, redis_manager: RedisManager):\n        # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...\n        self._subscribers_lock = RLock()\n        # ...\n        \n    def register_handler(self, channel: str, handler: Callable[[Dict[str, Any]], None]):\n        \"\"\"ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        with self._subscribers_lock:\n            if channel not in self.CHANNELS.values():\n                self.logger.warning(f\"Unknown channel: {channel}\")\n                return False\n                \n            self.handlers[channel].append(handler)\n            self.logger.debug(f\"Handler registered for channel: {channel}\")\n            return True\n```\n\n4. ë¹„ë™ê¸° ì½œë°± ì‹¤í–‰ì„ ìœ„í•œ ThreadPoolExecutor ì‚¬ìš©:\n```python\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass EventBus:\n    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€\n    def __init__(self, redis_manager: RedisManager):\n        # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...\n        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"event-worker\")\n        # ...\n        \n    async def _message_listener(self):\n        \"\"\"ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ë£¨í”„ - ThreadPoolExecutor ì‚¬ìš©\"\"\"\n        # ê¸°ì¡´ ì½”ë“œ...\n        \n        # í•¸ë“¤ëŸ¬ í˜¸ì¶œ ë¶€ë¶„ ìˆ˜ì •\n        for handler in self.handlers.get(channel, []):\n            try:\n                # ìŠ¤ë ˆë“œ í’€ì—ì„œ í•¸ë“¤ëŸ¬ ì‹¤í–‰\n                self.executor.submit(handler, data)\n            except Exception as e:\n                self.logger.error(f\"Error submitting handler for {channel}: {e}\")\n```\n\n5. ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜:\n```python\nclass EventBus:\n    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€\n    async def _reconnect(self):\n        \"\"\"Redis ì—°ê²° ì¬ì‹œë„\"\"\"\n        retry_count = 0\n        max_retries = 5\n        \n        while retry_count < max_retries:\n            try:\n                self.logger.info(f\"Attempting to reconnect (attempt {retry_count+1}/{max_retries})\")\n                self.pubsub = self.redis.subscribe(list(self.CHANNELS.values()))\n                if self.pubsub:\n                    self.logger.info(\"Reconnection successful\")\n                    return True\n            except Exception as e:\n                self.logger.error(f\"Reconnection failed: {e}\")\n                \n            retry_count += 1\n            await asyncio.sleep(min(2 ** retry_count, 30))  # ì§€ìˆ˜ ë°±ì˜¤í”„\n            \n        self.logger.critical(\"Failed to reconnect after maximum retries\")\n        return False\n```\n\n6. ì´ë²¤íŠ¸ í†µê³„ ì¶”ì :\n```python\nclass EventBus:\n    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€\n    def __init__(self, redis_manager: RedisManager):\n        # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...\n        self.stats = {channel: {\"published\": 0, \"received\": 0, \"errors\": 0} \n                      for channel in self.CHANNELS.values()}\n        # ...\n        \n    def get_stats(self) -> Dict[str, Dict[str, int]]:\n        \"\"\"ì´ë²¤íŠ¸ í†µê³„ ë°˜í™˜\"\"\"\n        return self.stats\n```\n\n7. í•˜íŠ¸ë¹„íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê¸°ëŠ¥:\n```python\nclass EventBus:\n    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€\n    async def start_heartbeat(self, interval_seconds: int = 30):\n        \"\"\"ì‹œìŠ¤í…œ í•˜íŠ¸ë¹„íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹œì‘\"\"\"\n        while self.running:\n            try:\n                heartbeat_event = Event(\n                    event_type=\"heartbeat\",\n                    source=\"event_bus\",\n                    data={\"status\": \"alive\", \"stats\": self.get_stats()}\n                )\n                self.publish(self.CHANNELS['SYSTEM_STATUS'], heartbeat_event.to_dict())\n                await asyncio.sleep(interval_seconds)\n            except Exception as e:\n                self.logger.error(f\"Error in heartbeat: {e}\")\n                await asyncio.sleep(interval_seconds)\n```\n\n8. ì¢…í•©ì ì¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ê°€ ì‘ì„±ë˜ì–´ ëª¨ë“  ê¸°ëŠ¥ì˜ ì •ìƒ ì‘ë™ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.\n</info added on 2025-07-25T07:23:23.241Z>",
            "status": "done",
            "testStrategy": "1. Pub/Sub ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:\n```python\nimport unittest\nimport asyncio\nimport json\nfrom utils.redis_manager import RedisManager\nfrom utils.event_bus import EventBus\n\nclass TestPubSub(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        self.test_channel = 'test_channel'\n        \n    def test_publish_event(self):\n        message = {'test': 'data', 'value': 123}\n        result = self.redis.publish_event(self.test_channel, message)\n        self.assertTrue(result)  # ë°œí–‰ ì„±ê³µ ì—¬ë¶€ í™•ì¸\n        \n    def test_subscribe(self):\n        pubsub = self.redis.subscribe([self.test_channel])\n        self.assertIsNotNone(pubsub)\n        pubsub.close()\n\nclass TestEventBus(unittest.IsolatedAsyncioTestCase):\n    async def asyncSetUp(self):\n        self.redis = RedisManager()\n        self.event_bus = EventBus(self.redis)\n        self.received_messages = []\n        \n    async def asyncTearDown(self):\n        await self.event_bus.stop()\n        \n    def message_handler(self, data):\n        self.received_messages.append(data)\n        \n    async def test_event_bus_flow(self):\n        # í•¸ë“¤ëŸ¬ ë“±ë¡\n        self.event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], self.message_handler)\n        \n        # ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘\n        await self.event_bus.start()\n        \n        # ì´ë²¤íŠ¸ ë°œí–‰\n        test_data = {'symbol': 'BTCUSDT', 'price': 50000, 'test_id': 12345}\n        self.event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], test_data)\n        \n        # ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°\n        await asyncio.sleep(0.5)\n        \n        # ê²€ì¦\n        self.assertEqual(len(self.received_messages), 1)\n        self.assertEqual(self.received_messages[0]['symbol'], 'BTCUSDT')\n        self.assertEqual(self.received_messages[0]['test_id'], 12345)\n        \n    async def test_multiple_channels(self):\n        # ì—¬ëŸ¬ ì±„ë„ í•¸ë“¤ëŸ¬ ë“±ë¡\n        self.event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], self.message_handler)\n        self.event_bus.register_handler(EventBus.CHANNELS['TRADING_SIGNAL'], self.message_handler)\n        \n        # ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘\n        await self.event_bus.start()\n        \n        # ì—¬ëŸ¬ ì±„ë„ì— ì´ë²¤íŠ¸ ë°œí–‰\n        self.event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], {'type': 'market', 'id': 1})\n        self.event_bus.publish(EventBus.CHANNELS['TRADING_SIGNAL'], {'type': 'signal', 'id': 2})\n        \n        # ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°\n        await asyncio.sleep(0.5)\n        \n        # ê²€ì¦\n        self.assertEqual(len(self.received_messages), 2)\n        self.assertTrue(any(msg['type'] == 'market' for msg in self.received_messages))\n        self.assertTrue(any(msg['type'] == 'signal' for msg in self.received_messages))\n```"
          },
          {
            "id": 4,
            "title": "ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ë° ì••ì¶• ê¸°ëŠ¥ êµ¬í˜„",
            "description": "Redis ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ìœ í‹¸ë¦¬í‹° ë° ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ë°ì´í„° ì••ì¶• ê¸°ëŠ¥ êµ¬í˜„",
            "dependencies": [
              "21.2"
            ],
            "details": "ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ë° ì••ì¶• ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n\n```python\n# utils/serialization.py\n\nimport json\nimport zlib\nimport base64\nimport msgpack\nimport logging\nfrom typing import Any, Dict, List, Union, Optional\n\nclass Serializer:\n    \"\"\"ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ë° ì••ì¶• ìœ í‹¸ë¦¬í‹°\"\"\"\n    \n    FORMAT_JSON = 'json'\n    FORMAT_MSGPACK = 'msgpack'\n    \n    def __init__(self, default_format=FORMAT_JSON, compress=False, compression_level=6):\n        self.logger = logging.getLogger(__name__)\n        self.default_format = default_format\n        self.compress = compress\n        self.compression_level = compression_level\n        \n    def serialize(self, data: Any, format: Optional[str] = None, compress: Optional[bool] = None) -> str:\n        \"\"\"ë°ì´í„° ì§ë ¬í™”\"\"\"\n        format = format or self.default_format\n        compress = self.compress if compress is None else compress\n        \n        try:\n            # ì§ë ¬í™”\n            if format == self.FORMAT_JSON:\n                serialized = json.dumps(data)\n            elif format == self.FORMAT_MSGPACK:\n                serialized = base64.b64encode(msgpack.packb(data)).decode('ascii')\n            else:\n                raise ValueError(f\"Unsupported format: {format}\")\n                \n            # ì••ì¶•\n            if compress:\n                compressed = zlib.compress(serialized.encode('utf-8'), self.compression_level)\n                return f\"c:{base64.b64encode(compressed).decode('ascii')}\"\n            else:\n                return f\"{format[0]}:{serialized}\"\n                \n        except Exception as e:\n            self.logger.error(f\"Serialization error: {e}\")\n            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ JSONìœ¼ë¡œ ëŒ€ì²´\n            return f\"j:{json.dumps(str(data))}\"\n            \n    def deserialize(self, data_str: str) -> Any:\n        \"\"\"ë°ì´í„° ì—­ì§ë ¬í™”\"\"\"\n        if not data_str or len(data_str) < 2 or data_str[1] != ':':\n            return data_str  # ì§ë ¬í™”ëœ í˜•ì‹ì´ ì•„ë‹˜\n            \n        prefix = data_str[0]\n        payload = data_str[2:]\n        \n        try:\n            # ì••ì¶• í•´ì œ\n            if prefix == 'c':\n                decompressed = zlib.decompress(base64.b64decode(payload))\n                # ì••ì¶• í•´ì œ í›„ ë‹¤ì‹œ ì—­ì§ë ¬í™” (j: ë˜ëŠ” m: ì ‘ë‘ì–´ í™•ì¸)\n                return self.deserialize(decompressed.decode('utf-8'))\n                \n            # JSON ì—­ì§ë ¬í™”\n            elif prefix == 'j':\n                return json.loads(payload)\n                \n            # MessagePack ì—­ì§ë ¬í™”\n            elif prefix == 'm':\n                return msgpack.unpackb(base64.b64decode(payload))\n                \n            else:\n                self.logger.warning(f\"Unknown serialization prefix: {prefix}\")\n                return data_str\n                \n        except Exception as e:\n            self.logger.error(f\"Deserialization error: {e}\")\n            return data_str\n```\n\nì´ì œ RedisManager í´ë˜ìŠ¤ë¥¼ í™•ì¥í•˜ì—¬ ì§ë ¬í™”/ì—­ì§ë ¬í™” ë° ì••ì¶• ê¸°ëŠ¥ì„ í†µí•©í•©ë‹ˆë‹¤:\n\n```python\n# utils/redis_manager.py ìˆ˜ì •\n\n# í•„ìš”í•œ import ì¶”ê°€\nfrom utils.serialization import Serializer\n\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0, password=None, \n                 use_compression=False, compression_level=6):\n        # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...\n        \n        # ì§ë ¬í™” ë„êµ¬ ì´ˆê¸°í™”\n        self.serializer = Serializer(\n            default_format=Serializer.FORMAT_JSON,\n            compress=use_compression,\n            compression_level=compression_level\n        )\n        \n    # ì••ì¶• ë°ì´í„° ì €ì¥ ë©”ì„œë“œ ì¶”ê°€\n    def set_compressed(self, key: str, value: Any, ttl: int = 0) -> bool:\n        \"\"\"ë°ì´í„° ì••ì¶• ì €ì¥\"\"\"\n        try:\n            serialized = self.serializer.serialize(value, compress=True)\n            self.redis.set(key, serialized)\n            if ttl > 0:\n                self.redis.expire(key, ttl)\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to set compressed data for {key}: {e}\")\n            return False\n            \n    def get_compressed(self, key: str) -> Any:\n        \"\"\"ì••ì¶• ë°ì´í„° ì¡°íšŒ\"\"\"\n        try:\n            data = self.redis.get(key)\n            if not data:\n                return None\n            return self.serializer.deserialize(data)\n        except Exception as e:\n            self.logger.error(f\"Failed to get compressed data for {key}: {e}\")\n            return None\n            \n    # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥ ë©”ì„œë“œ (ìë™ ì••ì¶• ì ìš©)\n    def set_large_data(self, key: str, value: Any, ttl: int = 0, \n                      size_threshold: int = 1024) -> bool:\n        \"\"\"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥ (í¬ê¸°ì— ë”°ë¼ ìë™ ì••ì¶•)\"\"\"\n        try:\n            # ì¼ë°˜ JSON ì§ë ¬í™”\n            serialized = json.dumps(value)\n            \n            # í¬ê¸°ê°€ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ì••ì¶• ì ìš©\n            if len(serialized) > size_threshold:\n                return self.set_compressed(key, value, ttl)\n            else:\n                self.redis.set(key, serialized)\n                if ttl > 0:\n                    self.redis.expire(key, ttl)\n                return True\n        except Exception as e:\n            self.logger.error(f\"Failed to set large data for {key}: {e}\")\n            return False\n            \n    def get_large_data(self, key: str) -> Any:\n        \"\"\"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì¡°íšŒ (ì••ì¶• ì—¬ë¶€ ìë™ ê°ì§€)\"\"\"\n        try:\n            data = self.redis.get(key)\n            if not data:\n                return None\n                \n            # ì••ì¶• ë°ì´í„° í™•ì¸ (c: ì ‘ë‘ì–´)\n            if data.startswith(b'c:'):\n                return self.serializer.deserialize(data.decode('utf-8'))\n            else:\n                # ì¼ë°˜ JSON\n                try:\n                    return json.loads(data)\n                except json.JSONDecodeError:\n                    return data.decode('utf-8')\n        except Exception as e:\n            self.logger.error(f\"Failed to get large data for {key}: {e}\")\n            return None\n```\n\në©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ë©”ì„œë“œ ì¶”ê°€:\n\n```python\n# utils/redis_manager.pyì— ì¶”ê°€\n\ndef get_memory_usage(self) -> Dict[str, Any]:\n    \"\"\"Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìƒì„¸ ì •ë³´\"\"\"\n    try:\n        memory_info = self.redis.info('memory')\n        return {\n            'used_memory': memory_info['used_memory'],\n            'used_memory_human': memory_info['used_memory_human'],\n            'used_memory_peak': memory_info['used_memory_peak'],\n            'used_memory_peak_human': memory_info['used_memory_peak_human'],\n            'used_memory_lua': memory_info['used_memory_lua'],\n            'maxmemory': memory_info['maxmemory'],\n            'maxmemory_human': memory_info['maxmemory_human'],\n            'maxmemory_policy': memory_info['maxmemory_policy']\n        }\n    except Exception as e:\n        self.logger.error(f\"Failed to get memory usage: {e}\")\n        return {}\n        \ndef get_key_memory_usage(self, key: str) -> int:\n    \"\"\"íŠ¹ì • í‚¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)\"\"\"\n    try:\n        return self.redis.memory_usage(key)\n    except Exception as e:\n        self.logger.error(f\"Failed to get memory usage for key {key}: {e}\")\n        return -1\n        \ndef get_keys_by_pattern(self, pattern: str) -> List[str]:\n    \"\"\"íŒ¨í„´ì— ì¼ì¹˜í•˜ëŠ” í‚¤ ëª©ë¡ ì¡°íšŒ\"\"\"\n    try:\n        return self.redis.keys(pattern)\n    except Exception as e:\n        self.logger.error(f\"Failed to get keys by pattern {pattern}: {e}\")\n        return []\n        \ndef get_pattern_memory_usage(self, pattern: str) -> Dict[str, int]:\n    \"\"\"íŠ¹ì • íŒ¨í„´ì˜ í‚¤ë“¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\"\"\"\n    try:\n        keys = self.get_keys_by_pattern(pattern)\n        result = {}\n        for key in keys:\n            result[key] = self.get_key_memory_usage(key)\n        return result\n    except Exception as e:\n        self.logger.error(f\"Failed to get pattern memory usage for {pattern}: {e}\")\n        return {}\n        \ndef optimize_memory(self, target_mb: int = 20) -> bool:\n    \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” (ëª©í‘œ: target_mb)\"\"\"\n    try:\n        # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n        memory_info = self.get_memory_usage()\n        current_mb = memory_info['used_memory'] / (1024 * 1024)\n        \n        self.logger.info(f\"Current memory usage: {current_mb:.2f}MB, Target: {target_mb}MB\")\n        \n        # ì´ë¯¸ ëª©í‘œ ì´í•˜ë©´ ìµœì í™” í•„ìš” ì—†ìŒ\n        if current_mb <= target_mb:\n            return True\n            \n        # 1. ë§Œë£Œ ì‹œê°„ì´ ì„¤ì •ë˜ì§€ ì•Šì€ í‚¤ì— ê¸°ë³¸ TTL ì ìš©\n        for key in self.get_keys_by_pattern('*'):\n            if self.redis.ttl(key) == -1:  # -1ì€ ë§Œë£Œ ì‹œê°„ ì—†ìŒ\n                self.redis.expire(key, 86400)  # 1ì¼ ê¸°ë³¸ TTL\n                \n        # 2. í° ë°ì´í„°ì…‹ ì••ì¶•\n        large_keys = []\n        for key in self.get_keys_by_pattern('*'):\n            size = self.get_key_memory_usage(key)\n            if size > 10240:  # 10KB ì´ìƒ\n                large_keys.append((key, size))\n                \n        # í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬\n        large_keys.sort(key=lambda x: x[1], reverse=True)\n        \n        # í° í‚¤ë¶€í„° ì••ì¶• ì‹œë„\n        for key, size in large_keys:\n            try:\n                # ë¬¸ìì—´ íƒ€ì…ë§Œ ì••ì¶• ê°€ëŠ¥\n                if self.redis.type(key) == 'string':\n                    value = self.redis.get(key)\n                    ttl = self.redis.ttl(key)\n                    if ttl < 0:\n                        ttl = 86400  # ê¸°ë³¸ TTL\n                        \n                    # ì••ì¶• ì €ì¥\n                    self.set_compressed(key, value, ttl)\n            except Exception as e:\n                self.logger.error(f\"Failed to compress key {key}: {e}\")\n                \n        # 3. ë©”ëª¨ë¦¬ ì •ì±… í™•ì¸ ë° ì„¤ì •\n        if memory_info['maxmemory_policy'] != 'allkeys-lru':\n            # Redis ì„¤ì • íŒŒì¼ ìˆ˜ì • í•„ìš” (ì—¬ê¸°ì„œëŠ” ëŸ°íƒ€ì„ì— ë³€ê²½ ë¶ˆê°€)\n            self.logger.warning(\"Consider changing maxmemory-policy to allkeys-lru\")\n            \n        # ìµœì í™” í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n        memory_info = self.get_memory_usage()\n        new_mb = memory_info['used_memory'] / (1024 * 1024)\n        self.logger.info(f\"Memory usage after optimization: {new_mb:.2f}MB\")\n        \n        return new_mb <= target_mb\n    except Exception as e:\n        self.logger.error(f\"Memory optimization failed: {e}\")\n        return False\n```\n<info added on 2025-07-25T09:37:55.939Z>\nêµ¬í˜„ ì™„ë£Œ ë³´ê³ :\n\n1. DataSerializer í´ë˜ìŠ¤ êµ¬í˜„ (qb/utils/serialization.py)\n   - JSON, Pickle ì§ë ¬í™” í¬ë§· ì§€ì›\n   - zlib, lz4, snappy ì••ì¶• ì•Œê³ ë¦¬ì¦˜ ì§€ì›\n   - NumPy, Pandas, datetime ë“± í™•ì¥ íƒ€ì… ì§€ì›\n   - ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìë™ ì—­ì§ë ¬í™”\n\n2. Redis Manager í†µí•©\n   - ì••ì¶• ì§€ì› ì¶”ê°€ (use_compression íŒŒë¼ë¯¸í„°)\n   - ë³µí•© ë°ì´í„° ì €ì¥/ì¡°íšŒ ë©”ì„œë“œ ì¶”ê°€\n   - ë°°ì¹˜ ì‘ì—… ë©”ì„œë“œ ì¶”ê°€\n   - ì„±ëŠ¥ ìµœì í™” ë©”ì„œë“œ ì¶”ê°€\n\n3. í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬\n   - 14ê°œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ëª¨ë‘ í†µê³¼ (tests/test_serialization.py)\n   - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ êµ¬í˜„ (tests/benchmark_serialization.py)\n   - ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼: pickle+noneì´ ê°€ì¥ ë¹ ë¥´ê³ , json+lz4ê°€ ê· í˜•ì¡íŒ ì„ íƒ\n   - Redis í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ, 14.1% ì••ì¶•ë¥  ë‹¬ì„±\n</info added on 2025-07-25T09:37:55.939Z>",
            "status": "done",
            "testStrategy": "1. ì§ë ¬í™”/ì—­ì§ë ¬í™” ë° ì••ì¶• í…ŒìŠ¤íŠ¸:\n```python\nimport unittest\nimport json\nimport sys\nfrom utils.serialization import Serializer\nfrom utils.redis_manager import RedisManager\n\nclass TestSerialization(unittest.TestCase):\n    def setUp(self):\n        self.serializer = Serializer(compress=False)\n        self.serializer_compressed = Serializer(compress=True)\n        \n    def test_json_serialization(self):\n        data = {'name': 'test', 'values': [1, 2, 3], 'nested': {'a': 1, 'b': 2}}\n        serialized = self.serializer.serialize(data)\n        deserialized = self.serializer.deserialize(serialized)\n        self.assertEqual(data, deserialized)\n        \n    def test_compression(self):\n        # í° ë°ì´í„° ìƒì„±\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        \n        # ì••ì¶• ì—†ì´ ì§ë ¬í™”\n        normal = self.serializer.serialize(large_data)\n        \n        # ì••ì¶• ì ìš© ì§ë ¬í™”\n        compressed = self.serializer_compressed.serialize(large_data)\n        \n        # ì••ì¶• íš¨ê³¼ í™•ì¸\n        self.assertLess(len(compressed), len(normal))\n        \n        # ì••ì¶• ë°ì´í„° ì—­ì§ë ¬í™” í™•ì¸\n        decompressed = self.serializer_compressed.deserialize(compressed)\n        self.assertEqual(large_data, decompressed)\n        \nclass TestRedisCompression(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager(use_compression=True)\n        self.test_key = 'test:compression'\n        \n    def tearDown(self):\n        self.redis.redis.delete(self.test_key)\n        \n    def test_compressed_storage(self):\n        # í° ë°ì´í„° ìƒì„±\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        \n        # ì••ì¶• ì €ì¥\n        self.assertTrue(self.redis.set_compressed(self.test_key, large_data))\n        \n        # ì¡°íšŒ ë° ê²€ì¦\n        retrieved = self.redis.get_compressed(self.test_key)\n        self.assertEqual(large_data, retrieved)\n        \n    def test_auto_compression(self):\n        # ì‘ì€ ë°ì´í„°\n        small_data = {'name': 'test'}\n        self.redis.set_large_data(self.test_key + ':small', small_data)\n        \n        # í° ë°ì´í„°\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        self.redis.set_large_data(self.test_key + ':large', large_data)\n        \n        # ì¡°íšŒ ë° ê²€ì¦\n        small_retrieved = self.redis.get_large_data(self.test_key + ':small')\n        large_retrieved = self.redis.get_large_data(self.test_key + ':large')\n        \n        self.assertEqual(small_data, small_retrieved)\n        self.assertEqual(large_data, large_retrieved)\n        \n        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ\n        small_size = self.redis.get_key_memory_usage(self.test_key + ':small')\n        large_size = self.redis.get_key_memory_usage(self.test_key + ':large')\n        \n        # ì••ì¶• íš¨ê³¼ í™•ì¸ (ì •í™•í•œ ë¹„êµëŠ” ì–´ë µì§€ë§Œ ëŒ€ëµì ì¸ ë¹„êµ)\n        normal_json_size = len(json.dumps(large_data))\n        self.assertLess(large_size, normal_json_size * 0.8)  # ìµœì†Œ 20% ì••ì¶• íš¨ê³¼ ê¸°ëŒ€\n\nclass TestMemoryOptimization(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        \n    def test_memory_usage_info(self):\n        memory_info = self.redis.get_memory_usage()\n        self.assertIn('used_memory_human', memory_info)\n        self.assertIn('maxmemory_policy', memory_info)\n        \n    def test_key_memory_usage(self):\n        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥\n        test_key = 'test:memory:usage'\n        test_data = {'data': ['x' * 100 for _ in range(100)]}\n        self.redis.redis.set(test_key, json.dumps(test_data))\n        \n        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n        usage = self.redis.get_key_memory_usage(test_key)\n        self.assertGreater(usage, 0)\n        \n        # ì •ë¦¬\n        self.redis.redis.delete(test_key)\n        \n    def test_optimize_memory(self):\n        # ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥\n        for i in range(10):\n            key = f'test:optimize:memory:{i}'\n            data = {'index': i, 'data': ['x' * 100 for _ in range(100)]}\n            self.redis.redis.set(key, json.dumps(data))\n            \n        # ìµœì í™” ì‹¤í–‰\n        result = self.redis.optimize_memory(target_mb=100)  # ë†’ì€ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í•­ìƒ ì„±ê³µí•˜ë„ë¡\n        self.assertTrue(result)\n        \n        # ì •ë¦¬\n        for i in range(10):\n            self.redis.redis.delete(f'test:optimize:memory:{i}')\n```"
          },
          {
            "id": 5,
            "title": "Redis ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ í™•ì¸ ê¸°ëŠ¥ êµ¬í˜„",
            "description": "Redis ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì , ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ì‹œê°í™” ê¸°ëŠ¥ êµ¬í˜„",
            "dependencies": [
              "21.3",
              "21.4"
            ],
            "details": "Redis ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ í™•ì¸ì„ ìœ„í•œ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:\n\n```python\n# utils/redis_monitor.py\n\nimport time\nimport logging\nimport asyncio\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom utils.redis_manager import RedisManager\nfrom utils.event_bus import EventBus\n\nclass RedisMonitor:\n    \"\"\"Redis ì„œë²„ ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ í™•ì¸ ë„êµ¬\"\"\"\n    \n    def __init__(self, redis_manager: RedisManager, event_bus: Optional[EventBus] = None):\n        self.redis = redis_manager\n        self.event_bus = event_bus\n        self.logger = logging.getLogger(__name__)\n        self.stats_history = []  # í†µê³„ ê¸°ë¡\n        self.max_history = 100  # ìµœëŒ€ ê¸°ë¡ ìˆ˜\n        self.running = False\n        self.monitor_task = None\n        \n    async def start_monitoring(self, interval_seconds: int = 60):\n        \"\"\"ëª¨ë‹ˆí„°ë§ ì‹œì‘\"\"\"\n        if self.running:\n            return\n            \n        self.running = True\n        self.monitor_task = asyncio.create_task(self._monitoring_loop(interval_seconds))\n        self.logger.info(f\"Redis monitoring started with {interval_seconds}s interval\")\n        \n    async def stop_monitoring(self):\n        \"\"\"ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\"\"\"\n        if not self.running:\n            return\n            \n        self.running = False\n        if self.monitor_task:\n            self.monitor_task.cancel()\n            try:\n                await self.monitor_task\n            except asyncio.CancelledError:\n                pass\n                \n        self.logger.info(\"Redis monitoring stopped\")\n        \n    async def _monitoring_loop(self, interval_seconds: int):\n        \"\"\"ëª¨ë‹ˆí„°ë§ ë£¨í”„\"\"\"\n        while self.running:\n            try:\n                stats = self.collect_stats()\n                self._add_to_history(stats)\n                \n                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²½ê³ \n                self._check_memory_alerts(stats)\n                \n                # ì´ë²¤íŠ¸ ë²„ìŠ¤ë¡œ ìƒíƒœ ë°œí–‰\n                if self.event_bus:\n                    self.event_bus.publish(EventBus.CHANNELS['SYSTEM_STATUS'], {\n                        'component': 'redis',\n                        'status': 'ok' if stats['is_connected'] else 'error',\n                        'memory_usage_percent': stats['memory_usage_percent'],\n                        'clients_connected': stats['clients_connected'],\n                        'timestamp': int(time.time())\n                    })\n                    \n                await asyncio.sleep(interval_seconds)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in monitoring loop: {e}\")\n                await asyncio.sleep(interval_seconds)\n                \n    def collect_stats(self) -> Dict[str, Any]:\n        \"\"\"Redis ì„œë²„ í†µê³„ ìˆ˜ì§‘\"\"\"\n        try:\n            # ì—°ê²° í™•ì¸\n            is_connected = self.redis.ping()\n            \n            if not is_connected:\n                return {\n                    'timestamp': datetime.now().isoformat(),\n                    'is_connected': False\n                }\n                \n            # ì„œë²„ ì •ë³´ ì¡°íšŒ\n            info = self.redis.get_info()\n            memory_info = self.redis.get_memory_usage()\n            \n            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°\n            used_memory = memory_info.get('used_memory', 0)\n            max_memory = memory_info.get('maxmemory', 0)\n            memory_usage_percent = (used_memory / max_memory * 100) if max_memory > 0 else 0\n            \n            # í†µê³„ êµ¬ì„±\n            stats = {\n                'timestamp': datetime.now().isoformat(),\n                'is_connected': True,\n                'redis_version': info.get('redis_version', 'unknown'),\n                'uptime_days': info.get('uptime_in_days', 0),\n                'used_memory': used_memory,\n                'used_memory_human': memory_info.get('used_memory_human', '0B'),\n                'max_memory': max_memory,\n                'max_memory_human': memory_info.get('maxmemory_human', '0B'),\n                'memory_usage_percent': memory_usage_percent,\n                'clients_connected': info.get('connected_clients', 0),\n                'total_commands': info.get('total_commands_processed', 0),\n                'keyspace_hits': info.get('keyspace_hits', 0),\n                'keyspace_misses': info.get('keyspace_misses', 0),\n                'hit_rate': self._calculate_hit_rate(info),\n                'evicted_keys': info.get('evicted_keys', 0),\n                'expired_keys': info.get('expired_keys', 0),\n                'db_keys': self._count_keys()\n            }\n            \n            return stats\n        except Exception as e:\n            self.logger.error(f\"Failed to collect Redis stats: {e}\")\n            return {\n                'timestamp': datetime.now().isoformat(),\n                'is_connected': False,\n                'error': str(e)\n            }\n            \n    def _calculate_hit_rate(self, info: Dict[str, Any]) -> float:\n        \"\"\"ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°\"\"\"\n        hits = info.get('keyspace_hits', 0)\n        misses = info.get('keyspace_misses', 0)\n        total = hits + misses\n        return (hits / total * 100) if total > 0 else 0\n        \n    def _count_keys(self) -> Dict[str, int]:\n        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ë³„ í‚¤ ê°œìˆ˜ ì¡°íšŒ\"\"\"\n        result = {}\n        try:\n            info = self.redis.get_info()\n            for key, value in info.items():\n                if key.startswith('db'):\n                    db_number = key[2:]  # 'db0' -> '0'\n                    keys_count = int(value.get('keys', 0)) if isinstance(value, dict) else 0\n                    result[db_number] = keys_count\n        except Exception as e:\n            self.logger.error(f\"Failed to count keys: {e}\")\n        return result\n        \n    def _add_to_history(self, stats: Dict[str, Any]):\n        \"\"\"í†µê³„ ê¸°ë¡ì— ì¶”ê°€\"\"\"\n        self.stats_history.append(stats)\n        if len(self.stats_history) > self.max_history:\n            self.stats_history.pop(0)  # ê°€ì¥ ì˜¤ë˜ëœ ê¸°ë¡ ì œê±°\n            \n    def _check_memory_alerts(self, stats: Dict[str, Any]):\n        \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²½ê³  í™•ì¸\"\"\"\n        if not stats.get('is_connected', False):\n            return\n            \n        memory_percent = stats.get('memory_usage_percent', 0)\n        \n        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²½ê³ \n        if memory_percent > 90:\n            message = f\"CRITICAL: Redis memory usage at {memory_percent:.1f}%\"\n            self.logger.critical(message)\n            \n            # ì´ë²¤íŠ¸ ë²„ìŠ¤ë¡œ ì•Œë¦¼ ë°œí–‰\n            if self.event_bus:\n                self.event_bus.publish(EventBus.CHANNELS['RISK_ALERT'], {\n                    'level': 'critical',\n                    'component': 'redis',\n                    'message': message,\n                    'memory_percent': memory_percent,\n                    'timestamp': int(time.time())\n                })\n                \n            # ìë™ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œë„\n            self.redis.optimize_memory()\n            \n        elif memory_percent > 75:\n            message = f\"WARNING: Redis memory usage at {memory_percent:.1f}%\"\n            self.logger.warning(message)\n            \n            # ì´ë²¤íŠ¸ ë²„ìŠ¤ë¡œ ì•Œë¦¼ ë°œí–‰\n            if self.event_bus:\n                self.event_bus.publish(EventBus.CHANNELS['RISK_ALERT'], {\n                    'level': 'warning',\n                    'component': 'redis',\n                    'message': message,\n                    'memory_percent': memory_percent,\n                    'timestamp': int(time.time())\n                })\n                \n    def get_stats_history(self, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"íŠ¹ì • ê¸°ê°„ ë™ì•ˆì˜ í†µê³„ ê¸°ë¡ ì¡°íšŒ\"\"\"\n        if not self.stats_history:\n            return []\n            \n        cutoff = datetime.now() - timedelta(hours=hours)\n        cutoff_str = cutoff.isoformat()\n        \n        return [stats for stats in self.stats_history \n                if stats.get('timestamp', '') >= cutoff_str]\n                \n    def get_memory_trend(self, hours: int = 24) -> List[Tuple[str, float]]:\n        \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì´ ì¡°íšŒ\"\"\"\n        stats = self.get_stats_history(hours)\n        return [(s['timestamp'], s.get('memory_usage_percent', 0)) for s in stats \n                if s.get('is_connected', False)]\n                \n    def get_hit_rate_trend(self, hours: int = 24) -> List[Tuple[str, float]]:\n        \"\"\"ìºì‹œ íˆíŠ¸ìœ¨ ì¶”ì´ ì¡°íšŒ\"\"\"\n        stats = self.get_stats_history(hours)\n        return [(s['timestamp'], s.get('hit_rate', 0)) for s in stats \n                if s.get('is_connected', False)]\n                \n    def get_key_distribution(self) -> Dict[str, int]:\n        \"\"\"í‚¤ íŒ¨í„´ë³„ ë¶„í¬ ì¡°íšŒ\"\"\"\n        patterns = [\n            'market:*',\n            'candles:*',\n            'indicators:*',\n            'orderbook:*',\n            'trades:*'\n        ]\n        \n        result = {}\n        for pattern in patterns:\n            keys = self.redis.get_keys_by_pattern(pattern)\n            result[pattern] = len(keys)\n            \n        return result\n        \n    def get_key_memory_distribution(self) -> Dict[str, int]:\n        \"\"\"í‚¤ íŒ¨í„´ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ\"\"\"\n        patterns = [\n            'market:*',\n            'candles:*',\n            'indicators:*',\n            'orderbook:*',\n            'trades:*'\n        ]\n        \n        result = {}\n        for pattern in patterns:\n            memory_usage = self.redis.get_pattern_memory_usage(pattern)\n            result[pattern] = sum(memory_usage.values())\n            \n        return result\n        \n    def get_status_summary(self) -> Dict[str, Any]:\n        \"\"\"Redis ìƒíƒœ ìš”ì•½ ì¡°íšŒ\"\"\"\n        stats = self.collect_stats()\n        \n        if not stats.get('is_connected', False):\n            return {\n                'status': 'disconnected',\n                'timestamp': stats.get('timestamp')\n            }\n            \n        # ìƒíƒœ í‰ê°€\n        memory_percent = stats.get('memory_usage_percent', 0)\n        if memory_percent > 90:\n            status = 'critical'\n        elif memory_percent > 75:\n            status = 'warning'\n        else:\n            status = 'ok'\n            \n        return {\n            'status': status,\n            'timestamp': stats.get('timestamp'),\n            'memory_usage_percent': memory_percent,\n            'used_memory_human': stats.get('used_memory_human'),\n            'max_memory_human': stats.get('max_memory_human'),\n            'clients_connected': stats.get('clients_connected'),\n            'hit_rate': stats.get('hit_rate'),\n            'total_keys': sum(stats.get('db_keys', {}).values()),\n            'uptime_days': stats.get('uptime_days')\n        }\n```\n\nëª¨ë‹ˆí„°ë§ ì‹œê°í™”ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ CLI ë„êµ¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:\n\n```python\n# utils/redis_cli_monitor.py\n\nimport asyncio\nimport argparse\nimport time\nfrom datetime import datetime\nfrom utils.redis_manager import RedisManager\nfrom utils.redis_monitor import RedisMonitor\n\nasync def display_stats(redis_host='localhost', redis_port=6379, interval=5):\n    \"\"\"Redis ìƒíƒœ ì •ë³´ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ í‘œì‹œ\"\"\"\n    redis = RedisManager(host=redis_host, port=redis_port)\n    monitor = RedisMonitor(redis)\n    \n    print(f\"Redis Monitor - {redis_host}:{redis_port}\")\n    print(\"-\" * 50)\n    \n    try:\n        while True:\n            stats = monitor.collect_stats()\n            \n            if not stats.get('is_connected', False):\n                print(f\"\\r[{datetime.now().strftime('%H:%M:%S')}] Connection Error: {stats.get('error', 'Unknown error')}\")\n                await asyncio.sleep(interval)\n                continue\n                \n            # í™”ë©´ ì§€ìš°ê¸° (Windows/Linux í˜¸í™˜)\n            print(\"\\033[H\\033[J\", end=\"\")\n            \n            print(f\"Redis Monitor - {redis_host}:{redis_port} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n            print(\"-\" * 50)\n            print(f\"Redis Version: {stats.get('redis_version', 'Unknown')}\")\n            print(f\"Uptime: {stats.get('uptime_days', 0)} days\")\n            print(\"-\" * 50)\n            print(f\"Memory Usage: {stats.get('used_memory_human', '0B')} / {stats.get('max_memory_human', '0B')} \"\n                  f\"({stats.get('memory_usage_percent', 0):.1f}%)\")\n            print(f\"Connected Clients: {stats.get('clients_connected', 0)}\")\n            print(f\"Commands Processed: {stats.get('total_commands', 0)}\")\n            print(f\"Hit Rate: {stats.get('hit_rate', 0):.1f}%\")\n            print(\"-\" * 50)\n            \n            # í‚¤ ë¶„í¬ í‘œì‹œ\n            key_dist = monitor.get_key_distribution()\n            print(\"Key Distribution:\")\n            for pattern, count in key_dist.items():\n                print(f\"  {pattern}: {count}\")\n                \n            print(\"-\" * 50)\n            \n            # ë©”ëª¨ë¦¬ ë¶„í¬ í‘œì‹œ\n            mem_dist = monitor.get_key_memory_distribution()\n            print(\"Memory Distribution:\")\n            for pattern, mem in mem_dist.items():\n                print(f\"  {pattern}: {mem / 1024:.1f} KB\")\n                \n            print(\"-\" * 50)\n            print(f\"Press Ctrl+C to exit. Refreshing every {interval} seconds...\")\n            \n            await asyncio.sleep(interval)\n    except KeyboardInterrupt:\n        print(\"\\nMonitoring stopped.\")\n        \ndef main():\n    parser = argparse.ArgumentParser(description='Redis Monitoring CLI')\n    parser.add_argument('--host', default='localhost', help='Redis host')\n    parser.add_argument('--port', type=int, default=6379, help='Redis port')\n    parser.add_argument('--interval', type=int, default=5, help='Refresh interval in seconds')\n    args = parser.parse_args()\n    \n    asyncio.run(display_stats(args.host, args.port, args.interval))\n    \nif __name__ == '__main__':\n    main()\n```",
            "status": "done",
            "testStrategy": "1. Redis ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸:\n```python\nimport unittest\nimport asyncio\nfrom unittest.mock import MagicMock, patch\nfrom utils.redis_manager import RedisManager\nfrom utils.redis_monitor import RedisMonitor\nfrom utils.event_bus import EventBus\n\nclass TestRedisMonitor(unittest.IsolatedAsyncioTestCase):\n    async def asyncSetUp(self):\n        self.redis = RedisManager()\n        self.event_bus = MagicMock(spec=EventBus)\n        self.monitor = RedisMonitor(self.redis, self.event_bus)\n        \n    async def test_collect_stats(self):\n        # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸\n        stats = self.monitor.collect_stats()\n        self.assertIsInstance(stats, dict)\n        self.assertIn('is_connected', stats)\n        self.assertIn('timestamp', stats)\n        \n        if stats['is_connected']:\n            self.assertIn('memory_usage_percent', stats)\n            self.assertIn('clients_connected', stats)\n            self.assertIn('hit_rate', stats)\n            \n    async def test_monitoring_loop(self):\n        # ëª¨ë‹ˆí„°ë§ ë£¨í”„ í…ŒìŠ¤íŠ¸ (ì§§ì€ ì‹œê°„ë§Œ ì‹¤í–‰)\n        await self.monitor.start_monitoring(interval_seconds=1)\n        await asyncio.sleep(2)  # ìµœì†Œ 2íšŒ ì‹¤í–‰ë˜ë„ë¡\n        await self.monitor.stop_monitoring()\n        \n        # í†µê³„ ê¸°ë¡ í™•ì¸\n        self.assertGreater(len(self.monitor.stats_history), 0)\n        \n    async def test_memory_alerts(self):\n        # ë©”ëª¨ë¦¬ ê²½ê³  í…ŒìŠ¤íŠ¸ (ëª¨ì˜ ë°ì´í„° ì‚¬ìš©)\n        with patch.object(self.monitor, 'collect_stats') as mock_collect:\n            # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ì˜\n            mock_collect.return_value = {\n                'is_connected': True,\n                'timestamp': '2023-01-01T00:00:00',\n                'memory_usage_percent': 95,\n                'used_memory_human': '95MB',\n                'max_memory_human': '100MB'\n            }\n            \n            # ëª¨ë‹ˆí„°ë§ ì‹¤í–‰\n            await self.monitor.start_monitoring(interval_seconds=1)\n            await asyncio.sleep(1.5)  # ìµœì†Œ 1íšŒ ì‹¤í–‰ë˜ë„ë¡\n            await self.monitor.stop_monitoring()\n            \n            # ì´ë²¤íŠ¸ ë°œí–‰ í™•ì¸\n            self.event_bus.publish.assert_called()\n            # RISK_ALERT ì±„ë„ì— ë°œí–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸\n            call_args = self.event_bus.publish.call_args_list\n            channel_used = False\n            for call in call_args:\n                args, _ = call\n                if args[0] == EventBus.CHANNELS['RISK_ALERT']:\n                    channel_used = True\n                    break\n            self.assertTrue(channel_used)\n            \n    async def test_get_stats_history(self):\n        # í†µê³„ ê¸°ë¡ í…ŒìŠ¤íŠ¸\n        # ëª‡ ê°œì˜ ëª¨ì˜ í†µê³„ ì¶”ê°€\n        for i in range(5):\n            self.monitor._add_to_history({\n                'timestamp': f'2023-01-01T{i:02d}:00:00',\n                'is_connected': True,\n                'memory_usage_percent': 50 + i\n            })\n            \n        # ê¸°ë¡ ì¡°íšŒ\n        history = self.monitor.get_stats_history()\n        self.assertEqual(len(history), 5)\n        \n    def test_get_key_distribution(self):\n        # í‚¤ ë¶„í¬ í…ŒìŠ¤íŠ¸\n        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±\n        for i in range(3):\n            self.redis.redis.set(f\"market:BTC{i}\", f\"value{i}\")\n            self.redis.redis.set(f\"candles:ETH{i}:1m\", f\"candle{i}\")\n            \n        # ë¶„í¬ ì¡°íšŒ\n        dist = self.monitor.get_key_distribution()\n        self.assertIn('market:*', dist)\n        self.assertIn('candles:*', dist)\n        self.assertGreaterEqual(dist['market:*'], 3)\n        self.assertGreaterEqual(dist['candles:*'], 3)\n        \n        # ì •ë¦¬\n        for i in range(3):\n            self.redis.redis.delete(f\"market:BTC{i}\")\n            self.redis.redis.delete(f\"candles:ETH{i}:1m\")\n            \n    def test_get_status_summary(self):\n        # ìƒíƒœ ìš”ì•½ í…ŒìŠ¤íŠ¸\n        summary = self.monitor.get_status_summary()\n        self.assertIn('status', summary)\n        self.assertIn('timestamp', summary)\n        \n        if summary['status'] != 'disconnected':\n            self.assertIn('memory_usage_percent', summary)\n            self.assertIn('used_memory_human', summary)\n\n# CLI ëª¨ë‹ˆí„°ë§ ë„êµ¬ í…ŒìŠ¤íŠ¸ (ìˆ˜ë™ í…ŒìŠ¤íŠ¸ í•„ìš”)\n# python -m utils.redis_cli_monitor --host localhost --port 6379 --interval 2\n```"
          }
        ]
      },
      {
        "id": 22,
        "title": "í•œêµ­íˆ¬ìì¦ê¶Œ API ì—°ë™ ë° ì¸ì¦ ì‹œìŠ¤í…œ",
        "description": "í•œêµ­íˆ¬ìì¦ê¶Œ API ì—°ë™ì„ ìœ„í•œ ì¸ì¦ ì‹œìŠ¤í…œ ë° ê¸°ë³¸ API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„",
        "details": "1. í•œêµ­íˆ¬ìì¦ê¶Œ Open API ê³„ì • ì„¤ì • ë° API í‚¤ ë°œê¸‰\n2. API ì¸ì¦ ëª¨ë“ˆ êµ¬í˜„ (utils/kis_auth.py):\n   - OAuth í† í° ë°œê¸‰ ë° ê°±ì‹ \n   - API í‚¤ ì•ˆì „í•œ ì €ì¥ ë° ê´€ë¦¬ (.env íŒŒì¼ í™œìš©)\n3. ê¸°ë³¸ API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ êµ¬í˜„ (collectors/kis_client.py):\n```python\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        self.mock = mock  # ëª¨ì˜íˆ¬ì ì—¬ë¶€\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        self.token = None\n        self.token_expired_at = None\n        \n    async def get_access_token(self):\n        # í† í° ë°œê¸‰ ë¡œì§\n        \n    async def refresh_token_if_needed(self):\n        # í† í° ë§Œë£Œ í™•ì¸ ë° ê°±ì‹  ë¡œì§\n        \n    async def request(self, method, endpoint, params=None, data=None):\n        # API ìš”ì²­ ê³µí†µ ë¡œì§ (ì¬ì‹œë„, ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n```\n4. API í˜¸ì¶œ ì œí•œ ê´€ë¦¬ (Rate Limiting):\n   - ìš”ì²­ ê°„ê²© ì¡°ì ˆ\n   - ì¼ì¼ API í˜¸ì¶œ íšŸìˆ˜ ì¶”ì \n5. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„\n6. ëª¨ì˜íˆ¬ìì™€ ì‹¤ì „íˆ¬ì ëª¨ë“œ ì „í™˜ ê¸°ëŠ¥\n7. API ì‘ë‹µ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§\n8. ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ ë˜í¼ í•¨ìˆ˜ êµ¬í˜„:\n   - ê³„ì¢Œ ì •ë³´ ì¡°íšŒ\n   - ì¢…ëª© ì •ë³´ ì¡°íšŒ\n   - ì£¼ë¬¸ ê´€ë ¨ ê¸°ëŠ¥",
        "testStrategy": "1. API ì¸ì¦ ë° í† í° ë°œê¸‰ í…ŒìŠ¤íŠ¸\n2. í† í° ê°±ì‹  ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸\n3. ê¸°ë³¸ API ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ í…ŒìŠ¤íŠ¸\n4. ì—ëŸ¬ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ ë° ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸\n5. Rate Limiting ì¤€ìˆ˜ ì—¬ë¶€ í…ŒìŠ¤íŠ¸\n6. ëª¨ì˜íˆ¬ì ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸\n7. ë¡œê¹… ì‹œìŠ¤í…œ ê²€ì¦\n8. ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸",
        "priority": "high",
        "dependencies": [
          19
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "í•œêµ­íˆ¬ìì¦ê¶Œ API ê³„ì • ì„¤ì • ë° í™˜ê²½ êµ¬ì„±",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ Open API ê³„ì • ìƒì„±, API í‚¤ ë°œê¸‰, ê·¸ë¦¬ê³  í”„ë¡œì íŠ¸ì—ì„œ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í™˜ê²½ ì„¤ì • êµ¬í˜„",
            "dependencies": [],
            "details": "1. í•œêµ­íˆ¬ìì¦ê¶Œ í™ˆí˜ì´ì§€ì—ì„œ Open API ì„œë¹„ìŠ¤ ì‹ ì²­ ë° ê³„ì • ìƒì„±\n2. ì‹¤ì „íˆ¬ì ë° ëª¨ì˜íˆ¬ììš© API í‚¤(appkey, appsecret) ë°œê¸‰\n3. .env íŒŒì¼ ìƒì„± ë° API í‚¤ ì €ì¥ êµ¬ì¡° ì„¤ê³„:\n```\nKIS_APPKEY=ë°œê¸‰ë°›ì€ì•±í‚¤\nKIS_APPSECRET=ë°œê¸‰ë°›ì€ì•±ì‹œí¬ë¦¿\nKIS_ACCOUNT_NO=ê³„ì¢Œë²ˆí˜¸\nKIS_MOCK=True  # ëª¨ì˜íˆ¬ì ì—¬ë¶€\n```\n4. .env íŒŒì¼ ë¡œë“œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ êµ¬í˜„ (utils/config.py):\n```python\nimport os\nfrom dotenv import load_dotenv\n\ndef load_config():\n    load_dotenv()\n    return {\n        'kis_appkey': os.getenv('KIS_APPKEY'),\n        'kis_appsecret': os.getenv('KIS_APPSECRET'),\n        'kis_account_no': os.getenv('KIS_ACCOUNT_NO'),\n        'kis_mock': os.getenv('KIS_MOCK', 'True').lower() == 'true'\n    }\n```\n5. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: python-dotenv, aiohttp, cryptography",
            "status": "done",
            "testStrategy": "1. .env íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸\n2. í™˜ê²½ ë³€ìˆ˜ ì ‘ê·¼ í…ŒìŠ¤íŠ¸\n3. ëª¨ì˜íˆ¬ì/ì‹¤ì „íˆ¬ì ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸\n4. API í‚¤ ì•”í˜¸í™” ì €ì¥ ë° ë³µí˜¸í™” í…ŒìŠ¤íŠ¸"
          },
          {
            "id": 2,
            "title": "API ì¸ì¦ ëª¨ë“ˆ êµ¬í˜„",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ API ì¸ì¦ì„ ìœ„í•œ OAuth í† í° ë°œê¸‰, ê°±ì‹ , ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì¸ì¦ ëª¨ë“ˆ êµ¬í˜„",
            "dependencies": [
              "22.1"
            ],
            "details": "1. utils/kis_auth.py íŒŒì¼ ìƒì„± ë° KISAuth í´ë˜ìŠ¤ êµ¬í˜„:\n```python\nimport time\nimport hashlib\nimport json\nimport aiohttp\nfrom datetime import datetime, timedelta\n\nclass KISAuth:\n    def __init__(self, api_key, api_secret, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.mock = mock\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        # ëª¨ì˜íˆ¬ì ì‚¬ìš© ì‹œ URL ë³€ê²½\n        if mock:\n            self.base_url = \"https://openapivts.koreainvestment.com:29443\"\n        self.token = None\n        self.token_expired_at = None\n        \n    async def issue_access_token(self):\n        \"\"\"OAuth í† í° ë°œê¸‰\"\"\"\n        endpoint = \"/oauth2/tokenP\"\n        url = f\"{self.base_url}{endpoint}\"\n        \n        # HMAC ê¸°ë°˜ ì‹œê·¸ë‹ˆì²˜ ìƒì„±\n        timestamp = str(int(time.time() * 1000))\n        message = timestamp + self.api_key + self.api_secret\n        hash_obj = hashlib.sha256(message.encode('utf-8'))\n        hashed = hash_obj.hexdigest()\n        \n        headers = {\n            \"content-type\": \"application/json\"\n        }\n        body = {\n            \"grant_type\": \"client_credentials\",\n            \"appkey\": self.api_key,\n            \"appsecret\": self.api_secret\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(url, headers=headers, json=body) as response:\n                if response.status == 200:\n                    result = await response.json()\n                    self.token = result.get('access_token')\n                    expires_in = result.get('expires_in', 86400)  # ê¸°ë³¸ 24ì‹œê°„\n                    self.token_expired_at = datetime.now() + timedelta(seconds=expires_in - 300)  # 5ë¶„ ì—¬ìœ \n                    return self.token\n                else:\n                    error_text = await response.text()\n                    raise Exception(f\"Token issue failed: {response.status} - {error_text}\")\n    \n    async def ensure_token(self):\n        \"\"\"í† í°ì´ ì—†ê±°ë‚˜ ë§Œë£Œ ì˜ˆì •ì´ë©´ ê°±ì‹ \"\"\"\n        if self.token is None or self.token_expired_at is None or datetime.now() >= self.token_expired_at:\n            await self.issue_access_token()\n        return self.token\n        \n    def get_auth_headers(self):\n        \"\"\"ì¸ì¦ í—¤ë” ë°˜í™˜\"\"\"\n        if not self.token:\n            raise Exception(\"Token not issued yet. Call ensure_token() first.\")\n        return {\n            \"Authorization\": f\"Bearer {self.token}\",\n            \"appkey\": self.api_key,\n            \"appsecret\": self.api_secret,\n            \"tr_id\": \"FHKST01010100\"  # ê¸°ë³¸ TR ID, ì‹¤ì œ ìš”ì²­ ì‹œ ì˜¤ë²„ë¼ì´ë“œ í•„ìš”\n        }\n```\n2. í† í° ì €ì¥ ë° ë³µì› ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€ (ì„ íƒì ):\n   - í† í° íŒŒì¼ ì €ì¥ ê¸°ëŠ¥\n   - ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘ ì‹œ í† í° ë³µì› ê¸°ëŠ¥",
            "status": "done",
            "testStrategy": "1. í† í° ë°œê¸‰ ì„±ê³µ í…ŒìŠ¤íŠ¸\n2. í† í° ë§Œë£Œ ì‹œ ìë™ ê°±ì‹  í…ŒìŠ¤íŠ¸\n3. ì¸ì¦ í—¤ë” ìƒì„± í…ŒìŠ¤íŠ¸\n4. ì˜ëª»ëœ API í‚¤ë¡œ ì¸ì¦ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸\n5. ëª¨ì˜íˆ¬ì/ì‹¤ì „íˆ¬ì URL ì „í™˜ í…ŒìŠ¤íŠ¸\n6. ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"
          },
          {
            "id": 3,
            "title": "ê¸°ë³¸ API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ API í˜¸ì¶œì„ ìœ„í•œ ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ êµ¬í˜„ ë° ê³µí†µ ìš”ì²­ ì²˜ë¦¬ ë¡œì§ ê°œë°œ",
            "dependencies": [
              "22.2"
            ],
            "details": "1. collectors/kis_client.py íŒŒì¼ ìƒì„± ë° KISClient í´ë˜ìŠ¤ êµ¬í˜„:\n```python\nimport json\nimport time\nimport logging\nimport asyncio\nimport aiohttp\nfrom datetime import datetime\nfrom utils.kis_auth import KISAuth\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        self.mock = mock  # ëª¨ì˜íˆ¬ì ì—¬ë¶€\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        if mock:\n            self.base_url = \"https://openapivts.koreainvestment.com:29443\"\n        self.auth = KISAuth(api_key, api_secret, mock)\n        self.logger = logging.getLogger(\"KISClient\")\n        self.request_times = []  # Rate limiting ê´€ë¦¬ìš©\n        self.max_requests_per_sec = 5  # ì´ˆë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜\n        self.daily_request_count = 0  # ì¼ì¼ ìš”ì²­ ìˆ˜ ì¶”ì \n        self.last_day = datetime.now().day\n        \n    async def _manage_rate_limit(self):\n        \"\"\"API í˜¸ì¶œ ì†ë„ ì œí•œ ê´€ë¦¬\"\"\"\n        now = time.time()\n        # 1ì´ˆ ì´ë‚´ ìš”ì²­ë“¤ë§Œ ìœ ì§€\n        self.request_times = [t for t in self.request_times if now - t < 1.0]\n        \n        # í˜„ì¬ ì´ˆë‹¹ ìš”ì²­ ìˆ˜ê°€ ì œí•œì— ë„ë‹¬í–ˆìœ¼ë©´ ëŒ€ê¸°\n        if len(self.request_times) >= self.max_requests_per_sec:\n            wait_time = 1.0 - (now - self.request_times[0])\n            if wait_time > 0:\n                self.logger.debug(f\"Rate limit reached, waiting {wait_time:.2f}s\")\n                await asyncio.sleep(wait_time)\n        \n        # ì¼ì¼ ìš”ì²­ ìˆ˜ ê´€ë¦¬\n        current_day = datetime.now().day\n        if current_day != self.last_day:\n            self.daily_request_count = 0\n            self.last_day = current_day\n        self.daily_request_count += 1\n        \n        # í˜„ì¬ ì‹œê°„ ê¸°ë¡\n        self.request_times.append(time.time())\n    \n    async def request(self, method, endpoint, tr_id=None, params=None, data=None, headers=None, retry_count=3):\n        \"\"\"API ìš”ì²­ ê³µí†µ ë¡œì§ (ì¬ì‹œë„, ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\"\"\"\n        await self._manage_rate_limit()\n        \n        # í† í° í™•ì¸ ë° ê°±ì‹ \n        await self.auth.ensure_token()\n        \n        # ê¸°ë³¸ í—¤ë” ì„¤ì •\n        request_headers = self.auth.get_auth_headers()\n        if tr_id:\n            request_headers[\"tr_id\"] = tr_id\n        if headers:\n            request_headers.update(headers)\n        \n        url = f\"{self.base_url}{endpoint}\"\n        \n        for attempt in range(retry_count):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    request_kwargs = {\n                        \"headers\": request_headers\n                    }\n                    \n                    if params:\n                        request_kwargs[\"params\"] = params\n                    \n                    if data:\n                        request_kwargs[\"json\"] = data\n                    \n                    self.logger.debug(f\"Requesting {method} {url}\")\n                    async with session.request(method, url, **request_kwargs) as response:\n                        response_text = await response.text()\n                        \n                        # ì‘ë‹µ ë¡œê¹…\n                        self.logger.debug(f\"Response {response.status}: {response_text[:200]}...\")\n                        \n                        if response.status == 200:\n                            try:\n                                return await response.json()\n                            except json.JSONDecodeError:\n                                return response_text\n                        elif response.status == 401:  # ì¸ì¦ ì˜¤ë¥˜\n                            # í† í° ì¬ë°œê¸‰ ì‹œë„\n                            self.logger.warning(\"Authentication error, refreshing token\")\n                            await self.auth.issue_access_token()\n                            if attempt < retry_count - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„\n                                continue\n                        \n                        # ê¸°íƒ€ ì˜¤ë¥˜\n                        error_msg = f\"API request failed: {response.status} - {response_text}\"\n                        self.logger.error(error_msg)\n                        raise Exception(error_msg)\n            except aiohttp.ClientError as e:\n                if attempt < retry_count - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„\n                    wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„\n                    self.logger.warning(f\"Request failed: {str(e)}. Retrying in {wait_time}s\")\n                    await asyncio.sleep(wait_time)\n                else:\n                    self.logger.error(f\"Request failed after {retry_count} attempts: {str(e)}\")\n                    raise\n        \n        raise Exception(f\"Request failed after {retry_count} attempts\")\n```\n2. ë¡œê¹… ì„¤ì • ì¶”ê°€ (utils/logging_config.py):\n```python\nimport logging\nimport sys\nfrom logging.handlers import RotatingFileHandler\nimport os\n\ndef setup_logging(log_dir=\"logs\"):\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n        \n    # ë¡œê±° ì„¤ì •\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    \n    # ì½˜ì†” í•¸ë“¤ëŸ¬\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.INFO)\n    console_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    console_handler.setFormatter(console_format)\n    \n    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¼ë°˜ ë¡œê·¸)\n    file_handler = RotatingFileHandler(\n        os.path.join(log_dir, 'app.log'), \n        maxBytes=10*1024*1024,  # 10MB\n        backupCount=5\n    )\n    file_handler.setLevel(logging.DEBUG)\n    file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(file_format)\n    \n    # API ìš”ì²­ ì „ìš© ë¡œê·¸ íŒŒì¼\n    api_file_handler = RotatingFileHandler(\n        os.path.join(log_dir, 'api_requests.log'), \n        maxBytes=10*1024*1024,  # 10MB\n        backupCount=5\n    )\n    api_file_handler.setLevel(logging.DEBUG)\n    api_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    api_file_handler.setFormatter(api_format)\n    \n    # API ë¡œê±° ì„¤ì •\n    api_logger = logging.getLogger('KISClient')\n    api_logger.addHandler(api_file_handler)\n    \n    # ê¸°ë³¸ ë¡œê±°ì— í•¸ë“¤ëŸ¬ ì¶”ê°€\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n```",
            "status": "done",
            "testStrategy": "1. ê¸°ë³¸ API ìš”ì²­ ì„±ê³µ í…ŒìŠ¤íŠ¸\n2. ì¸ì¦ ì˜¤ë¥˜ ì‹œ í† í° ìë™ ê°±ì‹  í…ŒìŠ¤íŠ¸\n3. ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸\n4. Rate limiting ì¤€ìˆ˜ í…ŒìŠ¤íŠ¸\n5. ì¼ì¼ ìš”ì²­ ìˆ˜ ì¶”ì  í…ŒìŠ¤íŠ¸\n6. ë¡œê¹… ì‹œìŠ¤í…œ ì‘ë™ í…ŒìŠ¤íŠ¸\n7. ë‹¤ì–‘í•œ HTTP ë©”ì†Œë“œ(GET, POST, PUT, DELETE) í…ŒìŠ¤íŠ¸"
          },
          {
            "id": 4,
            "title": "ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ ë˜í¼ í•¨ìˆ˜ êµ¬í˜„",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ APIì˜ ì£¼ìš” ê¸°ëŠ¥(ê³„ì¢Œ ì •ë³´, ì¢…ëª© ì •ë³´, ì£¼ë¬¸ ê¸°ëŠ¥ ë“±)ì— ëŒ€í•œ ë˜í¼ í•¨ìˆ˜ êµ¬í˜„",
            "dependencies": [
              "22.3"
            ],
            "details": "1. KISClient í´ë˜ìŠ¤ì— ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ ë˜í¼ í•¨ìˆ˜ ì¶”ê°€:\n```python\n# collectors/kis_client.pyì— ë‹¤ìŒ ë©”ì†Œë“œ ì¶”ê°€\n\n# ê³„ì¢Œ ì •ë³´ ì¡°íšŒ\nasync def get_account_info(self):\n    \"\"\"ê³„ì¢Œ ì •ë³´ ì¡°íšŒ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/inquire-balance\"\n    tr_id = \"TTTC8434R\" if not self.mock else \"VTTC8434R\"  # ì‹¤ì „/ëª¨ì˜ TR ID êµ¬ë¶„\n    \n    params = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"AFHR_FLPR_YN\": \"N\",\n        \"OFL_YN\": \"N\",\n        \"INQR_DVSN\": \"01\",\n        \"UNPR_DVSN\": \"01\",\n        \"FUND_STTL_ICLD_YN\": \"N\",\n        \"FNCG_AMT_AUTO_RDPT_YN\": \"N\",\n        \"PRCS_DVSN\": \"01\",\n        \"CTX_AREA_FK100\": \"\",\n        \"CTX_AREA_NK100\": \"\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# ì¢…ëª© ì •ë³´ ì¡°íšŒ\nasync def get_stock_info(self, stock_code):\n    \"\"\"ì¢…ëª© ê¸°ë³¸ ì •ë³´ ì¡°íšŒ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-price\"\n    tr_id = \"FHKST01010100\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# ì£¼ì‹ í˜„ì¬ê°€ ì¡°íšŒ\nasync def get_stock_price(self, stock_code):\n    \"\"\"ì¢…ëª© í˜„ì¬ê°€ ì¡°íšŒ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-price\"\n    tr_id = \"FHKST01010100\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# ì£¼ì‹ í˜¸ê°€ ì¡°íšŒ\nasync def get_stock_orderbook(self, stock_code):\n    \"\"\"ì¢…ëª© í˜¸ê°€ ì •ë³´ ì¡°íšŒ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-asking-price-exp-ccn\"\n    tr_id = \"FHKST01010200\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# ì£¼ì‹ ì¼ë´‰ ì¡°íšŒ\nasync def get_stock_daily_chart(self, stock_code, start_date=None, end_date=None, period=None):\n    \"\"\"ì¢…ëª© ì¼ë´‰ ì°¨íŠ¸ ì¡°íšŒ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-daily-price\"\n    tr_id = \"FHKST01010400\"\n    \n    # ê¸°ë³¸ê°’ ì„¤ì •\n    if not end_date:\n        end_date = datetime.now().strftime(\"%Y%m%d\")\n    \n    if not start_date and period:\n        # periodì¼ ì „ ë°ì´í„°ë¶€í„° ì¡°íšŒ\n        start_date = (datetime.now() - timedelta(days=period)).strftime(\"%Y%m%d\")\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code,\n        \"FID_PERIOD_DIV_CODE\": \"D\",\n        \"FID_ORG_ADJ_PRC\": \"1\",\n        \"FID_INPUT_DATE_1\": start_date if start_date else \"\",\n        \"FID_INPUT_DATE_2\": end_date,\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# ì£¼ì‹ ì£¼ë¬¸\nasync def place_order(self, stock_code, order_type, quantity, price=0, order_division=\"00\"):\n    \"\"\"ì£¼ì‹ ì£¼ë¬¸ ì‹¤í–‰\n    \n    Args:\n        stock_code (str): ì¢…ëª©ì½”ë“œ\n        order_type (str): ì£¼ë¬¸ íƒ€ì… (01: ë§¤ë„, 02: ë§¤ìˆ˜)\n        quantity (int): ì£¼ë¬¸ ìˆ˜ëŸ‰\n        price (int, optional): ì£¼ë¬¸ ê°€ê²©. ì‹œì¥ê°€ ì£¼ë¬¸ ì‹œ 0.\n        order_division (str, optional): ì£¼ë¬¸êµ¬ë¶„ (00: ì§€ì •ê°€, 01: ì‹œì¥ê°€)\n    \"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-cash\"\n    \n    # ì‹¤ì „/ëª¨ì˜íˆ¬ì êµ¬ë¶„\n    tr_id = \"\"\n    if order_type == \"01\":  # ë§¤ë„\n        tr_id = \"TTTC0801U\" if not self.mock else \"VTTC0801U\"\n    else:  # ë§¤ìˆ˜\n        tr_id = \"TTTC0802U\" if not self.mock else \"VTTC0802U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"PDNO\": stock_code,\n        \"ORD_DVSN\": order_division,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": str(price),\n        \"CTAC_TLNO\": \"\",  # ì—°ë½ì²˜\n        \"SLL_BUY_DVSN_CD\": order_type,\n        \"ALGO_NO\": \"\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n\n# ì£¼ë¬¸ ì·¨ì†Œ/ì •ì •\nasync def cancel_order(self, order_no, stock_code, quantity):\n    \"\"\"ì£¼ë¬¸ ì·¨ì†Œ\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-rvsecncl\"\n    tr_id = \"TTTC0803U\" if not self.mock else \"VTTC0803U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"KRX_FWDG_ORD_ORGNO\": \"\",  # í•œêµ­ê±°ë˜ì†Œ ì£¼ë¬¸ì¡°ì§ë²ˆí˜¸\n        \"ORGN_ODNO\": order_no,  # ì›ì£¼ë¬¸ë²ˆí˜¸\n        \"ORD_DVSN\": \"00\",  # ì£¼ë¬¸êµ¬ë¶„(ì·¨ì†Œ)\n        \"RVSE_CNCL_DVSN_CD\": \"02\",  # ì •ì •ì·¨ì†Œêµ¬ë¶„ì½”ë“œ(02: ì·¨ì†Œ)\n        \"PDNO\": stock_code,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": \"0\",\n        \"CTAC_TLNO\": \"\",\n        \"RSVN_ORD_YN\": \"N\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n\n# ì£¼ë¬¸ ì •ì •\nasync def modify_order(self, order_no, stock_code, quantity, price):\n    \"\"\"ì£¼ë¬¸ ì •ì •\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-rvsecncl\"\n    tr_id = \"TTTC0803U\" if not self.mock else \"VTTC0803U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"KRX_FWDG_ORD_ORGNO\": \"\",\n        \"ORGN_ODNO\": order_no,\n        \"ORD_DVSN\": \"00\",\n        \"RVSE_CNCL_DVSN_CD\": \"01\",  # ì •ì •ì·¨ì†Œêµ¬ë¶„ì½”ë“œ(01: ì •ì •)\n        \"PDNO\": stock_code,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": str(price),\n        \"CTAC_TLNO\": \"\",\n        \"RSVN_ORD_YN\": \"N\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n```\n\n2. ë˜í¼ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (examples/kis_api_example.py):\n```python\nimport asyncio\nimport sys\nimport os\n\n# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.config import load_config\nfrom collectors.kis_client import KISClient\nfrom utils.logging_config import setup_logging\n\nasync def main():\n    # ë¡œê¹… ì„¤ì •\n    logger = setup_logging()\n    \n    # ì„¤ì • ë¡œë“œ\n    config = load_config()\n    \n    # KIS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n    client = KISClient(\n        api_key=config['kis_appkey'],\n        api_secret=config['kis_appsecret'],\n        account_no=config['kis_account_no'],\n        mock=config['kis_mock']\n    )\n    \n    # ê³„ì¢Œ ì •ë³´ ì¡°íšŒ\n    account_info = await client.get_account_info()\n    print(\"\\nê³„ì¢Œ ì •ë³´:\")\n    print(account_info)\n    \n    # ì‚¼ì„±ì „ì ì¢…ëª© ì •ë³´ ì¡°íšŒ\n    stock_info = await client.get_stock_info(\"005930\")\n    print(\"\\nì‚¼ì„±ì „ì ì¢…ëª© ì •ë³´:\")\n    print(stock_info)\n    \n    # ì‚¼ì„±ì „ì í˜¸ê°€ ì •ë³´ ì¡°íšŒ\n    orderbook = await client.get_stock_orderbook(\"005930\")\n    print(\"\\nì‚¼ì„±ì „ì í˜¸ê°€ ì •ë³´:\")\n    print(orderbook)\n    \n    # ì‚¼ì„±ì „ì ì¼ë´‰ ì¡°íšŒ (ìµœê·¼ 10ì¼)\n    daily_chart = await client.get_stock_daily_chart(\"005930\", period=10)\n    print(\"\\nì‚¼ì„±ì „ì ì¼ë´‰ ì°¨íŠ¸ (ìµœê·¼ 10ì¼):\")\n    print(daily_chart)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```",
            "status": "done",
            "testStrategy": "1. ê° ë˜í¼ í•¨ìˆ˜ ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸\n2. ê³„ì¢Œ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸\n3. ì¢…ëª© ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸\n4. í˜¸ê°€ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸\n5. ì¼ë´‰ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n6. ì£¼ë¬¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ëª¨ì˜íˆ¬ì í™˜ê²½ì—ì„œ)\n7. ì£¼ë¬¸ ì·¨ì†Œ/ì •ì • í…ŒìŠ¤íŠ¸ (ëª¨ì˜íˆ¬ì í™˜ê²½ì—ì„œ)\n8. ë‹¤ì–‘í•œ ì…ë ¥ê°’ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"
          },
          {
            "id": 5,
            "title": "ëª¨ì˜íˆ¬ìì™€ ì‹¤ì „íˆ¬ì ëª¨ë“œ ì „í™˜ ê¸°ëŠ¥ êµ¬í˜„",
            "description": "ëª¨ì˜íˆ¬ìì™€ ì‹¤ì „íˆ¬ì ëª¨ë“œ ê°„ ì•ˆì „í•œ ì „í™˜ ê¸°ëŠ¥ ë° ëª¨ë“œë³„ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "dependencies": [
              "22.3",
              "22.4"
            ],
            "details": "1. ëª¨ë“œ ì „í™˜ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„ (utils/trading_mode.py):\n```python\nimport os\nimport json\nimport logging\nfrom pathlib import Path\n\nclass TradingModeManager:\n    def __init__(self, config_path=\"config/trading_mode.json\"):\n        self.logger = logging.getLogger(\"TradingModeManager\")\n        self.config_path = Path(config_path)\n        self.config = self._load_config()\n        \n    def _load_config(self):\n        \"\"\"ì„¤ì • íŒŒì¼ ë¡œë“œ\"\"\"\n        if not self.config_path.exists():\n            # ê¸°ë³¸ ì„¤ì • ìƒì„±\n            default_config = {\n                \"mode\": \"mock\",  # ê¸°ë³¸ê°’ì€ ëª¨ì˜íˆ¬ì\n                \"mock\": {\n                    \"base_url\": \"https://openapivts.koreainvestment.com:29443\",\n                    \"tr_id_prefix\": \"V\"\n                },\n                \"real\": {\n                    \"base_url\": \"https://openapi.koreainvestment.com:9443\",\n                    \"tr_id_prefix\": \"T\"\n                },\n                \"safety_checks\": {\n                    \"confirm_real_mode\": True,\n                    \"max_order_amount\": 1000000,  # ì‹¤ì „ ëª¨ë“œ ìµœëŒ€ ì£¼ë¬¸ ê¸ˆì•¡\n                    \"max_daily_orders\": 20  # ì‹¤ì „ ëª¨ë“œ ì¼ì¼ ìµœëŒ€ ì£¼ë¬¸ ìˆ˜\n                }\n            }\n            \n            # ì„¤ì • ë””ë ‰í† ë¦¬ ìƒì„±\n            os.makedirs(self.config_path.parent, exist_ok=True)\n            \n            # ì„¤ì • íŒŒì¼ ì €ì¥\n            with open(self.config_path, 'w', encoding='utf-8') as f:\n                json.dump(default_config, f, indent=2, ensure_ascii=False)\n                \n            return default_config\n        \n        # ê¸°ì¡´ ì„¤ì • íŒŒì¼ ë¡œë“œ\n        try:\n            with open(self.config_path, 'r', encoding='utf-8') as f:\n                return json.load(f)\n        except Exception as e:\n            self.logger.error(f\"Failed to load config: {str(e)}\")\n            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì„¤ì • ë°˜í™˜\n            return {\"mode\": \"mock\"}\n    \n    def save_config(self):\n        \"\"\"ì„¤ì • íŒŒì¼ ì €ì¥\"\"\"\n        try:\n            with open(self.config_path, 'w', encoding='utf-8') as f:\n                json.dump(self.config, f, indent=2, ensure_ascii=False)\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to save config: {str(e)}\")\n            return False\n    \n    def get_current_mode(self):\n        \"\"\"í˜„ì¬ ê±°ë˜ ëª¨ë“œ ë°˜í™˜\"\"\"\n        return self.config.get(\"mode\", \"mock\")\n    \n    def is_mock_mode(self):\n        \"\"\"ëª¨ì˜íˆ¬ì ëª¨ë“œì¸ì§€ í™•ì¸\"\"\"\n        return self.get_current_mode() == \"mock\"\n    \n    def switch_to_mock_mode(self):\n        \"\"\"ëª¨ì˜íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\"\"\"\n        self.config[\"mode\"] = \"mock\"\n        success = self.save_config()\n        if success:\n            self.logger.info(\"Switched to MOCK trading mode\")\n        return success\n    \n    def switch_to_real_mode(self, force=False):\n        \"\"\"ì‹¤ì „íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\"\"\"\n        if not force and self.config.get(\"safety_checks\", {}).get(\"confirm_real_mode\", True):\n            confirmation = input(\"WARNING: You are switching to REAL trading mode. Type 'CONFIRM' to proceed: \")\n            if confirmation != \"CONFIRM\":\n                self.logger.warning(\"Real mode switch cancelled\")\n                return False\n        \n        self.config[\"mode\"] = \"real\"\n        success = self.save_config()\n        if success:\n            self.logger.warning(\"Switched to REAL trading mode\")\n        return success\n    \n    def get_base_url(self):\n        \"\"\"í˜„ì¬ ëª¨ë“œì— ë§ëŠ” base_url ë°˜í™˜\"\"\"\n        mode = self.get_current_mode()\n        return self.config.get(mode, {}).get(\"base_url\")\n    \n    def get_tr_id_prefix(self):\n        \"\"\"í˜„ì¬ ëª¨ë“œì— ë§ëŠ” TR ID ì ‘ë‘ì‚¬ ë°˜í™˜\"\"\"\n        mode = self.get_current_mode()\n        return self.config.get(mode, {}).get(\"tr_id_prefix\")\n    \n    def get_safety_settings(self):\n        \"\"\"ì•ˆì „ ì„¤ì • ë°˜í™˜\"\"\"\n        return self.config.get(\"safety_checks\", {})\n```\n\n2. KISClient í´ë˜ìŠ¤ ìˆ˜ì •í•˜ì—¬ TradingModeManager í†µí•©:\n```python\n# collectors/kis_client.py ìˆ˜ì •\n\nfrom utils.trading_mode import TradingModeManager\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=None):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        \n        # ëª¨ë“œ ê´€ë¦¬ì ì´ˆê¸°í™”\n        self.mode_manager = TradingModeManager()\n        \n        # mock íŒŒë¼ë¯¸í„°ê°€ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœ ê²½ìš° ëª¨ë“œ ì„¤ì •\n        if mock is not None:\n            if mock:\n                self.mode_manager.switch_to_mock_mode()\n            else:\n                self.mode_manager.switch_to_real_mode(force=True)\n        \n        # í˜„ì¬ ëª¨ë“œì— ë”°ë¥¸ ì„¤ì •\n        self.mock = self.mode_manager.is_mock_mode()\n        self.base_url = self.mode_manager.get_base_url()\n        self.auth = KISAuth(api_key, api_secret, self.mock)\n        \n        # ë‚˜ë¨¸ì§€ ì´ˆê¸°í™” ì½”ë“œ...\n    \n    def switch_to_mock_mode(self):\n        \"\"\"ëª¨ì˜íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\"\"\"\n        if self.mode_manager.switch_to_mock_mode():\n            self.mock = True\n            self.base_url = self.mode_manager.get_base_url()\n            self.auth = KISAuth(self.api_key, self.api_secret, self.mock)\n            return True\n        return False\n    \n    def switch_to_real_mode(self):\n        \"\"\"ì‹¤ì „íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\"\"\"\n        if self.mode_manager.switch_to_real_mode():\n            self.mock = False\n            self.base_url = self.mode_manager.get_base_url()\n            self.auth = KISAuth(self.api_key, self.api_secret, self.mock)\n            return True\n        return False\n    \n    # TR ID ìƒì„± í—¬í¼ ë©”ì†Œë“œ ì¶”ê°€\n    def _get_tr_id(self, base_id):\n        \"\"\"í˜„ì¬ ëª¨ë“œì— ë§ëŠ” TR ID ìƒì„±\"\"\"\n        prefix = self.mode_manager.get_tr_id_prefix()\n        return f\"{prefix}{base_id}\"\n    \n    # ê¸°ì¡´ ë©”ì†Œë“œë“¤ì—ì„œ í•˜ë“œì½”ë”©ëœ TR ID ëŒ€ì‹  _get_tr_id ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •\n    # ì˜ˆ: tr_id = self._get_tr_id(\"TTC0802U\")\n```\n\n3. ëª¨ë“œ ì „í™˜ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ (examples/switch_trading_mode.py):\n```python\nimport asyncio\nimport sys\nimport os\n\n# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.config import load_config\nfrom collectors.kis_client import KISClient\nfrom utils.logging_config import setup_logging\n\nasync def main():\n    # ë¡œê¹… ì„¤ì •\n    logger = setup_logging()\n    \n    # ì„¤ì • ë¡œë“œ\n    config = load_config()\n    \n    # KIS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n    client = KISClient(\n        api_key=config['kis_appkey'],\n        api_secret=config['kis_appsecret'],\n        account_no=config['kis_account_no']\n    )\n    \n    # í˜„ì¬ ëª¨ë“œ ì¶œë ¥\n    print(f\"í˜„ì¬ ê±°ë˜ ëª¨ë“œ: {'ëª¨ì˜íˆ¬ì' if client.mock else 'ì‹¤ì „íˆ¬ì'}\")\n    \n    # ëª¨ë“œ ì „í™˜ ë©”ë‰´\n    print(\"\\n1. ëª¨ì˜íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\")\n    print(\"2. ì‹¤ì „íˆ¬ì ëª¨ë“œë¡œ ì „í™˜\")\n    print(\"3. ì¢…ë£Œ\")\n    \n    choice = input(\"\\nì„ íƒ: \")\n    \n    if choice == \"1\":\n        if client.switch_to_mock_mode():\n            print(\"ëª¨ì˜íˆ¬ì ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n        else:\n            print(\"ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n    elif choice == \"2\":\n        if client.switch_to_real_mode():\n            print(\"ì‹¤ì „íˆ¬ì ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n        else:\n            print(\"ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n    \n    # ì „í™˜ í›„ ëª¨ë“œ ì¶œë ¥\n    print(f\"í˜„ì¬ ê±°ë˜ ëª¨ë“œ: {'ëª¨ì˜íˆ¬ì' if client.mock else 'ì‹¤ì „íˆ¬ì'}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```",
            "status": "done",
            "testStrategy": "1. ëª¨ë“œ ì„¤ì • íŒŒì¼ ìƒì„± ë° ë¡œë“œ í…ŒìŠ¤íŠ¸\n2. ëª¨ì˜íˆ¬ì ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸\n3. ì‹¤ì „íˆ¬ì ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸ (í™•ì¸ í”„ë¡¬í”„íŠ¸ í¬í•¨)\n4. ëª¨ë“œ ì „í™˜ í›„ API ìš”ì²­ í…ŒìŠ¤íŠ¸\n5. ëª¨ë“œë³„ TR ID ìƒì„± í…ŒìŠ¤íŠ¸\n6. ì•ˆì „ ì„¤ì • ì ìš© í…ŒìŠ¤íŠ¸\n7. ì„¤ì • íŒŒì¼ ì €ì¥ ë° ë³µì› í…ŒìŠ¤íŠ¸"
          },
          {
            "id": 6,
            "title": "API ì‘ë‹µ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "API í˜¸ì¶œ ë° ì‘ë‹µì„ ì²´ê³„ì ìœ¼ë¡œ ë¡œê¹…í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„ìœ¼ë¡œ ë””ë²„ê¹… ë° ì„±ëŠ¥ ë¶„ì„ ì§€ì›",
            "dependencies": [
              "22.3",
              "22.4"
            ],
            "details": "1. API ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ êµ¬í˜„ (utils/api_monitor.py):\n```python\nimport time\nimport json\nimport logging\nfrom datetime import datetime, timedelta\nimport asyncio\nimport os\nfrom pathlib import Path\nimport sqlite3\nfrom collections import deque\n\nclass APIMonitor:\n    def __init__(self, db_path=\"logs/api_monitor.db\", max_memory_logs=1000):\n        self.logger = logging.getLogger(\"APIMonitor\")\n        self.db_path = Path(db_path)\n        self.memory_logs = deque(maxlen=max_memory_logs)  # ìµœê·¼ ë¡œê·¸ ë©”ëª¨ë¦¬ ìºì‹œ\n        self.daily_stats = {}  # ì¼ì¼ í†µê³„\n        self.endpoint_stats = {}  # ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„\n        self.error_counts = {}  # ì˜¤ë¥˜ ì¹´ìš´íŠ¸\n        \n        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±\n        os.makedirs(self.db_path.parent, exist_ok=True)\n        \n        # DB ì´ˆê¸°í™”\n        self._init_db()\n        \n        # í†µê³„ ë¡œë”©\n        self._load_stats()\n    \n    def _init_db(self):\n        \"\"\"SQLite DB ì´ˆê¸°í™”\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # API ìš”ì²­ ë¡œê·¸ í…Œì´ë¸”\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS api_logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            timestamp TEXT,\n            method TEXT,\n            endpoint TEXT,\n            tr_id TEXT,\n            status_code INTEGER,\n            response_time REAL,\n            success INTEGER,\n            error_message TEXT,\n            request_data TEXT,\n            response_data TEXT\n        )\n        \"\"\")\n        \n        # ì¼ì¼ í†µê³„ í…Œì´ë¸”\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS daily_stats (\n            date TEXT PRIMARY KEY,\n            total_requests INTEGER,\n            successful_requests INTEGER,\n            failed_requests INTEGER,\n            avg_response_time REAL\n        )\n        \"\"\")\n        \n        # ì—”ë“œí¬ì¸íŠ¸ í†µê³„ í…Œì´ë¸”\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS endpoint_stats (\n            endpoint TEXT PRIMARY KEY,\n            total_requests INTEGER,\n            successful_requests INTEGER,\n            failed_requests INTEGER,\n            avg_response_time REAL,\n            last_used TEXT\n        )\n        \"\"\")\n        \n        conn.commit()\n        conn.close()\n    \n    def _load_stats(self):\n        \"\"\"DBì—ì„œ í†µê³„ ë¡œë“œ\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # ì˜¤ëŠ˜ ë‚ ì§œ\n            today = datetime.now().strftime(\"%Y-%m-%d\")\n            \n            # ì¼ì¼ í†µê³„ ë¡œë“œ\n            cursor.execute(\"SELECT * FROM daily_stats WHERE date = ?\", (today,))\n            row = cursor.fetchone()\n            if row:\n                self.daily_stats = {\n                    \"total_requests\": row[1],\n                    \"successful_requests\": row[2],\n                    \"failed_requests\": row[3],\n                    \"avg_response_time\": row[4]\n                }\n            else:\n                self.daily_stats = {\n                    \"total_requests\": 0,\n                    \"successful_requests\": 0,\n                    \"failed_requests\": 0,\n                    \"avg_response_time\": 0.0\n                }\n            \n            # ì—”ë“œí¬ì¸íŠ¸ í†µê³„ ë¡œë“œ\n            cursor.execute(\"SELECT * FROM endpoint_stats\")\n            rows = cursor.fetchall()\n            for row in rows:\n                self.endpoint_stats[row[0]] = {\n                    \"total_requests\": row[1],\n                    \"successful_requests\": row[2],\n                    \"failed_requests\": row[3],\n                    \"avg_response_time\": row[4],\n                    \"last_used\": row[5]\n                }\n            \n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to load stats: {str(e)}\")\n    \n    def _save_stats(self):\n        \"\"\"í†µê³„ DBì— ì €ì¥\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # ì˜¤ëŠ˜ ë‚ ì§œ\n            today = datetime.now().strftime(\"%Y-%m-%d\")\n            \n            # ì¼ì¼ í†µê³„ ì €ì¥\n            cursor.execute(\"\"\"\n            INSERT OR REPLACE INTO daily_stats \n            (date, total_requests, successful_requests, failed_requests, avg_response_time)\n            VALUES (?, ?, ?, ?, ?)\n            \"\"\", (\n                today,\n                self.daily_stats[\"total_requests\"],\n                self.daily_stats[\"successful_requests\"],\n                self.daily_stats[\"failed_requests\"],\n                self.daily_stats[\"avg_response_time\"]\n            ))\n            \n            # ì—”ë“œí¬ì¸íŠ¸ í†µê³„ ì €ì¥\n            for endpoint, stats in self.endpoint_stats.items():\n                cursor.execute(\"\"\"\n                INSERT OR REPLACE INTO endpoint_stats\n                (endpoint, total_requests, successful_requests, failed_requests, avg_response_time, last_used)\n                VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\", (\n                    endpoint,\n                    stats[\"total_requests\"],\n                    stats[\"successful_requests\"],\n                    stats[\"failed_requests\"],\n                    stats[\"avg_response_time\"],\n                    stats[\"last_used\"]\n                ))\n            \n            conn.commit()\n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to save stats: {str(e)}\")\n    \n    async def log_request(self, method, endpoint, tr_id=None, request_data=None, response_data=None, \n                         status_code=None, response_time=None, success=True, error_message=None):\n        \"\"\"API ìš”ì²­ ë¡œê¹…\"\"\"\n        timestamp = datetime.now().isoformat()\n        \n        # ë¡œê·¸ ë°ì´í„° ìƒì„±\n        log_data = {\n            \"timestamp\": timestamp,\n            \"method\": method,\n            \"endpoint\": endpoint,\n            \"tr_id\": tr_id,\n            \"status_code\": status_code,\n            \"response_time\": response_time,\n            \"success\": success,\n            \"error_message\": error_message,\n            \"request_data\": json.dumps(request_data) if request_data else None,\n            \"response_data\": json.dumps(response_data) if response_data else None\n        }\n        \n        # ë©”ëª¨ë¦¬ ìºì‹œì— ì¶”ê°€\n        self.memory_logs.append(log_data)\n        \n        # í†µê³„ ì—…ë°ì´íŠ¸\n        self._update_stats(log_data)\n        \n        # DBì— ë¡œê·¸ ì €ì¥ (ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬)\n        asyncio.create_task(self._save_log_to_db(log_data))\n    \n    def _update_stats(self, log_data):\n        \"\"\"í†µê³„ ì—…ë°ì´íŠ¸\"\"\"\n        # ì¼ì¼ í†µê³„ ì—…ë°ì´íŠ¸\n        self.daily_stats[\"total_requests\"] += 1\n        if log_data[\"success\"]:\n            self.daily_stats[\"successful_requests\"] += 1\n        else:\n            self.daily_stats[\"failed_requests\"] += 1\n        \n        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸\n        if log_data[\"response_time\"] is not None:\n            current_avg = self.daily_stats[\"avg_response_time\"]\n            current_total = self.daily_stats[\"total_requests\"]\n            self.daily_stats[\"avg_response_time\"] = (\n                (current_avg * (current_total - 1) + log_data[\"response_time\"]) / current_total\n            )\n        \n        # ì—”ë“œí¬ì¸íŠ¸ í†µê³„ ì—…ë°ì´íŠ¸\n        endpoint = log_data[\"endpoint\"]\n        if endpoint not in self.endpoint_stats:\n            self.endpoint_stats[endpoint] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_used\": log_data[\"timestamp\"]\n            }\n        \n        self.endpoint_stats[endpoint][\"total_requests\"] += 1\n        if log_data[\"success\"]:\n            self.endpoint_stats[endpoint][\"successful_requests\"] += 1\n        else:\n            self.endpoint_stats[endpoint][\"failed_requests\"] += 1\n        \n        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸\n        if log_data[\"response_time\"] is not None:\n            current_avg = self.endpoint_stats[endpoint][\"avg_response_time\"]\n            current_total = self.endpoint_stats[endpoint][\"total_requests\"]\n            self.endpoint_stats[endpoint][\"avg_response_time\"] = (\n                (current_avg * (current_total - 1) + log_data[\"response_time\"]) / current_total\n            )\n        \n        self.endpoint_stats[endpoint][\"last_used\"] = log_data[\"timestamp\"]\n        \n        # ì˜¤ë¥˜ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸\n        if not log_data[\"success\"] and log_data[\"error_message\"]:\n            error_key = log_data[\"error_message\"][:100]  # ì˜¤ë¥˜ ë©”ì‹œì§€ ì•ë¶€ë¶„ë§Œ í‚¤ë¡œ ì‚¬ìš©\n            self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1\n        \n        # ì£¼ê¸°ì ìœ¼ë¡œ í†µê³„ ì €ì¥\n        if self.daily_stats[\"total_requests\"] % 100 == 0:\n            self._save_stats()\n    \n    async def _save_log_to_db(self, log_data):\n        \"\"\"ë¡œê·¸ë¥¼ DBì— ì €ì¥\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n            INSERT INTO api_logs \n            (timestamp, method, endpoint, tr_id, status_code, response_time, success, error_message, request_data, response_data)\n            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            \"\"\", (\n                log_data[\"timestamp\"],\n                log_data[\"method\"],\n                log_data[\"endpoint\"],\n                log_data[\"tr_id\"],\n                log_data[\"status_code\"],\n                log_data[\"response_time\"],\n                1 if log_data[\"success\"] else 0,\n                log_data[\"error_message\"],\n                log_data[\"request_data\"],\n                log_data[\"response_data\"]\n            ))\n            \n            conn.commit()\n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to save log to DB: {str(e)}\")\n    \n    def get_recent_logs(self, limit=50):\n        \"\"\"ìµœê·¼ ë¡œê·¸ ì¡°íšŒ\"\"\"\n        return list(self.memory_logs)[-limit:]\n    \n    def get_daily_stats(self):\n        \"\"\"ì¼ì¼ í†µê³„ ì¡°íšŒ\"\"\"\n        return self.daily_stats\n    \n    def get_endpoint_stats(self):\n        \"\"\"ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„ ì¡°íšŒ\"\"\"\n        return self.endpoint_stats\n    \n    def get_error_stats(self):\n        \"\"\"ì˜¤ë¥˜ í†µê³„ ì¡°íšŒ\"\"\"\n        return self.error_counts\n    \n    def get_logs_by_endpoint(self, endpoint, limit=50):\n        \"\"\"íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ì˜ ë¡œê·¸ ì¡°íšŒ\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE endpoint = ? \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (endpoint, limit))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n    \n    def get_logs_by_timerange(self, start_time, end_time=None, limit=100):\n        \"\"\"íŠ¹ì • ì‹œê°„ ë²”ìœ„ì˜ ë¡œê·¸ ì¡°íšŒ\"\"\"\n        if end_time is None:\n            end_time = datetime.now().isoformat()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE timestamp BETWEEN ? AND ? \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (start_time, end_time, limit))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n    \n    def get_error_logs(self, limit=50):\n        \"\"\"ì˜¤ë¥˜ ë¡œê·¸ ì¡°íšŒ\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE success = 0 \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (limit,))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n```\n\n2. KISClient í´ë˜ìŠ¤ì— APIMonitor í†µí•©:\n```python\n# collectors/kis_client.py ìˆ˜ì •\n\nfrom utils.api_monitor import APIMonitor\nimport time\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=None):\n        # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...\n        \n        # API ëª¨ë‹ˆí„° ì´ˆê¸°í™”\n        self.api_monitor = APIMonitor()\n    \n    async def request(self, method, endpoint, tr_id=None, params=None, data=None, headers=None, retry_count=3):\n        \"\"\"API ìš”ì²­ ê³µí†µ ë¡œì§ (ì¬ì‹œë„, ì—ëŸ¬ ì²˜ë¦¬, ëª¨ë‹ˆí„°ë§ í¬í•¨)\"\"\"\n        await self._manage_rate_limit()\n        \n        # í† í° í™•ì¸ ë° ê°±ì‹ \n        await self.auth.ensure_token()\n        \n        # ê¸°ë³¸ í—¤ë” ì„¤ì •\n        request_headers = self.auth.get_auth_headers()\n        if tr_id:\n            request_headers[\"tr_id\"] = tr_id\n        if headers:\n            request_headers.update(headers)\n        \n        url = f\"{self.base_url}{endpoint}\"\n        start_time = time.time()\n        response_data = None\n        status_code = None\n        success = False\n        error_message = None\n        \n        for attempt in range(retry_count):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    request_kwargs = {\n                        \"headers\": request_headers\n                    }\n                    \n                    if params:\n                        request_kwargs[\"params\"] = params\n                    \n                    if data:\n                        request_kwargs[\"json\"] = data\n                    \n                    self.logger.debug(f\"Requesting {method} {url}\")\n                    async with session.request(method, url, **request_kwargs) as response:\n                        response_text = await response.text()\n                        status_code = response.status\n                        \n                        # ì‘ë‹µ ë¡œê¹…\n                        self.logger.debug(f\"Response {response.status}: {response_text[:200]}...\")\n                        \n                        if response.status == 200:\n                            try:\n                                response_data = await response.json()\n                                success = True\n                                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ\n                            except json.JSONDecodeError:\n                                response_data = response_text\n                                success = True\n                                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ\n                        elif response.status == 401:  # ì¸ì¦ ì˜¤ë¥˜\n                            # í† í° ì¬ë°œê¸‰ ì‹œë„\n                            error_message = \"Authentication error\"\n                            self.logger.warning(\"Authentication error, refreshing token\")\n                            await self.auth.issue_access_token()\n                            if attempt < retry_count - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„\n                                continue\n                        \n                        # ê¸°íƒ€ ì˜¤ë¥˜\n                        error_message = f\"API request failed: {response.status} - {response_text}\"\n                        self.logger.error(error_message)\n                        response_data = response_text\n            except aiohttp.ClientError as e:\n                error_message = str(e)\n                if attempt < retry_count - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„\n                    wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„\n                    self.logger.warning(f\"Request failed: {error_message}. Retrying in {wait_time}s\")\n                    await asyncio.sleep(wait_time)\n                else:\n                    self.logger.error(f\"Request failed after {retry_count} attempts: {error_message}\")\n        \n        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°\n        response_time = time.time() - start_time\n        \n        # API ëª¨ë‹ˆí„°ì— ë¡œê¹…\n        await self.api_monitor.log_request(\n            method=method,\n            endpoint=endpoint,\n            tr_id=tr_id,\n            request_data=data if data else params,\n            response_data=response_data,\n            status_code=status_code,\n            response_time=response_time,\n            success=success,\n            error_message=error_message\n        )\n        \n        if not success:\n            raise Exception(error_message or f\"Request failed after {retry_count} attempts\")\n        \n        return response_data\n```\n\n3. API ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìŠ¤í¬ë¦½íŠ¸ (examples/api_monitor_dashboard.py):\n```python\nimport asyncio\nimport sys\nimport os\nfrom datetime import datetime, timedelta\n\n# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.api_monitor import APIMonitor\n\nasync def show_dashboard():\n    monitor = APIMonitor()\n    \n    # ì¼ì¼ í†µê³„ ì¶œë ¥\n    daily_stats = monitor.get_daily_stats()\n    print(\"\\n===== ì¼ì¼ API í†µê³„ =====\")\n    print(f\"ì´ ìš”ì²­ ìˆ˜: {daily_stats['total_requests']}\")\n    print(f\"ì„±ê³µ ìš”ì²­ ìˆ˜: {daily_stats['successful_requests']}\")\n    print(f\"ì‹¤íŒ¨ ìš”ì²­ ìˆ˜: {daily_stats['failed_requests']}\")\n    print(f\"í‰ê·  ì‘ë‹µ ì‹œê°„: {daily_stats['avg_response_time']:.4f}ì´ˆ\")\n    \n    # ì—”ë“œí¬ì¸íŠ¸ í†µê³„ ì¶œë ¥\n    endpoint_stats = monitor.get_endpoint_stats()\n    print(\"\\n===== ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„ =====\")\n    for endpoint, stats in endpoint_stats.items():\n        print(f\"\\nì—”ë“œí¬ì¸íŠ¸: {endpoint}\")\n        print(f\"  ì´ ìš”ì²­ ìˆ˜: {stats['total_requests']}\")\n        print(f\"  ì„±ê³µë¥ : {stats['successful_requests'] / stats['total_requests'] * 100:.1f}%\")\n        print(f\"  í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.4f}ì´ˆ\")\n        print(f\"  ë§ˆì§€ë§‰ ì‚¬ìš©: {stats['last_used']}\")\n    \n    # ì˜¤ë¥˜ í†µê³„ ì¶œë ¥\n    error_stats = monitor.get_error_stats()\n    if error_stats:\n        print(\"\\n===== ì˜¤ë¥˜ í†µê³„ =====\")\n        for error, count in sorted(error_stats.items(), key=lambda x: x[1], reverse=True):\n            print(f\"{error}: {count}íšŒ\")\n    \n    # ìµœê·¼ ë¡œê·¸ ì¶œë ¥\n    recent_logs = monitor.get_recent_logs(10)\n    print(\"\\n===== ìµœê·¼ API ìš”ì²­ ë¡œê·¸ =====\")\n    for log in recent_logs:\n        status = \"ì„±ê³µ\" if log[\"success\"] else \"ì‹¤íŒ¨\"\n        print(f\"{log['timestamp']} - {log['method']} {log['endpoint']} - {status} ({log['response_time']:.4f}ì´ˆ)\")\n    \n    # ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥\n    error_logs = monitor.get_error_logs(5)\n    if error_logs:\n        print(\"\\n===== ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸ =====\")\n        for log in error_logs:\n            print(f\"{log[1]} - {log[2]} {log[3]} - {log[7]}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(show_dashboard())\n```",
            "status": "done",
            "testStrategy": "1. API ëª¨ë‹ˆí„° ì´ˆê¸°í™” ë° DB ìƒì„± í…ŒìŠ¤íŠ¸\n2. API ìš”ì²­ ë¡œê¹… í…ŒìŠ¤íŠ¸\n3. í†µê³„ ì—…ë°ì´íŠ¸ ë° ì €ì¥ í…ŒìŠ¤íŠ¸\n4. ë¡œê·¸ ì¡°íšŒ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n5. ì¼ì¼ í†µê³„ ë° ì—”ë“œí¬ì¸íŠ¸ í†µê³„ í…ŒìŠ¤íŠ¸\n6. ì˜¤ë¥˜ ë¡œê·¸ ë° í†µê³„ í…ŒìŠ¤íŠ¸\n7. ëŒ€ì‹œë³´ë“œ ì¶œë ¥ í…ŒìŠ¤íŠ¸\n8. ì¥ê¸°ê°„ ì‹¤í–‰ ì‹œ ì„±ëŠ¥ ë° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸\n9. ëŒ€ìš©ëŸ‰ ë¡œê·¸ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
          }
        ]
      },
      {
        "id": 23,
        "title": "ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ WebSocket í´ë¼ì´ì–¸íŠ¸",
        "description": "í•œêµ­íˆ¬ìì¦ê¶Œ WebSocket APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì‹œì„¸, í˜¸ê°€, ì²´ê²° ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„ ë° ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° í†µí•©",
        "status": "done",
        "dependencies": [
          21,
          22
        ],
        "priority": "high",
        "details": "1. ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ ë…ë¦½ì ì¸ ë°ì´í„° ìˆ˜ì§‘ê¸° ì—”ì§„ êµ¬í˜„:\n```python\nclass DataCollector:\n    def __init__(self, redis_manager, event_manager):\n        self.redis_manager = redis_manager\n        self.event_manager = event_manager\n        self.adapters = {}\n        self.normalizer = DataNormalizer()\n        self.connection_manager = ConnectionManager()\n        self.subscribed_symbols = set()\n        self.running = False\n        \n    async def initialize(self):\n        # ì–´ëŒ‘í„° ì´ˆê¸°í™” ë° ì—°ê²° ê´€ë¦¬ì ì„¤ì •\n        self.adapters['kis'] = KISDataAdapter()\n        self.adapters['naver'] = NaverDataAdapter()\n        self.adapters['yahoo'] = YahooDataAdapter()\n        await self.connection_manager.initialize(self.adapters)\n        \n    async def subscribe(self, symbol, data_types=None):\n        # ë‹¤ì¤‘ ì†ŒìŠ¤ ì¢…ëª© êµ¬ë… ë¡œì§ (ticker, orderbook, trade)\n        # ê° ì–´ëŒ‘í„°ì— êµ¬ë… ìš”ì²­ ì „ë‹¬\n        \n    async def unsubscribe(self, symbol, data_types=None):\n        # êµ¬ë… í•´ì œ ë¡œì§\n        \n    async def _process_data(self, source, data):\n        # ë°ì´í„° ì •ê·œí™” ë° ì²˜ë¦¬\n        normalized_data = self.normalizer.normalize(source, data)\n        \n        # Redis Rolling ì—…ë°ì´íŠ¸ (ì¢…ëª©ë³„ ìµœê·¼ 200ê°œ ìº”ë“¤)\n        await self.redis_manager.update_market_data(normalized_data)\n        \n        # market_data_received ì´ë²¤íŠ¸ ë°œí–‰\n        await self.event_manager.publish('market_data_received', normalized_data)\n        \n    async def start(self, symbols=None):\n        # ìˆ˜ì§‘ê¸° ì‹œì‘ ë¡œì§\n        \n    async def stop(self):\n        # ìˆ˜ì§‘ê¸° ì¤‘ì§€ ë¡œì§\n```\n\n2. ì£¼ìš” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„:\n```python\nclass KISDataAdapter:\n    # í•œêµ­íˆ¬ìì¦ê¶Œ WebSocket/REST API ì–´ëŒ‘í„°\n    \nclass NaverDataAdapter:\n    # ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ì–´ëŒ‘í„°\n    \nclass YahooDataAdapter:\n    # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„° ì–´ëŒ‘í„°\n    \nclass DataNormalizer:\n    # ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”\n    \nclass ConnectionManager:\n    # ì—°ê²° ê´€ë¦¬ ë° ìë™ ì¬ì—°ê²° ë¡œì§\n```\n\n3. ë‹¤ì–‘í•œ ì‹¤ì‹œê°„ ë°ì´í„° íƒ€ì… ì²˜ë¦¬:\n   - í˜„ì¬ê°€/ì²´ê²° (ticker)\n   - í˜¸ê°€ (orderbook)\n   - ì²´ê²° ë‚´ì—­ (trade)\n\n4. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬:\n   - ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ë° ì´ìƒì¹˜ íƒì§€\n   - ì†ŒìŠ¤ ê°„ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦\n   - ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬ ì „ëµ\n\n5. Redis ë°ì´í„° ê´€ë¦¬:\n   - ì¢…ëª©ë³„ ìµœê·¼ 200ê°œ ìº”ë“¤ Rolling ì—…ë°ì´íŠ¸\n   - ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥ ë° ë°œí–‰\n   - ìºì‹± ì „ëµ ìµœì í™”\n\n6. ì¥ì•  ì²˜ë¦¬ ë° ë³µì›ë ¥:\n   - ìë™ ì¬ì—°ê²° ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„\n   - ë°ì´í„° ì†ŒìŠ¤ ì¥ì•  ì‹œ ëŒ€ì²´ ì†ŒìŠ¤ í™œìš©\n   - ì¥ì•  ë¡œê¹… ë° ì•Œë¦¼\n\n7. ì„±ëŠ¥ ìµœì í™”:\n   - ë¹„ë™ê¸° ì²˜ë¦¬\n   - ë°°ì¹˜ ì²˜ë¦¬\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”\n\n8. ì´ë²¤íŠ¸ ë°œí–‰:\n   - market_data_received ì´ë²¤íŠ¸ ë°œí–‰\n   - ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ í†µí•©",
        "testStrategy": "1. ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ ì—°ê²° ë° ì¸ì¦ í…ŒìŠ¤íŠ¸\n2. ë‹¤ì–‘í•œ ì¢…ëª© êµ¬ë…/í•´ì œ í…ŒìŠ¤íŠ¸\n3. ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ë° íŒŒì‹± ì •í™•ì„± í…ŒìŠ¤íŠ¸\n4. ë°ì´í„° ì •ê·œí™” ë° í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸\n5. Redis Rolling ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸ (200ê°œ ìº”ë“¤ ì œí•œ)\n6. market_data_received ì´ë²¤íŠ¸ ë°œí–‰ ë° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸\n7. ë„¤íŠ¸ì›Œí¬ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ ë° ì¬ì—°ê²° í…ŒìŠ¤íŠ¸\n8. ë°ì´í„° ì†ŒìŠ¤ ì¥ì•  ì‹œ ëŒ€ì²´ ì†ŒìŠ¤ í™œìš© í…ŒìŠ¤íŠ¸\n9. ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸\n10. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§\n11. ë‹¤ì¤‘ ì¢…ëª© ë™ì‹œ êµ¬ë… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n12. ì†ŒìŠ¤ ê°„ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "DataCollector ì—”ì§„ í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ì§€ì›í•˜ëŠ” ë©”ì¸ ë°ì´í„° ìˆ˜ì§‘ê¸° ì—”ì§„ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "KISDataAdapter êµ¬í˜„",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ WebSocket/REST API ì—°ë™ ì–´ëŒ‘í„° êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "NaverDataAdapter ë° YahooDataAdapter êµ¬í˜„",
            "description": "ë³´ì¡° ë°ì´í„° ì†ŒìŠ¤ë¡œ ë„¤ì´ë²„ ê¸ˆìœµê³¼ ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ì–´ëŒ‘í„° êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "DataNormalizer êµ¬í˜„",
            "description": "ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ConnectionManager êµ¬í˜„",
            "description": "ì—°ê²° ê´€ë¦¬ ë° ìë™ ì¬ì—°ê²° ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Redis Rolling ì—…ë°ì´íŠ¸ êµ¬í˜„",
            "description": "ì¢…ëª©ë³„ ìµœê·¼ 200ê°œ ìº”ë“¤ë§Œ ìœ ì§€í•˜ëŠ” Rolling ì—…ë°ì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "market_data_received ì´ë²¤íŠ¸ ë°œí–‰ êµ¬í˜„",
            "description": "ë°ì´í„° ìˆ˜ì‹  ë° ì²˜ë¦¬ í›„ ì´ë²¤íŠ¸ë¥¼ ë°œí–‰í•˜ëŠ” ë¡œì§ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì´ìƒì¹˜ íƒì§€ êµ¬í˜„",
            "description": "ìˆ˜ì‹ ëœ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì¦ ë° ì´ìƒì¹˜ íƒì§€ ë¡œì§ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 24,
        "title": "ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ",
        "description": "í•œêµ­íˆ¬ìì¦ê¶Œ APIì™€ ë³´ì¡° ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™œìš©í•œ ê³¼ê±° ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘, ì •ê·œí™” ë° ì €ì¥ ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          20,
          22
        ],
        "priority": "low",
        "details": "1. ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ê¸° êµ¬í˜„ (collectors/historical_collector.py):\n```python\nclass HistoricalCollector:\n    def __init__(self, kis_client, db_session):\n        self.kis_client = kis_client\n        self.db_session = db_session\n        self.backup_sources = {\n            'naver': NaverFinanceCollector(),\n            'yfinance': YFinanceCollector()\n        }\n        \n    async def collect_daily_data(self, symbol, start_date, end_date=None):\n        # ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§\n        \n    async def collect_minute_data(self, symbol, interval=1, days=5):\n        # ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§\n        \n    async def collect_multiple_symbols(self, symbols, interval='1d', start_date=None):\n        # ë‹¤ì¤‘ ì¢…ëª© ìˆ˜ì§‘ ë¡œì§ (ë³‘ë ¬ ì²˜ë¦¬)\n        \n    async def _normalize_and_save(self, data, symbol, interval_type):\n        # ë°ì´í„° ì •ê·œí™” ë° ì €ì¥ ë¡œì§\n        \n    async def backfill_missing_data(self, symbol, interval_type, start_date, end_date):\n        # ëˆ„ë½ ë°ì´í„° ë³´ì™„ ë¡œì§ (ë³´ì¡° ì†ŒìŠ¤ í™œìš©)\n```\n2. ë‹¤ì–‘í•œ ì‹œê°„ í”„ë ˆì„ ì§€ì›:\n   - 1ë¶„ë´‰, 5ë¶„ë´‰, ì¼ë´‰\n3. ë³´ì¡° ë°ì´í„° ì†ŒìŠ¤ êµ¬í˜„:\n   - ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ëŸ¬\n   - yfinance API í´ë¼ì´ì–¸íŠ¸\n4. ë°ì´í„° ì •ê·œí™” ë° ê²€ì¦ ë¡œì§:\n   - ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬\n   - ëˆ„ë½ ë°ì´í„° ë³´ì™„\n5. íš¨ìœ¨ì ì¸ ë°ì´í„° ì €ì¥ (ë°°ì¹˜ ì‚½ì…)\n6. ì£¼ê¸°ì  ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬í˜„\n7. ê¸€ë¡œë²Œ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ (yfinance í™œìš©)\n8. ê¸°ì—… ì •ë³´ ë° ì¬ë¬´ì œí‘œ ë°ì´í„° ìˆ˜ì§‘ (DART API í™œìš©)\n9. ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ\n\nì°¸ê³ : ì´ ì‹œìŠ¤í…œì€ ë°±í…ŒìŠ¤íŒ…ì„ ìœ„í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ êµ¬ì¶• í›„ ë‚˜ì¤‘ì— ê°œë°œí•  ì˜ˆì •ì…ë‹ˆë‹¤. í˜„ì¬ëŠ” ì‹¤ì‹œê°„ ë°ì´í„°ë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ë§¤ë§¤ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "testStrategy": "1. ë‹¤ì–‘í•œ ì‹œê°„ í”„ë ˆì„ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸\n2. ë°ì´í„° ì •ê·œí™” ë° ì €ì¥ ì •í™•ì„± í…ŒìŠ¤íŠ¸\n3. ë³´ì¡° ë°ì´í„° ì†ŒìŠ¤ í™œìš© í…ŒìŠ¤íŠ¸\n4. ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n5. ëˆ„ë½ ë°ì´í„° ë³´ì™„ í…ŒìŠ¤íŠ¸\n6. ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n7. ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ë™ í…ŒìŠ¤íŠ¸\n8. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸\n9. ì¥ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 25,
        "title": "ì „ëµ ì—”ì§„ í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ êµ¬í˜„",
        "description": "ë‹¤ì–‘í•œ íŠ¸ë ˆì´ë”© ì „ëµì„ ì‰½ê²Œ ì¶”ê°€í•˜ê³  êµì²´í•  ìˆ˜ ìˆëŠ” ì´ë²¤íŠ¸ ê¸°ë°˜ í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬í˜„",
        "status": "done",
        "dependencies": [
          19,
          20
        ],
        "priority": "high",
        "details": "1. BaseStrategy ì¶”ìƒ í´ë˜ìŠ¤ (strategies/base.py):\n```python\nfrom abc import ABC, abstractmethod\n\nclass BaseStrategy(ABC):\n    def __init__(self, params=None):\n        self.params = params or {}\n        self.name = self.__class__.__name__\n    \n    @abstractmethod\n    async def analyze(self, market_data):\n        \"\"\"ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§¤ë§¤ ì‹ í˜¸ ìƒì„±\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_parameters(self):\n        \"\"\"ì „ëµ íŒŒë¼ë¯¸í„° ë°˜í™˜\"\"\"\n        return self.params\n    \n    @abstractmethod\n    def set_parameters(self, params):\n        \"\"\"ì „ëµ íŒŒë¼ë¯¸í„° ì„¤ì •\"\"\"\n        self.params = params\n    \n    @abstractmethod\n    def get_description(self):\n        \"\"\"ì „ëµ ì„¤ëª… ë°˜í™˜\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_required_indicators(self):\n        \"\"\"ì „ëµì— í•„ìš”í•œ ê¸°ìˆ  ì§€í‘œ ëª©ë¡ ë°˜í™˜\"\"\"\n        pass\n```\n\n2. StrategyLoader êµ¬í˜„ (strategies/loader.py):\n```python\nimport importlib\nimport inspect\nimport os\nfrom typing import Dict, Type, List\nfrom .base import BaseStrategy\n\nclass StrategyLoader:\n    def __init__(self, strategies_dir=\"strategies\"):\n        self.strategies_dir = strategies_dir\n        self.available_strategies: Dict[str, Type[BaseStrategy]] = {}\n        self.loaded_strategies: Dict[str, BaseStrategy] = {}\n    \n    def discover_strategies(self) -> List[str]:\n        \"\"\"ì „ëµ ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì „ëµ í´ë˜ìŠ¤ íƒìƒ‰\"\"\"\n        # êµ¬í˜„ ë¡œì§\n        \n    def load_strategy(self, strategy_name: str, params=None) -> BaseStrategy:\n        \"\"\"ì „ëµ ì´ë¦„ìœ¼ë¡œ ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ\"\"\"\n        # êµ¬í˜„ ë¡œì§\n        \n    def unload_strategy(self, strategy_name: str) -> bool:\n        \"\"\"ë¡œë“œëœ ì „ëµ ì–¸ë¡œë“œ\"\"\"\n        # êµ¬í˜„ ë¡œì§\n```\n\n3. StrategyEngine êµ¬í˜„ (strategies/engine.py):\n```python\nfrom typing import Dict, List\nfrom .loader import StrategyLoader\nfrom .base import BaseStrategy\nfrom ..utils.redis_manager import RedisManager\nfrom ..utils.event_bus import EventBus\n\nclass StrategyEngine:\n    def __init__(self, redis_manager: RedisManager, event_bus: EventBus):\n        self.redis = redis_manager\n        self.event_bus = event_bus\n        self.strategy_loader = StrategyLoader()\n        self.active_strategies: Dict[str, BaseStrategy] = {}\n        self.performance_tracker = StrategyPerformanceTracker(redis_manager)\n        \n        # ì´ë²¤íŠ¸ êµ¬ë… ì„¤ì •\n        self.event_bus.subscribe(\"market_data_received\", self.on_market_data)\n    \n    async def on_market_data(self, data):\n        \"\"\"ì‹œì¥ ë°ì´í„° ìˆ˜ì‹  ì‹œ ëª¨ë“  í™œì„± ì „ëµ ì‹¤í–‰\"\"\"\n        symbol = data.get(\"symbol\")\n        \n        # Redisì—ì„œ í•„ìš”í•œ ê¸°ìˆ  ì§€í‘œ ë°ì´í„° ì¡°íšŒ\n        indicators = await self.fetch_indicators(symbol)\n        \n        # ê° í™œì„± ì „ëµ ì‹¤í–‰\n        for strategy_name, strategy in self.active_strategies.items():\n            signals = await strategy.analyze({**data, \"indicators\": indicators})\n            if signals:\n                # ë§¤ë§¤ ì‹ í˜¸ ë°œí–‰\n                await self.publish_trading_signals(strategy_name, symbol, signals)\n                # ì„±ê³¼ ì¶”ì \n                await self.performance_tracker.record_signal(strategy_name, symbol, signals)\n    \n    async def fetch_indicators(self, symbol):\n        \"\"\"Redisì—ì„œ ê¸°ìˆ  ì§€í‘œ ë°ì´í„° ì¡°íšŒ\"\"\"\n        # êµ¬í˜„ ë¡œì§\n        \n    async def publish_trading_signals(self, strategy_name, symbol, signals):\n        \"\"\"ë§¤ë§¤ ì‹ í˜¸ ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        await self.event_bus.publish(\"trading_signal\", {\n            \"strategy\": strategy_name,\n            \"symbol\": symbol,\n            \"signals\": signals,\n            \"timestamp\": # í˜„ì¬ ì‹œê°„\n        })\n    \n    def activate_strategy(self, strategy_name, params=None):\n        \"\"\"ì „ëµ í™œì„±í™”\"\"\"\n        # êµ¬í˜„ ë¡œì§\n        \n    def deactivate_strategy(self, strategy_name):\n        \"\"\"ì „ëµ ë¹„í™œì„±í™”\"\"\"\n        # êµ¬í˜„ ë¡œì§\n```\n\n4. ì „ëµ ì„±ê³¼ ì¶”ì ê¸° (strategies/performance.py):\n```python\nclass StrategyPerformanceTracker:\n    def __init__(self, redis_manager):\n        self.redis = redis_manager\n    \n    async def record_signal(self, strategy_name, symbol, signals):\n        \"\"\"ì „ëµ ì‹ í˜¸ ê¸°ë¡\"\"\"\n        # êµ¬í˜„ ë¡œì§\n        \n    async def get_strategy_performance(self, strategy_name, timeframe=\"1d\"):\n        \"\"\"ì „ëµ ì„±ê³¼ ì¡°íšŒ\"\"\"\n        # êµ¬í˜„ ë¡œì§\n```\n\n5. ìƒ˜í”Œ ì „ëµ êµ¬í˜„:\n\n```python\n# strategies/moving_average.py\nfrom .base import BaseStrategy\n\nclass MovingAverageCrossover(BaseStrategy):\n    def __init__(self, params=None):\n        default_params = {\n            \"short_period\": 10,\n            \"long_period\": 30\n        }\n        super().__init__(params or default_params)\n    \n    async def analyze(self, market_data):\n        indicators = market_data.get(\"indicators\", {})\n        symbol = market_data.get(\"symbol\")\n        \n        # í•„ìš”í•œ ì´ë™í‰ê·  ë°ì´í„° í™•ì¸\n        ma_short = indicators.get(f\"ma_{self.params['short_period']}\")\n        ma_long = indicators.get(f\"ma_{self.params['long_period']}\")\n        \n        if ma_short is None or ma_long is None:\n            return None\n        \n        # ê³¨ë“  í¬ë¡œìŠ¤ (ë‹¨ê¸° > ì¥ê¸°)\n        if ma_short > ma_long and indicators.get(\"prev_ma_short\", 0) <= indicators.get(\"prev_ma_long\", 0):\n            return {\"action\": \"buy\", \"reason\": \"golden_cross\"}\n        \n        # ë°ë“œ í¬ë¡œìŠ¤ (ë‹¨ê¸° < ì¥ê¸°)\n        if ma_short < ma_long and indicators.get(\"prev_ma_short\", 0) >= indicators.get(\"prev_ma_long\", 0):\n            return {\"action\": \"sell\", \"reason\": \"dead_cross\"}\n        \n        return None\n    \n    def get_parameters(self):\n        return self.params\n    \n    def set_parameters(self, params):\n        self.params.update(params)\n    \n    def get_description(self):\n        return f\"ì´ë™í‰ê·  êµì°¨ ì „ëµ (ë‹¨ê¸°: {self.params['short_period']}, ì¥ê¸°: {self.params['long_period']})\"\n    \n    def get_required_indicators(self):\n        return [f\"ma_{self.params['short_period']}\", f\"ma_{self.params['long_period']}\", \n                \"prev_ma_short\", \"prev_ma_long\"]\n```",
        "testStrategy": "1. ì „ëµ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ í…ŒìŠ¤íŠ¸\n2. ì „ëµ ë¡œë“œ/ì–¸ë¡œë“œ í…ŒìŠ¤íŠ¸\n3. ì´ë²¤íŠ¸ êµ¬ë… ë° ë°œí–‰ í…ŒìŠ¤íŠ¸\n4. Redisì—ì„œ ê¸°ìˆ ì§€í‘œ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n5. ìƒ˜í”Œ ì „ëµ ì‹ í˜¸ ìƒì„± ì •í™•ì„± í…ŒìŠ¤íŠ¸\n6. íŒŒë¼ë¯¸í„° ì„¤ì •/ì¡°íšŒ í…ŒìŠ¤íŠ¸\n7. ëŸ°íƒ€ì„ ì „ëµ êµì²´ í…ŒìŠ¤íŠ¸\n8. ì „ëµ ì„±ê³¼ ì¶”ì  í…ŒìŠ¤íŠ¸\n9. ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™©ì—ì„œì˜ ì „ëµ ë™ì‘ í…ŒìŠ¤íŠ¸\n10. ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ í†µí•© í…ŒìŠ¤íŠ¸\n11. ì—¬ëŸ¬ ì „ëµ ë™ì‹œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n12. ì „ëµ ì„¤ì • íŒŒì¼ ë¡œë“œ/ì €ì¥ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "BaseStrategy ì¶”ìƒ í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì „ëµ ì¸í„°í˜ì´ìŠ¤ ì •ì˜ ë° ê¸°ë³¸ ë©”ì„œë“œ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "StrategyLoader êµ¬í˜„",
            "description": "ë™ì ìœ¼ë¡œ ì „ëµ í´ë˜ìŠ¤ë¥¼ ë°œê²¬í•˜ê³  ë¡œë“œ/ì–¸ë¡œë“œí•˜ëŠ” ê¸°ëŠ¥ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "StrategyEngine êµ¬í˜„",
            "description": "ì´ë²¤íŠ¸ êµ¬ë… ë° ì „ëµ ì‹¤í–‰ ì—”ì§„ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "ì „ëµ ì„±ê³¼ ì¶”ì ê¸° êµ¬í˜„",
            "description": "ì „ëµë³„ ì„±ê³¼ë¥¼ ì¶”ì í•˜ê³  ê¸°ë¡í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ìƒ˜í”Œ ì „ëµ êµ¬í˜„",
            "description": "ì´ë™í‰ê·  êµì°¨, RSI, ë³¼ë¦°ì € ë°´ë“œ ë“± ìƒ˜í”Œ ì „ëµ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ì´ë²¤íŠ¸ ê¸°ë°˜ í†µí•© í…ŒìŠ¤íŠ¸",
            "description": "market_data_received ì´ë²¤íŠ¸ë¶€í„° trading_signal ë°œí–‰ê¹Œì§€ ì „ì²´ íë¦„ í…ŒìŠ¤íŠ¸",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 26,
        "title": "ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬í˜„",
        "description": "íŠ¸ë ˆì´ë”© ì „ëµì— í™œìš©í•  ë‹¤ì–‘í•œ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ê³„ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬í˜„ ë° ë…ë¦½ì ì¸ ê¸°ìˆ  ë¶„ì„ ì—”ì§„ìœ¼ë¡œ êµ¬ì„±",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "high",
        "details": "1. TechnicalAnalyzer ì—”ì§„ í´ë˜ìŠ¤ êµ¬í˜„ (analysis/technical_analyzer.py):\n```python\nclass TechnicalAnalyzer:\n    def __init__(self, redis_client):\n        self.redis_client = redis_client\n        self.indicator_calculator = IndicatorCalculator()\n        self.event_bus = EventBus()\n        \n    def start(self):\n        \"\"\"ì´ë²¤íŠ¸ êµ¬ë… ë° ë¶„ì„ ì—”ì§„ ì‹œì‘\"\"\"\n        self.event_bus.subscribe('market_data_received', self.process_market_data)\n        \n    def process_market_data(self, data):\n        \"\"\"ì‹œì¥ ë°ì´í„° ìˆ˜ì‹  ì‹œ ì§€í‘œ ê³„ì‚° ë° ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        symbol = data['symbol']\n        timeframe = data['timeframe']\n        \n        # Redisì—ì„œ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ\n        candles = self.get_candles_from_redis(symbol, timeframe)\n        \n        # ì§€í‘œ ê³„ì‚°\n        indicators = self.calculate_indicators(symbol, candles)\n        \n        # Redisì— ì§€í‘œ ìºì‹±\n        self.cache_indicators(symbol, indicators)\n        \n        # ì§€í‘œ ì—…ë°ì´íŠ¸ ì´ë²¤íŠ¸ ë°œí–‰\n        self.event_bus.publish('indicators_updated', {\n            'symbol': symbol,\n            'timeframe': timeframe,\n            'indicators': indicators\n        })\n```\n\n2. IndicatorCalculator í´ë˜ìŠ¤ êµ¬í˜„ (analysis/indicators.py):\n```python\nclass IndicatorCalculator:\n    def __init__(self):\n        self.ta_lib_available = self._check_talib()\n    \n    def _check_talib(self):\n        \"\"\"TA-Lib ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\"\"\"\n        try:\n            import talib\n            return True\n        except ImportError:\n            return False\n    \n    def sma(self, data, period=20):\n        \"\"\"ë‹¨ìˆœ ì´ë™í‰ê· \"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.SMA(data, timeperiod=period)\n        return data.rolling(window=period).mean()\n    \n    def ema(self, data, period=20):\n        \"\"\"ì§€ìˆ˜ ì´ë™í‰ê· \"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.EMA(data, timeperiod=period)\n        return data.ewm(span=period, adjust=False).mean()\n    \n    def bollinger_bands(self, data, period=20, std_dev=2):\n        \"\"\"ë³¼ë¦°ì € ë°´ë“œ\"\"\"\n        if self.ta_lib_available:\n            import talib\n            upper, middle, lower = talib.BBANDS(data, timeperiod=period, nbdevup=std_dev, nbdevdn=std_dev)\n            return upper, middle, lower\n        \n        sma = self.sma(data, period)\n        std = data.rolling(window=period).std()\n        upper_band = sma + (std * std_dev)\n        lower_band = sma - (std * std_dev)\n        return upper_band, sma, lower_band\n        \n    def rsi(self, data, period=14):\n        \"\"\"ìƒëŒ€ê°•ë„ì§€ìˆ˜(RSI)\"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.RSI(data, timeperiod=period)\n        # ìˆœìˆ˜ Python êµ¬í˜„\n        delta = data.diff()\n        gain = delta.where(delta > 0, 0)\n        loss = -delta.where(delta < 0, 0)\n        avg_gain = gain.rolling(window=period).mean()\n        avg_loss = loss.rolling(window=period).mean()\n        rs = avg_gain / avg_loss\n        return 100 - (100 / (1 + rs))\n    \n    def macd(self, data, fast_period=12, slow_period=26, signal_period=9):\n        \"\"\"MACD(ì´ë™í‰ê· ìˆ˜ë ´í™•ì‚°ì§€ìˆ˜)\"\"\"\n        if self.ta_lib_available:\n            import talib\n            macd, signal, hist = talib.MACD(data, fastperiod=fast_period, slowperiod=slow_period, signalperiod=signal_period)\n            return macd, signal, hist\n        \n        ema_fast = self.ema(data, fast_period)\n        ema_slow = self.ema(data, slow_period)\n        macd_line = ema_fast - ema_slow\n        signal_line = self.ema(macd_line, signal_period)\n        histogram = macd_line - signal_line\n        return macd_line, signal_line, histogram\n```\n\n3. Redis ì§€í‘œ ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„ (analysis/cache_manager.py):\n```python\nclass IndicatorCacheManager:\n    def __init__(self, redis_client):\n        self.redis = redis_client\n        self.expiry = 3600  # 1ì‹œê°„ ìºì‹œ ìœ íš¨ê¸°ê°„\n    \n    def get_cached_indicator(self, symbol, indicator_name, params=None):\n        \"\"\"Redisì—ì„œ ìºì‹œëœ ì§€í‘œ ì¡°íšŒ\"\"\"\n        cache_key = self._build_cache_key(symbol, indicator_name, params)\n        cached_data = self.redis.hget(f\"indicators:{symbol}\", cache_key)\n        if cached_data:\n            return json.loads(cached_data)\n        return None\n    \n    def cache_indicator(self, symbol, indicator_name, data, params=None):\n        \"\"\"ì§€í‘œ ê³„ì‚° ê²°ê³¼ Redisì— ìºì‹±\"\"\"\n        cache_key = self._build_cache_key(symbol, indicator_name, params)\n        self.redis.hset(f\"indicators:{symbol}\", cache_key, json.dumps(data))\n        self.redis.expire(f\"indicators:{symbol}\", self.expiry)\n    \n    def _build_cache_key(self, symbol, indicator_name, params=None):\n        \"\"\"ìºì‹œ í‚¤ ìƒì„±\"\"\"\n        if not params:\n            return f\"{indicator_name}\"\n        param_str = \"_\".join([f\"{k}:{v}\" for k, v in params.items()])\n        return f\"{indicator_name}_{param_str}\"\n    \n    def invalidate_cache(self, symbol):\n        \"\"\"ì‹¬ë³¼ì— ëŒ€í•œ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”\"\"\"\n        self.redis.delete(f\"indicators:{symbol}\")\n```\n\n4. ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ êµ¬í˜„ (utils/event_bus.py):\n```python\nclass EventBus:\n    def __init__(self, redis_client=None):\n        self.redis = redis_client\n        self.local_subscribers = {}\n    \n    def publish(self, event_name, data):\n        \"\"\"ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        message = json.dumps({\n            'event': event_name,\n            'data': data,\n            'timestamp': time.time()\n        })\n        \n        # Redis Pub/Sub ì‚¬ìš© (ë¶„ì‚° í™˜ê²½)\n        if self.redis:\n            self.redis.publish(event_name, message)\n        \n        # ë¡œì»¬ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ í™˜ê²½)\n        if event_name in self.local_subscribers:\n            for callback in self.local_subscribers[event_name]:\n                callback(data)\n    \n    def subscribe(self, event_name, callback):\n        \"\"\"ì´ë²¤íŠ¸ êµ¬ë…\"\"\"\n        if event_name not in self.local_subscribers:\n            self.local_subscribers[event_name] = []\n        self.local_subscribers[event_name].append(callback)\n        \n        # Redis Pub/Sub êµ¬ë… ì„¤ì •\n        if self.redis:\n            thread = threading.Thread(target=self._listen_for_redis_events, args=(event_name,))\n            thread.daemon = True\n            thread.start()\n    \n    def _listen_for_redis_events(self, event_name):\n        \"\"\"Redis ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ\"\"\"\n        pubsub = self.redis.pubsub()\n        pubsub.subscribe(event_name)\n        \n        for message in pubsub.listen():\n            if message['type'] == 'message':\n                data = json.loads(message['data'])\n                if event_name in self.local_subscribers:\n                    for callback in self.local_subscribers[event_name]:\n                        callback(data['data'])\n```\n\n5. ì»¤ìŠ¤í…€ ì§€í‘œ ì¶”ê°€ ì§€ì› (analysis/custom_indicators.py):\n```python\nclass CustomIndicatorRegistry:\n    def __init__(self):\n        self.indicators = {}\n    \n    def register(self, name, calculation_func, description=\"\"):\n        \"\"\"ì»¤ìŠ¤í…€ ì§€í‘œ ë“±ë¡\"\"\"\n        self.indicators[name] = {\n            'function': calculation_func,\n            'description': description\n        }\n        return True\n    \n    def get_indicator(self, name):\n        \"\"\"ë“±ë¡ëœ ì»¤ìŠ¤í…€ ì§€í‘œ ì¡°íšŒ\"\"\"\n        return self.indicators.get(name, {}).get('function')\n    \n    def calculate(self, name, data, **params):\n        \"\"\"ì»¤ìŠ¤í…€ ì§€í‘œ ê³„ì‚°\"\"\"\n        indicator_func = self.get_indicator(name)\n        if not indicator_func:\n            raise ValueError(f\"Unknown indicator: {name}\")\n        return indicator_func(data, **params)\n    \n    def list_indicators(self):\n        \"\"\"ë“±ë¡ëœ ëª¨ë“  ì»¤ìŠ¤í…€ ì§€í‘œ ëª©ë¡ ë°˜í™˜\"\"\"\n        return {\n            name: info['description'] \n            for name, info in self.indicators.items()\n        }\n```\n\n6. ì§€í‘œ ê³„ì‚° ì„±ëŠ¥ ìµœì í™” (analysis/performance.py):\n```python\nclass IndicatorPerformanceOptimizer:\n    def __init__(self, cache_manager):\n        self.cache_manager = cache_manager\n        self.calculation_stats = {}\n    \n    def optimize_calculation(self, symbol, indicator_name, data, calculation_func, params=None):\n        \"\"\"ì§€í‘œ ê³„ì‚° ìµœì í™” (ìºì‹± ë° ì„±ëŠ¥ ì¸¡ì •)\"\"\"\n        # ìºì‹œ í™•ì¸\n        cached_result = self.cache_manager.get_cached_indicator(symbol, indicator_name, params)\n        if cached_result is not None:\n            return cached_result\n        \n        # ì„±ëŠ¥ ì¸¡ì • ë° ê³„ì‚°\n        start_time = time.time()\n        result = calculation_func(data, **params) if params else calculation_func(data)\n        calc_time = time.time() - start_time\n        \n        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸\n        if indicator_name not in self.calculation_stats:\n            self.calculation_stats[indicator_name] = []\n        self.calculation_stats[indicator_name].append(calc_time)\n        \n        # ê²°ê³¼ ìºì‹±\n        self.cache_manager.cache_indicator(symbol, indicator_name, result, params)\n        \n        return result\n    \n    def get_performance_stats(self):\n        \"\"\"ì§€í‘œë³„ ê³„ì‚° ì„±ëŠ¥ í†µê³„ ë°˜í™˜\"\"\"\n        stats = {}\n        for indicator, times in self.calculation_stats.items():\n            stats[indicator] = {\n                'avg_time': sum(times) / len(times),\n                'min_time': min(times),\n                'max_time': max(times),\n                'calls': len(times)\n            }\n        return stats\n```",
        "testStrategy": "1. ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ í…ŒìŠ¤íŠ¸:\n   - market_data_received ì´ë²¤íŠ¸ ë°œí–‰ ë° êµ¬ë… í…ŒìŠ¤íŠ¸\n   - indicators_updated ì´ë²¤íŠ¸ ë°œí–‰ ë° êµ¬ë… í…ŒìŠ¤íŠ¸\n   - ì´ë²¤íŠ¸ ì²˜ë¦¬ íë¦„ ê²€ì¦\n\n2. ì§€í‘œ ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸:\n   - ê° ì§€í‘œ ê³„ì‚° ê²°ê³¼ ê²€ì¦\n   - TA-Lib ê²°ê³¼ì™€ ë¹„êµ ê²€ì¦\n   - ì»¤ìŠ¤í…€ ì§€í‘œ ê³„ì‚° ê²€ì¦\n\n3. Redis ìºì‹± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n   - ì§€í‘œ ìºì‹± ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n   - ìºì‹œ ë§Œë£Œ ì •ì±… í…ŒìŠ¤íŠ¸\n   - ìºì‹œ ë¬´íš¨í™” í…ŒìŠ¤íŠ¸\n\n4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n   - ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ìºì‹± ë©”ì»¤ë‹ˆì¦˜ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸\n\n5. í†µí•© í…ŒìŠ¤íŠ¸:\n   - ì „ì²´ ì´ë²¤íŠ¸ íë¦„ í…ŒìŠ¤íŠ¸ (market_data_received â†’ ì§€í‘œ ê³„ì‚° â†’ Redis ìºì‹± â†’ indicators_updated ë°œí–‰)\n   - ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™©ì—ì„œì˜ ì§€í‘œ ë™ì‘ í…ŒìŠ¤íŠ¸\n   - ì—¬ëŸ¬ ì‹¬ë³¼ ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n\n6. ì»¤ìŠ¤í…€ ì§€í‘œ í”„ë ˆì„ì›Œí¬ í…ŒìŠ¤íŠ¸:\n   - ì»¤ìŠ¤í…€ ì§€í‘œ ë“±ë¡ ë° ê³„ì‚° í…ŒìŠ¤íŠ¸\n   - ì»¤ìŠ¤í…€ ì§€í‘œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "TechnicalAnalyzer ì—”ì§„ í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì´ë²¤íŠ¸ ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„ ì—”ì§„ êµ¬í˜„ (market_data_received ì´ë²¤íŠ¸ êµ¬ë…, indicators_updated ì´ë²¤íŠ¸ ë°œí–‰)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "IndicatorCalculator í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "TA-Lib ë˜í¼ ë° ìˆœìˆ˜ Python êµ¬í˜„ì„ í¬í•¨í•œ ì£¼ìš” ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í´ë˜ìŠ¤ êµ¬í˜„ (RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ, ì´ë™í‰ê·  ë“±)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Redis ì§€í‘œ ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ê³„ì‚°ëœ ì§€í‘œë¥¼ Redisì— ìºì‹±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„ (ì¤‘ë³µ ê³„ì‚° ë°©ì§€)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ êµ¬í˜„",
            "description": "Redis Pub/Subì„ í™œìš©í•œ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„ (market_data_received, indicators_updated ë“±)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ì»¤ìŠ¤í…€ ì§€í‘œ ì¶”ê°€ ì§€ì› êµ¬í˜„",
            "description": "ì‚¬ìš©ì ì •ì˜ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë“±ë¡í•˜ê³  ê³„ì‚°í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ êµ¬í˜„",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ì§€í‘œ ê³„ì‚° ì„±ëŠ¥ ìµœì í™”",
            "description": "ìºì‹±, ë²¡í„°í™”, ë³‘ë ¬ ì²˜ë¦¬ ë“±ì„ í™œìš©í•œ ì§€í‘œ ê³„ì‚° ì„±ëŠ¥ ìµœì í™”",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "description": "ê° ì§€í‘œ ê³„ì‚° ë° ìºì‹± ì‹œìŠ¤í…œì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "description": "ì „ì²´ ì´ë²¤íŠ¸ íë¦„ ë° ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 27,
        "title": "ë°±í…ŒìŠ¤íŒ… ì—”ì§„ êµ¬í˜„",
        "description": "ê³¼ê±° ë°ì´í„°ë¥¼ í™œìš©í•œ íŠ¸ë ˆì´ë”© ì „ëµ ë°±í…ŒìŠ¤íŒ… ì—”ì§„ êµ¬í˜„ ë° ì„±ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ",
        "status": "pending",
        "dependencies": [
          24,
          25,
          26
        ],
        "priority": "low",
        "details": "1. ë°±í…ŒìŠ¤íŒ… ì—”ì§„ í´ë˜ìŠ¤ êµ¬í˜„ (backtesting/engine.py):\n```python\nclass BacktestEngine:\n    def __init__(self, strategy, initial_capital=2000000):\n        self.strategy = strategy\n        self.initial_capital = initial_capital\n        self.current_capital = initial_capital\n        self.positions = {}\n        self.trades = []\n        self.equity_curve = []\n        \n    async def run(self, data, commission=0.00015):\n        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§\n        \n    def calculate_metrics(self):\n        # ì„±ê³¼ ì§€í‘œ ê³„ì‚° ë¡œì§\n        # - ì´ ìˆ˜ìµë¥ \n        # - ìƒ¤í”„ ë¹„ìœ¨\n        # - ìµœëŒ€ ë‚™í­ (MDD)\n        # - ìŠ¹ë¥ \n        # - ì†ìµë¹„\n        \n    def plot_results(self):\n        # ê²°ê³¼ ì‹œê°í™” ë¡œì§\n        \n    def export_results(self, filename):\n        # ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ë¡œì§\n```\n2. í˜„ì‹¤ì ì¸ ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜:\n   - ìŠ¬ë¦¬í”¼ì§€ ëª¨ë¸ë§\n   - ê±°ë˜ ìˆ˜ìˆ˜ë£Œ ë°˜ì˜\n   - ë¶€ë¶„ ì²´ê²° ì‹œë®¬ë ˆì´ì…˜\n3. ë‹¤ì–‘í•œ ì„±ê³¼ ì§€í‘œ ê³„ì‚°:\n   - ì´ ìˆ˜ìµë¥ , ì—°ê°„ ìˆ˜ìµë¥ \n   - ìƒ¤í”„ ë¹„ìœ¨, ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨\n   - ìµœëŒ€ ë‚™í­ (MDD)\n   - ìŠ¹ë¥ , ì†ìµë¹„\n   - ì¼ì¼/ì›”ê°„ ìˆ˜ìµë¥  ë¶„í¬\n4. ê²°ê³¼ ì‹œê°í™” ë„êµ¬:\n   - ìë³¸ ê³¡ì„ \n   - ìˆ˜ìµë¥  ë¶„í¬\n   - ì›”ê°„/ì—°ê°„ ì„±ê³¼ íˆíŠ¸ë§µ\n5. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ê¸°ëŠ¥\n6. íŒŒë¼ë¯¸í„° ìµœì í™” (ê·¸ë¦¬ë“œ ì„œì¹˜, ìœ ì „ ì•Œê³ ë¦¬ì¦˜)\n7. ì›Œí¬í¬ì›Œë“œ ë¶„ì„ (ê³¼ì í•© ë°©ì§€)\n8. ê²°ê³¼ ë‚´ë³´ë‚´ê¸° (CSV, JSON, HTML ë³´ê³ ì„œ)\n\nì°¸ê³ : ì‹¤ì œ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ êµ¬ì¶•ì´ ìš°ì„ ìˆœìœ„ì´ë©°, ë°±í…ŒìŠ¤íŒ…ì€ ë¶€ê°€ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ êµ¬ì¶• í›„ ë‚˜ì¤‘ì— ê°œë°œí•  ì˜ˆì •ì…ë‹ˆë‹¤. ì†Œì•¡ ê±°ë˜ ì‹œìŠ¤í…œì´ë¯€ë¡œ ë°±í…ŒìŠ¤íŒ…ë³´ë‹¤ëŠ” ì‹¤ì „ì—ì„œ ê²€ì¦í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "testStrategy": "1. ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n2. ìˆ˜ë™ ê³„ì‚° ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ ì •í™•ì„± ê²€ì¦\n3. ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸\n4. ìŠ¬ë¦¬í”¼ì§€ ë° ìˆ˜ìˆ˜ë£Œ ëª¨ë¸ë§ í…ŒìŠ¤íŠ¸\n5. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n6. íŒŒë¼ë¯¸í„° ìµœì í™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n7. ê²°ê³¼ ì‹œê°í™” ë° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸\n8. ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ìœ íš¨ì„± í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "ì£¼ë¬¸ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "description": "ì´ë²¤íŠ¸ ê¸°ë°˜ ì£¼ë¬¸ ì—”ì§„ì„ í†µí•œ ì£¼ë¬¸ ìƒì„±, ì‹¤í–‰, ì·¨ì†Œ ë° í¬ì§€ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          22,
          20
        ],
        "priority": "high",
        "details": "1. OrderEngine í´ë˜ìŠ¤ êµ¬í˜„ (orders/engine.py):\n```python\nclass OrderEngine:\n    def __init__(self, kis_broker_client, db_session, risk_manager=None, event_bus=None):\n        self.broker_client = kis_broker_client\n        self.db_session = db_session\n        self.risk_manager = risk_manager\n        self.event_bus = event_bus\n        self.order_queue = OrderQueue()\n        self.position_manager = PositionManager()\n        self.commission_calculator = CommissionCalculator()\n        \n    async def start(self):\n        # ì´ë²¤íŠ¸ êµ¬ë… ì„¤ì •\n        await self.event_bus.subscribe('trading_signal', self.handle_trading_signal)\n        \n    async def handle_trading_signal(self, signal):\n        # íŠ¸ë ˆì´ë”© ì‹œê·¸ë„ ì²˜ë¦¬\n        # 1. ë¦¬ìŠ¤í¬ ì²´í¬\n        # 2. ì£¼ë¬¸ ìƒì„±\n        # 3. ì£¼ë¬¸ íì— ì¶”ê°€\n        # 4. ì£¼ë¬¸ ì‹¤í–‰\n        \n    async def execute_order(self, order):\n        # ì£¼ë¬¸ ì‹¤í–‰ ë¡œì§\n        try:\n            result = await self.broker_client.place_order(order)\n            # ì£¼ë¬¸ ì„±ê³µ ì‹œ ì´ë²¤íŠ¸ ë°œí–‰\n            await self.event_bus.publish('order_executed', result)\n        except Exception as e:\n            # ì£¼ë¬¸ ì‹¤íŒ¨ ì‹œ ì´ë²¤íŠ¸ ë°œí–‰\n            await self.event_bus.publish('order_failed', {'order': order, 'error': str(e)})\n        \n    async def cancel_order(self, order_id):\n        # ì£¼ë¬¸ ì·¨ì†Œ ë¡œì§\n        \n    async def update_order(self, order_id, new_price=None, new_quantity=None):\n        # ì£¼ë¬¸ ìˆ˜ì • ë¡œì§\n        \n    async def get_order_status(self, order_id):\n        # ì£¼ë¬¸ ìƒíƒœ ì¡°íšŒ ë¡œì§\n        \n    async def handle_execution_report(self, report):\n        # ì²´ê²° ë³´ê³ ì„œ ì²˜ë¦¬\n        # 1. í¬ì§€ì…˜ ì—…ë°ì´íŠ¸\n        # 2. ë¶€ë¶„/ì™„ì „ ì²´ê²° ì²˜ë¦¬\n        # 3. ì´ë²¤íŠ¸ ë°œí–‰\n```\n\n2. KISBrokerClient í´ë˜ìŠ¤ êµ¬í˜„ (brokers/kis_broker.py):\n```python\nclass KISBrokerClient:\n    def __init__(self, kis_client):\n        self.kis_client = kis_client\n        \n    async def place_order(self, order):\n        # í•œêµ­íˆ¬ìì¦ê¶Œ APIë¥¼ í†µí•œ ì£¼ë¬¸ ì‹¤í–‰\n        \n    async def cancel_order(self, order_id):\n        # ì£¼ë¬¸ ì·¨ì†Œ ìš”ì²­\n        \n    async def get_order_status(self, order_id):\n        # ì£¼ë¬¸ ìƒíƒœ ì¡°íšŒ\n        \n    async def get_positions(self):\n        # í˜„ì¬ í¬ì§€ì…˜ ì¡°íšŒ\n```\n\n3. OrderQueue í´ë˜ìŠ¤ êµ¬í˜„ (orders/queue.py):\n```python\nclass OrderQueue:\n    def __init__(self):\n        self.queue = asyncio.Queue()\n        self.processing = False\n        \n    async def add_order(self, order):\n        # ì£¼ë¬¸ íì— ì¶”ê°€\n        \n    async def process_queue(self):\n        # íì— ìˆëŠ” ì£¼ë¬¸ ìˆœì°¨ì  ì²˜ë¦¬\n```\n\n4. PositionManager í´ë˜ìŠ¤ êµ¬í˜„ (orders/position.py):\n```python\nclass PositionManager:\n    def __init__(self):\n        self.positions = {}\n        \n    async def update_position(self, symbol, quantity, price, side):\n        # í¬ì§€ì…˜ ì—…ë°ì´íŠ¸\n        \n    async def get_position(self, symbol):\n        # íŠ¹ì • ì¢…ëª© í¬ì§€ì…˜ ì¡°íšŒ\n        \n    async def get_all_positions(self):\n        # ëª¨ë“  í¬ì§€ì…˜ ì¡°íšŒ\n        \n    async def calculate_unrealized_pnl(self, symbol, current_price):\n        # ë¯¸ì‹¤í˜„ ì†ìµ ê³„ì‚°\n```\n\n5. CommissionCalculator í´ë˜ìŠ¤ êµ¬í˜„ (orders/commission.py):\n```python\nclass CommissionCalculator:\n    def __init__(self, commission_rates=None):\n        self.commission_rates = commission_rates or {\n            'stock': 0.00015,  # ê¸°ë³¸ ì£¼ì‹ ìˆ˜ìˆ˜ë£Œ\n            'etf': 0.00010,    # ETF ìˆ˜ìˆ˜ë£Œ\n        }\n        \n    def calculate_commission(self, order_type, price, quantity):\n        # ìˆ˜ìˆ˜ë£Œ ê³„ì‚°\n```\n\n6. ì£¼ë¬¸ íƒ€ì… ì§€ì›:\n   - ì‹œì¥ê°€ ì£¼ë¬¸\n   - ì§€ì •ê°€ ì£¼ë¬¸\n   - ì¡°ê±´ë¶€ ì£¼ë¬¸ (ìŠ¤íƒ‘, OCO)\n\n7. ì´ë²¤íŠ¸ ê¸°ë°˜ ì£¼ë¬¸ ì²˜ë¦¬ íë¦„:\n   - trading_signal ì´ë²¤íŠ¸ ìˆ˜ì‹ \n   - ë¦¬ìŠ¤í¬ ì²´í¬ ë° ì£¼ë¬¸ ìƒì„±\n   - ì£¼ë¬¸ íì— ì¶”ê°€ ë° ì²˜ë¦¬\n   - ì£¼ë¬¸ ì‹¤í–‰ ë° ê²°ê³¼ ì´ë²¤íŠ¸ ë°œí–‰ (order_executed, order_failed)\n   - ì²´ê²° ë³´ê³ ì„œ ì²˜ë¦¬ ë° í¬ì§€ì…˜ ì—…ë°ì´íŠ¸\n\n8. ì²´ê²° ê´€ë¦¬:\n   - ë¶€ë¶„ ì²´ê²° ì²˜ë¦¬\n   - ë¯¸ì²´ê²° ì£¼ë¬¸ ì¶”ì  ë° ê´€ë¦¬\n   - ì²´ê²° ì´ë²¤íŠ¸ ë°œí–‰\n\n9. í¬ì§€ì…˜ ê´€ë¦¬:\n   - ì‹¤ì‹œê°„ í¬ì§€ì…˜ ì¶”ì \n   - í‰ê·  ë§¤ìˆ˜ê°€ ê³„ì‚°\n   - ë¯¸ì‹¤í˜„ ì†ìµ ê³„ì‚°\n\n10. ê±°ë˜ ê¸°ë¡ ì €ì¥ ë° ë¶„ì„\n\n11. ì£¼ë¬¸ ì‹¤íŒ¨ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜",
        "testStrategy": "1. ì´ë²¤íŠ¸ ê¸°ë°˜ ì£¼ë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\n   - trading_signal ì´ë²¤íŠ¸ ë°œí–‰ ì‹œ ì£¼ë¬¸ ìƒì„± ê²€ì¦\n   - order_executed, order_failed ì´ë²¤íŠ¸ ë°œí–‰ ê²€ì¦\n\n2. í•œêµ­íˆ¬ìì¦ê¶Œ API ì—°ë™ í…ŒìŠ¤íŠ¸:\n   - ì‹¤ì œ ì£¼ë¬¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ëª¨ì˜íˆ¬ì í™˜ê²½)\n   - API ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n\n3. ì£¼ë¬¸ í ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n   - ë‹¤ì¤‘ ì£¼ë¬¸ ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n   - ì£¼ë¬¸ ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ ê²€ì¦\n\n4. ì²´ê²° ê´€ë¦¬ í…ŒìŠ¤íŠ¸:\n   - ë¶€ë¶„ ì²´ê²° ì²˜ë¦¬ ì •í™•ì„± í…ŒìŠ¤íŠ¸\n   - ë¯¸ì²´ê²° ì£¼ë¬¸ ì¶”ì  í…ŒìŠ¤íŠ¸\n\n5. í¬ì§€ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸:\n   - í¬ì§€ì…˜ ì—…ë°ì´íŠ¸ ì •í™•ì„± í…ŒìŠ¤íŠ¸\n   - í‰ê·  ë§¤ìˆ˜ê°€ ê³„ì‚° ê²€ì¦\n   - ë¯¸ì‹¤í˜„ ì†ìµ ê³„ì‚° ê²€ì¦\n\n6. ìˆ˜ìˆ˜ë£Œ ê³„ì‚° í…ŒìŠ¤íŠ¸:\n   - ë‹¤ì–‘í•œ ì£¼ë¬¸ íƒ€ì…ë³„ ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ì •í™•ì„± ê²€ì¦\n\n7. ë‹¤ì–‘í•œ ì£¼ë¬¸ íƒ€ì… í…ŒìŠ¤íŠ¸:\n   - ì‹œì¥ê°€, ì§€ì •ê°€, ì¡°ê±´ë¶€ ì£¼ë¬¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n\n8. ì£¼ë¬¸ ì·¨ì†Œ ë° ìˆ˜ì • í…ŒìŠ¤íŠ¸\n\n9. ì—ëŸ¬ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ ë° ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸\n\n10. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì—°ë™ í…ŒìŠ¤íŠ¸\n\n11. ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "OrderEngine í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì´ë²¤íŠ¸ ê¸°ë°˜ ì£¼ë¬¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ OrderEngine í´ë˜ìŠ¤ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "KISBrokerClient í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "í•œêµ­íˆ¬ìì¦ê¶Œ APIë¥¼ í†µí•œ ì‹¤ì œ ê±°ë˜ ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ë¸Œë¡œì»¤ í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "OrderQueue í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì£¼ë¬¸ ìˆœì„œ ê´€ë¦¬ ë° ë™ì‹œ ì£¼ë¬¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ í ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "PositionManager í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì‹¤ì‹œê°„ í¬ì§€ì…˜ ì¶”ì  ë° ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "CommissionCalculator í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ê±°ë˜ ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ì´ë²¤íŠ¸ êµ¬ë… ë° ë°œí–‰ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "trading_signal ì´ë²¤íŠ¸ êµ¬ë… ë° order_executed, order_failed ì´ë²¤íŠ¸ ë°œí–‰ ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "ì²´ê²° ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ë¶€ë¶„/ì™„ì „ ì²´ê²° ì²˜ë¦¬ ë° ë¯¸ì²´ê²° ì£¼ë¬¸ ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "description": "ê° ì»´í¬ë„ŒíŠ¸ë³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "description": "ì „ì²´ ì£¼ë¬¸ ì²˜ë¦¬ íë¦„ì— ëŒ€í•œ í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 29,
        "title": "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "description": "í¬ì§€ì…˜ í¬ê¸° ì œí•œ, ì†ì ˆ/ìµì ˆ, ì¼ì¼/ì›”ê°„ ì†ì‹¤ í•œë„ ë“± ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„. RPC ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤í¬ ì—”ì§„ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ì‹¤ì‹œê°„ ë¦¬ìŠ¤í¬ ì²´í¬ ë° ìë™ ì†ì ˆ/ìµì ˆ ê¸°ëŠ¥ ì œê³µ.",
        "status": "pending",
        "dependencies": [
          20,
          28
        ],
        "priority": "high",
        "details": "1. RiskEngine í´ë˜ìŠ¤ êµ¬í˜„ (risk/engine.py):\n```python\nclass RiskEngine:\n    def __init__(self, db_session, config=None):\n        self.db_session = db_session\n        self.config = config or self.default_config()\n        self.daily_pnl = 0\n        self.monthly_pnl = 0\n        self.consecutive_losses = 0\n        self.risk_rules = self._init_risk_rules()\n        self.stop_loss_manager = AutoStopLoss(self)\n        self.risk_monitor = RiskMonitor(self)\n        self.emergency_stop = EmergencyStop(self)\n        \n    @staticmethod\n    def default_config():\n        return {\n            'max_position_size': 0.2,  # ì¢…ëª©ë‹¹ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨\n            'max_sector_exposure': 0.3,  # ì„¹í„°ë³„ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨\n            'stop_loss_pct': 0.03,  # ì¢…ëª©ë³„ ì†ì ˆ ë¹„ìœ¨\n            'trailing_stop_pct': 0.02,  # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë¹„ìœ¨\n            'take_profit_pct': 0.05,  # ìµì ˆ ë¹„ìœ¨\n            'max_daily_loss': 10000,  # ì¼ì¼ ìµœëŒ€ ì†ì‹¤ ê¸ˆì•¡\n            'max_monthly_loss': 100000,  # ì›”ê°„ ìµœëŒ€ ì†ì‹¤ ê¸ˆì•¡\n            'max_trades_per_day': 10,  # í•˜ë£¨ ìµœëŒ€ ê±°ë˜ íšŸìˆ˜\n            'min_rebuy_interval': 60,  # ë™ì¼ ì¢…ëª© ì¬ë§¤ìˆ˜ ëŒ€ê¸° ì‹œê°„(ë¶„)\n            'risk_alert_threshold': 0.8  # ë¦¬ìŠ¤í¬ í•œë„ ì•Œë¦¼ ì„ê³„ê°’\n        }\n    \n    def _init_risk_rules(self):\n        # ë¦¬ìŠ¤í¬ ê·œì¹™ ì´ˆê¸°í™”\n        return [\n            PositionSizeRule(self),\n            SectorExposureRule(self),\n            DailyLossRule(self),\n            MonthlyLossRule(self),\n            CashReserveRule(self),\n            TradeFrequencyRule(self)\n        ]\n        \n    async def check_order(self, symbol, side, quantity, price):\n        # RPC ìŠ¤íƒ€ì¼: ì£¼ë¬¸ ì‹¤í–‰ ì „ ë¦¬ìŠ¤í¬ ì²´í¬ ë¡œì§\n        # ëª¨ë“  ë¦¬ìŠ¤í¬ ê·œì¹™ ê²€ì¦ í›„ ìŠ¹ì¸/ê±°ë¶€ ì‘ë‹µ\n        for rule in self.risk_rules:\n            result = await rule.validate(symbol, side, quantity, price)\n            if not result['approved']:\n                await self._publish_risk_alert(result['message'], symbol)\n                return {\n                    'approved': False,\n                    'reason': result['message']\n                }\n        \n        return {'approved': True}\n        \n    async def update_position_risk(self, symbol, current_price):\n        # í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ì—…ë°ì´íŠ¸ ë° ìë™ ì†ì ˆ/ìµì ˆ ì²´í¬\n        return await self.stop_loss_manager.check_positions(symbol, current_price)\n        \n    async def update_daily_pnl(self, trade_pnl):\n        # ì¼ì¼ ì†ìµ ì—…ë°ì´íŠ¸ ë° í•œë„ ì²´í¬\n        self.daily_pnl += trade_pnl\n        if trade_pnl < 0:\n            self.consecutive_losses += 1\n        else:\n            self.consecutive_losses = 0\n            \n        # ì¼ì¼ ì†ì‹¤ í•œë„ ì ‘ê·¼ ì‹œ ì•Œë¦¼\n        if abs(self.daily_pnl) > self.config['max_daily_loss'] * self.config['risk_alert_threshold']:\n            await self._publish_risk_alert(f\"ì¼ì¼ ì†ì‹¤ í•œë„ {self.config['risk_alert_threshold']*100}% ì ‘ê·¼\", \"SYSTEM\")\n            \n        return self.daily_pnl < -self.config['max_daily_loss']\n        \n    async def update_monthly_pnl(self, trade_pnl):\n        # ì›”ê°„ ì†ìµ ì—…ë°ì´íŠ¸ ë° í•œë„ ì²´í¬\n        self.monthly_pnl += trade_pnl\n        \n        # ì›”ê°„ ì†ì‹¤ í•œë„ ì ‘ê·¼ ì‹œ ì•Œë¦¼\n        if abs(self.monthly_pnl) > self.config['max_monthly_loss'] * self.config['risk_alert_threshold']:\n            await self._publish_risk_alert(f\"ì›”ê°„ ì†ì‹¤ í•œë„ {self.config['risk_alert_threshold']*100}% ì ‘ê·¼\", \"SYSTEM\")\n            \n        return self.monthly_pnl < -self.config['max_monthly_loss']\n        \n    async def should_stop_trading(self):\n        # ê±°ë˜ ì¤‘ë‹¨ ì—¬ë¶€ ê²°ì • ë¡œì§\n        return await self.emergency_stop.check_conditions()\n        \n    async def _publish_risk_alert(self, message, symbol):\n        # risk_alert ì´ë²¤íŠ¸ ë°œí–‰\n        event = {\n            'type': 'risk_alert',\n            'message': message,\n            'symbol': symbol,\n            'timestamp': datetime.now().isoformat()\n        }\n        # Redis Pub/Subìœ¼ë¡œ ì´ë²¤íŠ¸ ë°œí–‰\n        # await redis_client.publish('risk_alerts', json.dumps(event))\n```\n\n2. RiskRules í´ë˜ìŠ¤ êµ¬í˜„ (risk/rules.py):\n```python\nclass BaseRiskRule:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        \n    async def validate(self, symbol, side, quantity, price):\n        raise NotImplementedError()\n\nclass PositionSizeRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # ì¢…ëª©ë‹¹ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨ ê²€ì¦\n        pass\n        \nclass SectorExposureRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # ì„¹í„°ë³„ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨ ê²€ì¦\n        pass\n\nclass DailyLossRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # ì¼ì¼ ì†ì‹¤ í•œë„ ê²€ì¦\n        pass\n\nclass MonthlyLossRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # ì›”ê°„ ì†ì‹¤ í•œë„ ê²€ì¦\n        pass\n        \nclass CashReserveRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # í˜„ê¸ˆ ë³´ìœ ëŸ‰ ê²€ì¦\n        pass\n        \nclass TradeFrequencyRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # ê±°ë˜ ë¹ˆë„ ì œí•œ ê²€ì¦\n        pass\n```\n\n3. AutoStopLoss í´ë˜ìŠ¤ êµ¬í˜„ (risk/stop_loss.py):\n```python\nclass AutoStopLoss:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.trailing_stops = {}\n        \n    async def check_positions(self, symbol, current_price):\n        # í¬ì§€ì…˜ ì†ì ˆ/ìµì ˆ ì¡°ê±´ í™•ì¸ ë° ìë™ ì£¼ë¬¸ ì‹¤í–‰\n        position = await self._get_position(symbol)\n        if not position:\n            return None\n            \n        # ê³ ì • ì†ì ˆ/ìµì ˆ ì²´í¬\n        if self._check_fixed_stop_loss(position, current_price):\n            return await self._execute_stop_loss(symbol, position)\n            \n        # ìµì ˆ ì²´í¬\n        if self._check_take_profit(position, current_price):\n            return await self._execute_take_profit(symbol, position)\n            \n        # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸ ë° ì²´í¬\n        if self._update_trailing_stop(symbol, position, current_price):\n            return await self._execute_trailing_stop(symbol, position)\n            \n        return None\n        \n    async def _get_position(self, symbol):\n        # DBì—ì„œ í¬ì§€ì…˜ ì •ë³´ ì¡°íšŒ\n        pass\n        \n    def _check_fixed_stop_loss(self, position, current_price):\n        # ê³ ì • ì†ì ˆ ì¡°ê±´ í™•ì¸\n        pass\n        \n    def _check_take_profit(self, position, current_price):\n        # ìµì ˆ ì¡°ê±´ í™•ì¸\n        pass\n        \n    def _update_trailing_stop(self, symbol, position, current_price):\n        # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì—…ë°ì´íŠ¸ ë° ì¡°ê±´ í™•ì¸\n        pass\n        \n    async def _execute_stop_loss(self, symbol, position):\n        # ì†ì ˆ ì£¼ë¬¸ ì‹¤í–‰\n        pass\n        \n    async def _execute_take_profit(self, symbol, position):\n        # ìµì ˆ ì£¼ë¬¸ ì‹¤í–‰\n        pass\n        \n    async def _execute_trailing_stop(self, symbol, position):\n        # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ì£¼ë¬¸ ì‹¤í–‰\n        pass\n```\n\n4. RiskMonitor í´ë˜ìŠ¤ êµ¬í˜„ (risk/monitor.py):\n```python\nclass RiskMonitor:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.metrics = {}\n        \n    async def update_metrics(self):\n        # ë¦¬ìŠ¤í¬ ì§€í‘œ ì—…ë°ì´íŠ¸\n        await self._update_portfolio_metrics()\n        await self._update_exposure_metrics()\n        await self._update_pnl_metrics()\n        await self._check_risk_thresholds()\n        \n    async def _update_portfolio_metrics(self):\n        # í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ì§€í‘œ ì—…ë°ì´íŠ¸\n        pass\n        \n    async def _update_exposure_metrics(self):\n        # ìµìŠ¤í¬ì € ì§€í‘œ ì—…ë°ì´íŠ¸\n        pass\n        \n    async def _update_pnl_metrics(self):\n        # ì†ìµ ì§€í‘œ ì—…ë°ì´íŠ¸\n        pass\n        \n    async def _check_risk_thresholds(self):\n        # ë¦¬ìŠ¤í¬ ì„ê³„ê°’ í™•ì¸ ë° ì•Œë¦¼\n        pass\n        \n    async def get_risk_report(self):\n        # ë¦¬ìŠ¤í¬ ë³´ê³ ì„œ ìƒì„±\n        pass\n```\n\n5. EmergencyStop í´ë˜ìŠ¤ êµ¬í˜„ (risk/emergency.py):\n```python\nclass EmergencyStop:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.is_active = False\n        self.reason = None\n        \n    async def check_conditions(self):\n        # ë¹„ìƒ ì •ì§€ ì¡°ê±´ í™•ì¸\n        if self.is_active:\n            return True\n            \n        # ì¼ì¼ ì†ì‹¤ í•œë„ ì´ˆê³¼ í™•ì¸\n        if await self._check_daily_loss_limit():\n            return await self._activate(\"ì¼ì¼ ì†ì‹¤ í•œë„ ì´ˆê³¼\")\n            \n        # ì›”ê°„ ì†ì‹¤ í•œë„ ì´ˆê³¼ í™•ì¸\n        if await self._check_monthly_loss_limit():\n            return await self._activate(\"ì›”ê°„ ì†ì‹¤ í•œë„ ì´ˆê³¼\")\n            \n        # ì—°ì† ì†ì‹¤ í™•ì¸\n        if await self._check_consecutive_losses():\n            return await self._activate(\"ì—°ì† ì†ì‹¤ ë°œìƒ\")\n            \n        # ì‹œìŠ¤í…œ ì´ìƒ í™•ì¸\n        if await self._check_system_anomalies():\n            return await self._activate(\"ì‹œìŠ¤í…œ ì´ìƒ ê°ì§€\")\n            \n        return False\n        \n    async def _check_daily_loss_limit(self):\n        # ì¼ì¼ ì†ì‹¤ í•œë„ ì´ˆê³¼ í™•ì¸\n        return self.risk_engine.daily_pnl < -self.risk_engine.config['max_daily_loss']\n        \n    async def _check_monthly_loss_limit(self):\n        # ì›”ê°„ ì†ì‹¤ í•œë„ ì´ˆê³¼ í™•ì¸\n        return self.risk_engine.monthly_pnl < -self.risk_engine.config['max_monthly_loss']\n        \n    async def _check_consecutive_losses(self):\n        # ì—°ì† ì†ì‹¤ í™•ì¸\n        return self.risk_engine.consecutive_losses >= 5\n        \n    async def _check_system_anomalies(self):\n        # ì‹œìŠ¤í…œ ì´ìƒ í™•ì¸\n        pass\n        \n    async def _activate(self, reason):\n        # ë¹„ìƒ ì •ì§€ í™œì„±í™”\n        self.is_active = True\n        self.reason = reason\n        await self._notify_emergency_stop()\n        return True\n        \n    async def reset(self):\n        # ë¹„ìƒ ì •ì§€ í•´ì œ\n        self.is_active = False\n        self.reason = None\n        \n    async def _notify_emergency_stop(self):\n        # ë¹„ìƒ ì •ì§€ ì•Œë¦¼\n        event = {\n            'type': 'emergency_stop',\n            'reason': self.reason,\n            'timestamp': datetime.now().isoformat()\n        }\n        # Redis Pub/Subìœ¼ë¡œ ì´ë²¤íŠ¸ ë°œí–‰\n        # await redis_client.publish('risk_alerts', json.dumps(event))\n```\n\n6. ì´ë²¤íŠ¸ íë¦„ êµ¬í˜„:\n   - ì£¼ë¬¸ ìš”ì²­ â†’ ë¦¬ìŠ¤í¬ ì²´í¬ (RPC) â†’ ìŠ¹ì¸/ê±°ë¶€ ì‘ë‹µ â†’ risk_alert ë°œí–‰\n   - ì‹¤ì‹œê°„ í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ â†’ ì†ì ˆ/ìµì ˆ ì¡°ê±´ í™•ì¸ â†’ ìë™ ì£¼ë¬¸ ì‹¤í–‰\n   - ë¦¬ìŠ¤í¬ ì§€í‘œ ëª¨ë‹ˆí„°ë§ â†’ ì„ê³„ê°’ ì ‘ê·¼ ì‹œ ì•Œë¦¼ ë°œí–‰\n   - ë¹„ìƒ ì •ì§€ ì¡°ê±´ í™•ì¸ â†’ ë¹„ìƒ ì •ì§€ í™œì„±í™” â†’ ì•Œë¦¼ ë°œí–‰\n\n7. í¬ì§€ì…˜ í¬ê¸° ê´€ë¦¬:\n   - Kelly Criterion êµ¬í˜„\n   - ê³ ì • ë¹„ìœ¨/ê¸ˆì•¡ ë°©ì‹\n   - ë³€ë™ì„± ê¸°ë°˜ í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ\n\n8. í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬:\n   - ì¢…ëª©ë³„ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨\n   - ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì\n   - ìƒê´€ê´€ê³„ ë¶„ì„",
        "testStrategy": "1. RPC ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤í¬ ì²´í¬ í…ŒìŠ¤íŠ¸:\n   - ë‹¤ì–‘í•œ ì£¼ë¬¸ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ìŠ¹ì¸/ê±°ë¶€ ì‘ë‹µ í…ŒìŠ¤íŠ¸\n   - ë¦¬ìŠ¤í¬ ê·œì¹™ë³„ ê²€ì¦ ë¡œì§ í…ŒìŠ¤íŠ¸\n   - ì‘ë‹µ ì‹œê°„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (10ms ì´ë‚´ ëª©í‘œ)\n\n2. ìë™ ì†ì ˆ/ìµì ˆ í…ŒìŠ¤íŠ¸:\n   - ê³ ì • ì†ì ˆ/ìµì ˆ ì¡°ê±´ í…ŒìŠ¤íŠ¸\n   - íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë¡œì§ í…ŒìŠ¤íŠ¸\n   - ìë™ ì£¼ë¬¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n\n3. ë¦¬ìŠ¤í¬ ì•Œë¦¼ í…ŒìŠ¤íŠ¸:\n   - risk_alert ì´ë²¤íŠ¸ ë°œí–‰ í…ŒìŠ¤íŠ¸\n   - ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì • í…ŒìŠ¤íŠ¸\n   - ì•Œë¦¼ ë©”ì‹œì§€ í¬ë§· ë° ë‚´ìš© ê²€ì¦\n\n4. ë¹„ìƒ ì •ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n   - ë‹¤ì–‘í•œ ë¹„ìƒ ì •ì§€ ì¡°ê±´ í…ŒìŠ¤íŠ¸\n   - ë¹„ìƒ ì •ì§€ í™œì„±í™” ë° í•´ì œ í…ŒìŠ¤íŠ¸\n   - ë¹„ìƒ ì •ì§€ ì•Œë¦¼ í…ŒìŠ¤íŠ¸\n\n5. í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸\n6. ì†ì ˆ/ìµì ˆ ë¡œì§ í…ŒìŠ¤íŠ¸\n7. ì¼ì¼/ì›”ê°„ ì†ì‹¤ í•œë„ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n8. í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚° íˆ¬ì ë¡œì§ í…ŒìŠ¤íŠ¸\n9. ê±°ë˜ ë¹ˆë„ ì œí•œ í…ŒìŠ¤íŠ¸\n10. ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™© ì‹œë®¬ë ˆì´ì…˜\n11. ë¦¬ìŠ¤í¬ ì„¤ì • ë³€ê²½ í…ŒìŠ¤íŠ¸\n12. ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚° ë° ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸\n13. ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™ í…ŒìŠ¤íŠ¸\n14. í†µí•© í…ŒìŠ¤íŠ¸: ì „ì²´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ íë¦„ ê²€ì¦",
        "subtasks": [
          {
            "id": 1,
            "title": "RiskEngine í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "RPC ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤í¬ ì²´í¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” RiskEngine í´ë˜ìŠ¤ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "RiskRules í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ë‹¤ì–‘í•œ ë¦¬ìŠ¤í¬ ê·œì¹™ì„ ê²€ì¦í•˜ëŠ” RiskRules í´ë˜ìŠ¤ êµ¬í˜„ (í¬ì§€ì…˜ í¬ê¸°, ì„¹í„° ìµìŠ¤í¬ì €, ì†ì‹¤ í•œë„ ë“±)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "AutoStopLoss/TakeProfit í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ìë™ ì†ì ˆ/ìµì ˆ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤ êµ¬í˜„ (ê³ ì • ì†ì ˆ/ìµì ˆ, íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "RiskMonitor í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ì‹¤ì‹œê°„ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "EmergencyStop í´ë˜ìŠ¤ êµ¬í˜„",
            "description": "ë¹„ìƒ ì •ì§€ ì‹œìŠ¤í…œ êµ¬í˜„ (ì¼ì¼/ì›”ê°„ ì†ì‹¤ í•œë„ ì´ˆê³¼, ì—°ì† ì†ì‹¤, ì‹œìŠ¤í…œ ì´ìƒ ë“±)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ì´ë²¤íŠ¸ ë°œí–‰ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "risk_alert ë° emergency_stop ì´ë²¤íŠ¸ ë°œí–‰ ì‹œìŠ¤í…œ êµ¬í˜„ (Redis Pub/Sub í™œìš©)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "í¬ì§€ì…˜ í¬ê¸° ê´€ë¦¬ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„",
            "description": "Kelly Criterion, ê³ ì • ë¹„ìœ¨/ê¸ˆì•¡, ë³€ë™ì„± ê¸°ë°˜ í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê¸°ëŠ¥ êµ¬í˜„",
            "description": "ì¢…ëª©ë³„ ìµœëŒ€ íˆ¬ì ë¹„ìœ¨, ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì, ìƒê´€ê´€ê³„ ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "í†µí•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ìµœì í™”",
            "description": "ì „ì²´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ìµœì í™”",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 30,
        "title": "FastAPI ë°±ì—”ë“œ ì„œë²„ êµ¬í˜„",
        "description": "ì‹œìŠ¤í…œ ì œì–´, ë°ì´í„° ì¡°íšŒ, ì „ëµ ê´€ë¦¬ë¥¼ ìœ„í•œ RESTful API ì„œë²„ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          19,
          23,
          25,
          28,
          29
        ],
        "priority": "medium",
        "details": "1. FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • (api/app.py):\n```python\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(title=\"QB Trading API\", version=\"1.0.0\")\n\n# CORS ì„¤ì •\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# ë¼ìš°í„° ë“±ë¡\nfrom api.routers import data, strategies, orders, system\n\napp.include_router(data.router, prefix=\"/api/data\", tags=[\"data\"])\napp.include_router(strategies.router, prefix=\"/api/strategies\", tags=[\"strategies\"])\napp.include_router(orders.router, prefix=\"/api/orders\", tags=[\"orders\"])\napp.include_router(system.router, prefix=\"/api/system\", tags=[\"system\"])\n```\n2. ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„:\n   - ë°ì´í„° ì¡°íšŒ API\n   - ì „ëµ ê´€ë¦¬ API\n   - ì£¼ë¬¸ ê´€ë¦¬ API\n   - ì‹œìŠ¤í…œ ì œì–´ API\n3. ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬:\n   - JWT ê¸°ë°˜ ì¸ì¦\n   - API í‚¤ ì¸ì¦\n4. ìš”ì²­ ê²€ì¦ ë° ì—ëŸ¬ ì²˜ë¦¬\n5. API ë¬¸ì„œí™” (Swagger/ReDoc)\n6. ì›¹ì†Œì¼“ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„:\n   - ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„°\n   - ì‹¤ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸\n   - ì‹œìŠ¤í…œ ì•Œë¦¼\n7. ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ (Background Tasks)\n8. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´\n9. ì†ë„ ì œí•œ ë° ìºì‹± êµ¬í˜„\n10. í”„ë¡ íŠ¸ì—”ë“œ ì§€ì› ë° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§/ê´€ë¦¬ ê¸°ëŠ¥ í†µí•©",
        "testStrategy": "1. ê° API ì—”ë“œí¬ì¸íŠ¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n2. ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n3. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n4. ì›¹ì†Œì¼“ ì—°ê²° ë° ë°ì´í„° ì „ì†¡ í…ŒìŠ¤íŠ¸\n5. ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n6. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸\n7. ì†ë„ ì œí•œ ë° ìºì‹± í…ŒìŠ¤íŠ¸\n8. ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ë™ì‹œ ìš”ì²­ ì²˜ë¦¬)\n9. API ë¬¸ì„œ ì •í™•ì„± í…ŒìŠ¤íŠ¸\n10. í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ í…ŒìŠ¤íŠ¸\n11. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "ê¸°ë³¸ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •",
            "description": "FastAPI ê¸°ë³¸ ì„¤ì •, CORS ë¯¸ë“¤ì›¨ì–´ ë° ë¼ìš°í„° êµ¬ì¡° ì„¤ì •",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "ë°ì´í„° ì¡°íšŒ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
            "description": "ì‹œì¥ ë°ì´í„°, ì°¨íŠ¸ ë°ì´í„°, ì¢…ëª© ì •ë³´ ë“± ì¡°íšŒ API êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "ì „ëµ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
            "description": "ì „ëµ ìƒì„±, ìˆ˜ì •, ì‚­ì œ, í™œì„±í™”/ë¹„í™œì„±í™” API êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ API êµ¬í˜„",
            "description": "ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§, ë¡œê·¸ ì¡°íšŒ, ì„¤ì • ë³€ê²½ API êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "JWT ê¸°ë°˜ ì¸ì¦ ë° API í‚¤ ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ì›¹ì†Œì¼“ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
            "description": "ì‹¤ì‹œê°„ ë°ì´í„° ì „ì†¡ì„ ìœ„í•œ ì›¹ì†Œì¼“ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 31,
        "title": "Next.js í”„ë¡ íŠ¸ì—”ë“œ ê¸°ë³¸ êµ¬ì¡° êµ¬í˜„",
        "description": "Next.js 14ì™€ TypeScriptë¥¼ í™œìš©í•œ ì›¹ ëŒ€ì‹œë³´ë“œ ê¸°ë³¸ êµ¬ì¡° ë° ë ˆì´ì•„ì›ƒ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          19
        ],
        "priority": "low",
        "details": "1. Next.js 14 í”„ë¡œì íŠ¸ ì„¤ì •:\n```bash\nnpx create-next-app@latest qb-dashboard --typescript --tailwind --eslint\ncd qb-dashboard\nnpm install shadcn-ui @radix-ui/react-icons\n```\n2. í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„:\n```\nsrc/\n  â”œâ”€â”€ app/             # Next.js 14 App Router\n  â”œâ”€â”€ components/      # UI ì»´í¬ë„ŒíŠ¸\n  â”œâ”€â”€ lib/             # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n  â”œâ”€â”€ hooks/           # ì»¤ìŠ¤í…€ í›…\n  â”œâ”€â”€ api/             # API í´ë¼ì´ì–¸íŠ¸\n  â””â”€â”€ types/           # TypeScript íƒ€ì… ì •ì˜\n```\n3. Shadcn UI ë° Tailwind CSS ì„¤ì •:\n```bash\nnpx shadcn-ui@latest init\n```\n4. ê¸°ë³¸ ë ˆì´ì•„ì›ƒ êµ¬í˜„:\n   - í—¤ë”/í‘¸í„°\n   - ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜\n   - ë‹¤í¬/ë¼ì´íŠ¸ í…Œë§ˆ ì§€ì›\n5. ì£¼ìš” í˜ì´ì§€ êµ¬ì¡° ì„¤ê³„:\n   - ëŒ€ì‹œë³´ë“œ í™ˆ\n   - í¬íŠ¸í´ë¦¬ì˜¤ í˜„í™©\n   - ì „ëµ ê´€ë¦¬\n   - ê±°ë˜ ë‚´ì—­\n   - ì„¤ì •\n6. ë°˜ì‘í˜• ë””ìì¸ êµ¬í˜„\n7. ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„ (NextAuth.js)\n8. API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (axios ë˜ëŠ” fetch ë˜í¼)\n9. ìƒíƒœ ê´€ë¦¬ ì„¤ì • (React Context ë˜ëŠ” Zustand)\n\nì°¸ê³ : ë°±ì—”ë“œ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì™„ì„± í›„ ê°œë°œ ì˜ˆì •. í”„ë¡ íŠ¸ì—”ë“œëŠ” ì‹œê°ì  ìš”ì†Œë¡œ ì‹¤ì œ ë§¤ë§¤ ì‹œì‘ì—ëŠ” í•„ìˆ˜ì ì´ì§€ ì•ŠìŒ.",
        "testStrategy": "1. í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ì„¤ì • ê²€ì¦\n2. ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n3. ë°˜ì‘í˜• ë””ìì¸ í…ŒìŠ¤íŠ¸\n4. í…Œë§ˆ ì „í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n5. ë„¤ë¹„ê²Œì´ì…˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n6. API í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸\n7. ì¸ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n8. ìƒíƒœ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n9. ì ‘ê·¼ì„± (a11y) í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "ì‹¤ì‹œê°„ ì°¨íŠ¸ ë° ë°ì´í„° ì‹œê°í™” êµ¬í˜„",
        "description": "TradingView Charting Library ë˜ëŠ” Chart.jsë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì°¨íŠ¸ ë° ë°ì´í„° ì‹œê°í™” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          31,
          30
        ],
        "priority": "low",
        "details": "1. TradingView Charting Library í†µí•©:\n```typescript\n// components/TradingViewChart.tsx\nimport { useEffect, useRef } from 'react';\nimport { widget } from '../lib/charting_library/charting_library.min';\n\ninterface ChartProps {\n  symbol: string;\n  interval: string;\n  containerId: string;\n}\n\nexport default function TradingViewChart({ symbol, interval, containerId }: ChartProps) {\n  const chartRef = useRef<any>(null);\n\n  useEffect(() => {\n    const widgetOptions = {\n      symbol: symbol,\n      datafeed: new CustomDatafeed(),\n      interval: interval,\n      container: containerId,\n      library_path: '/charting_library/',\n      locale: 'ko',\n      timezone: 'Asia/Seoul',\n      // ì¶”ê°€ ì˜µì…˜ ì„¤ì •\n    };\n\n    chartRef.current = new widget(widgetOptions);\n\n    return () => {\n      if (chartRef.current) {\n        chartRef.current.remove();\n        chartRef.current = null;\n      }\n    };\n  }, [symbol, interval, containerId]);\n\n  return <div id={containerId} className=\"h-[500px] w-full\" />;\n}\n```\n2. ì»¤ìŠ¤í…€ ë°ì´í„°í”¼ë“œ êµ¬í˜„:\n   - ì‹¤ì‹œê°„ WebSocket ë°ì´í„° ì—°ë™\n   - ê³¼ê±° ë°ì´í„° ë¡œë”©\n   - ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ë° í‘œì‹œ\n3. ëŒ€ì²´ ì°¨íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Chart.js) êµ¬í˜„:\n   - ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸\n   - ê¸°ìˆ ì  ì§€í‘œ ì˜¤ë²„ë ˆì´\n   - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸\n4. ì¶”ê°€ ë°ì´í„° ì‹œê°í™” ì»´í¬ë„ŒíŠ¸:\n   - í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± íŒŒì´/ë„ë„› ì°¨íŠ¸\n   - ìˆ˜ìµë¥  ë¼ì¸/ë°” ì°¨íŠ¸\n   - íˆíŠ¸ë§µ (ì›”ê°„/ì—°ê°„ ì„±ê³¼)\n   - ê±°ë˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n5. ëŒ€ì‹œë³´ë“œ ìœ„ì ¯ êµ¬í˜„:\n   - ì‹¤ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜\n   - ì¼ì¼/ì›”ê°„ ìˆ˜ìµë¥ \n   - ì£¼ìš” ì§€í‘œ ìš”ì•½\n   - ìµœê·¼ ê±°ë˜ ë‚´ì—­\n6. ì°¨íŠ¸ ìƒí˜¸ì‘ìš© ê¸°ëŠ¥:\n   - ì¤Œì¸/ì¤Œì•„ì›ƒ\n   - ì‹œê°„ ë²”ìœ„ ì„ íƒ\n   - ì§€í‘œ ì¶”ê°€/ì œê±°\n   - ì£¼ë¬¸ í‘œì‹œ ë° ìƒì„±\n\nì°¸ê³ : ì´ ê¸°ëŠ¥ì€ ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ ë‚˜ì¤‘ì— ê°œë°œí•  ë¶€ê°€ ê¸°ëŠ¥ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. í•µì‹¬ íŠ¸ë ˆì´ë”© ê¸°ëŠ¥ì´ ìš°ì„ ì ìœ¼ë¡œ ê°œë°œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "testStrategy": "1. ì°¨íŠ¸ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n2. ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸\n3. ê³¼ê±° ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸\n4. ë‹¤ì–‘í•œ ê¸°ìˆ ì  ì§€í‘œ í‘œì‹œ í…ŒìŠ¤íŠ¸\n5. ì°¨íŠ¸ ìƒí˜¸ì‘ìš© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n6. ë‹¤ì–‘í•œ ì‹œê°„ í”„ë ˆì„ ì „í™˜ í…ŒìŠ¤íŠ¸\n7. ëŒ€ì‹œë³´ë“œ ìœ„ì ¯ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n8. ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸\n9. ë‹¤ì–‘í•œ ë¸Œë¼ìš°ì €/ê¸°ê¸° í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "ê°œë°œ ìš°ì„ ìˆœìœ„ ì¡°ì •",
            "description": "ì‹¤ì‹œê°„ ì°¨íŠ¸ ë° ë°ì´í„° ì‹œê°í™”ëŠ” ë¶€ê°€ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ ê°œë°œí•˜ë„ë¡ ìš°ì„ ìˆœìœ„ ì¡°ì •",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 33,
        "title": "WebSocket ì‹¤ì‹œê°„ í†µì‹  êµ¬í˜„",
        "description": "í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ ê°„ WebSocketì„ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° í†µì‹  ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          30,
          31
        ],
        "priority": "low",
        "details": "1. ë°±ì—”ë“œ WebSocket ì„œë²„ êµ¬í˜„ (api/websocket.py):\n```python\nfrom fastapi import WebSocket, WebSocketDisconnect\nfrom typing import Dict, List, Any\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: Dict[str, List[WebSocket]] = {}\n        \n    async def connect(self, websocket: WebSocket, client_id: str, channel: str):\n        await websocket.accept()\n        if channel not in self.active_connections:\n            self.active_connections[channel] = []\n        self.active_connections[channel].append((client_id, websocket))\n        \n    def disconnect(self, websocket: WebSocket, client_id: str, channel: str):\n        if channel in self.active_connections:\n            self.active_connections[channel] = [\n                (cid, ws) for cid, ws in self.active_connections[channel] \n                if cid != client_id\n            ]\n            \n    async def broadcast(self, message: Any, channel: str):\n        if channel in self.active_connections:\n            for client_id, connection in self.active_connections[channel]:\n                try:\n                    await connection.send_json(message)\n                except WebSocketDisconnect:\n                    self.disconnect(connection, client_id, channel)\n\nmanager = ConnectionManager()\n```\n2. WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„:\n   - ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„° ì±„ë„\n   - í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ ì±„ë„\n   - ì£¼ë¬¸ ìƒíƒœ ì±„ë„\n   - ì‹œìŠ¤í…œ ì•Œë¦¼ ì±„ë„\n3. í”„ë¡ íŠ¸ì—”ë“œ WebSocket í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ (hooks/useWebSocket.ts):\n```typescript\nimport { useState, useEffect, useCallback } from 'react';\n\ninterface WebSocketOptions {\n  url: string;\n  onMessage?: (data: any) => void;\n  onOpen?: () => void;\n  onClose?: () => void;\n  onError?: (error: Event) => void;\n  reconnect?: boolean;\n  reconnectInterval?: number;\n  maxReconnectAttempts?: number;\n}\n\nexport function useWebSocket(options: WebSocketOptions) {\n  const [socket, setSocket] = useState<WebSocket | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const [reconnectAttempts, setReconnectAttempts] = useState(0);\n  \n  // WebSocket ì—°ê²° í•¨ìˆ˜\n  const connect = useCallback(() => {\n    const ws = new WebSocket(options.url);\n    \n    ws.onopen = () => {\n      setIsConnected(true);\n      setReconnectAttempts(0);\n      if (options.onOpen) options.onOpen();\n    };\n    \n    ws.onmessage = (event) => {\n      if (options.onMessage) {\n        try {\n          const data = JSON.parse(event.data);\n          options.onMessage(data);\n        } catch (error) {\n          options.onMessage(event.data);\n        }\n      }\n    };\n    \n    ws.onclose = () => {\n      setIsConnected(false);\n      if (options.onClose) options.onClose();\n      \n      // ì¬ì—°ê²° ë¡œì§\n      if (options.reconnect && \n          reconnectAttempts < (options.maxReconnectAttempts || 5)) {\n        setTimeout(() => {\n          setReconnectAttempts(prev => prev + 1);\n          connect();\n        }, options.reconnectInterval || 3000);\n      }\n    };\n    \n    ws.onerror = (error) => {\n      if (options.onError) options.onError(error);\n    };\n    \n    setSocket(ws);\n  }, [options, reconnectAttempts]);\n  \n  // ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜\n  const sendMessage = useCallback((data: any) => {\n    if (socket && isConnected) {\n      socket.send(typeof data === 'string' ? data : JSON.stringify(data));\n      return true;\n    }\n    return false;\n  }, [socket, isConnected]);\n  \n  // ì—°ê²° ì¢…ë£Œ í•¨ìˆ˜\n  const disconnect = useCallback(() => {\n    if (socket) {\n      socket.close();\n      setSocket(null);\n      setIsConnected(false);\n    }\n  }, [socket]);\n  \n  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì—°ê²°\n  useEffect(() => {\n    connect();\n    return () => {\n      if (socket) socket.close();\n    };\n  }, [connect]);\n  \n  return { isConnected, sendMessage, disconnect };\n}\n```\n4. ì‹¤ì‹œê°„ ë°ì´í„° êµ¬ë… ê´€ë¦¬ ì‹œìŠ¤í…œ\n5. ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì¬ì—°ê²°\n6. ë©”ì‹œì§€ í ë° ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”\n7. ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬\n8. ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬í˜„\n\nì°¸ê³ : ì´ ê¸°ëŠ¥ì€ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì™„ì„± í›„ ë‚˜ì¤‘ì— ê°œë°œí•  ì˜ˆì •ì…ë‹ˆë‹¤. í”„ë¡ íŠ¸ì—”ë“œìš© WebSocket í†µì‹ ìœ¼ë¡œ, ì‹¤ì œ íŠ¸ë ˆì´ë”© ì‹œì‘ì„ ìœ„í•´ ìš°ì„ ìˆœìœ„ê°€ ë‚®ì•„ì¡ŒìŠµë‹ˆë‹¤.",
        "testStrategy": "1. WebSocket ì—°ê²° ë° í†µì‹  í…ŒìŠ¤íŠ¸\n2. ë‹¤ì–‘í•œ ì±„ë„ êµ¬ë…/í•´ì œ í…ŒìŠ¤íŠ¸\n3. ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n4. ì—°ê²° ëŠê¹€ ë° ì¬ì—°ê²° í…ŒìŠ¤íŠ¸\n5. ëŒ€ëŸ‰ ë©”ì‹œì§€ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n6. ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n7. ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì—°ê²° í…ŒìŠ¤íŠ¸\n8. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸\n9. ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 34,
        "title": "í¬íŠ¸í´ë¦¬ì˜¤ ë° ê±°ë˜ ë‚´ì—­ ê´€ë¦¬ êµ¬í˜„",
        "description": "í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ, ê±°ë˜ ë‚´ì—­, ì„±ê³¼ ë¶„ì„ì„ ìœ„í•œ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          28,
          29,
          30,
          31
        ],
        "priority": "low",
        "details": "1. í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„ (orders/portfolio.py):\n```python\nclass Portfolio:\n    def __init__(self, db_session, account_id):\n        self.db_session = db_session\n        self.account_id = account_id\n        self.positions = {}\n        self.cash = 0\n        self.initial_capital = 0\n        self.last_updated = None\n        \n    async def load_from_database(self):\n        # DBì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ë¡œë“œ\n        \n    async def update_from_api(self, kis_client):\n        # APIì—ì„œ ìµœì‹  í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ì—…ë°ì´íŠ¸\n        \n    async def add_position(self, symbol, quantity, price):\n        # í¬ì§€ì…˜ ì¶”ê°€ ë¡œì§\n        \n    async def update_position(self, symbol, quantity, price):\n        # í¬ì§€ì…˜ ì—…ë°ì´íŠ¸ ë¡œì§\n        \n    async def remove_position(self, symbol):\n        # í¬ì§€ì…˜ ì œê±° ë¡œì§\n        \n    async def calculate_metrics(self):\n        # í¬íŠ¸í´ë¦¬ì˜¤ ì§€í‘œ ê³„ì‚° (ì´ ê°€ì¹˜, ìˆ˜ìµë¥ , ì„¹í„° ë¶„í¬ ë“±)\n        \n    async def save_to_database(self):\n        # í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ DB ì €ì¥\n```\n2. ê±°ë˜ ë‚´ì—­ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„:\n   - ê±°ë˜ ê¸°ë¡ ì €ì¥ ë° ì¡°íšŒ\n   - ê±°ë˜ë³„ ìˆ˜ìµ/ì†ì‹¤ ê³„ì‚°\n   - ê±°ë˜ í†µê³„ ë¶„ì„\n3. ì„±ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„:\n   - ì¼/ì£¼/ì›”/ì—° ë‹¨ìœ„ ìˆ˜ìµë¥  ê³„ì‚°\n   - ì£¼ìš” ì„±ê³¼ ì§€í‘œ ê³„ì‚° (ìƒ¤í”„ ë¹„ìœ¨, MDD ë“±)\n   - ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ì„±ê³¼ ë¹„êµ\n4. í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê¸°ëŠ¥:\n   - ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì ë¶„ì„\n   - ìƒê´€ê´€ê³„ ë¶„ì„\n   - ë¦¬ë°¸ëŸ°ì‹± ì¶”ì²œ\n5. ì„¸ê¸ˆ ë° ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ì‹œìŠ¤í…œ\n6. í¬íŠ¸í´ë¦¬ì˜¤ ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸° ê¸°ëŠ¥\n7. ë°±ì—”ë“œ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„:\n   - í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ/ì—…ë°ì´íŠ¸ API\n   - ê±°ë˜ ë‚´ì—­ ì¡°íšŒ API\n   - ì„±ê³¼ ë¶„ì„ API\n8. í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„ (ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ ë‚˜ì¤‘ì— ê°œë°œ):\n   - í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½ ëŒ€ì‹œë³´ë“œ\n   - í¬ì§€ì…˜ ëª©ë¡ í…Œì´ë¸”\n   - ê±°ë˜ ë‚´ì—­ í…Œì´ë¸”\n   - ì„±ê³¼ ë¶„ì„ ì°¨íŠ¸",
        "testStrategy": "1. í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n2. ê±°ë˜ ë‚´ì—­ ì €ì¥ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n3. ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸\n4. í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n5. ì„¸ê¸ˆ ë° ìˆ˜ìˆ˜ë£Œ ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸\n6. ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n7. API ì—”ë“œí¬ì¸íŠ¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n8. í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ ì§„í–‰)\n9. ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ í´ë˜ìŠ¤ ê¸°ë³¸ êµ¬í˜„",
            "description": "Portfolio í´ë˜ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡° ë° í•µì‹¬ ë©”ì„œë“œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "ê±°ë˜ ë‚´ì—­ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ê±°ë˜ ê¸°ë¡ ì €ì¥, ì¡°íšŒ ë° ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "ë°±ì—”ë“œ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
            "description": "í¬íŠ¸í´ë¦¬ì˜¤ ë° ê±°ë˜ ë‚´ì—­ ê´€ë ¨ API êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„",
            "description": "ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ UI ì»´í¬ë„ŒíŠ¸ ê°œë°œ (í›„ìˆœìœ„)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 35,
        "title": "ì•Œë¦¼ ë° ë¦¬í¬íŒ… ì‹œìŠ¤í…œ êµ¬í˜„",
        "description": "ì¤‘ìš” ì´ë²¤íŠ¸ ì•Œë¦¼, ì¼ì¼ ê±°ë˜ ìš”ì•½, ì„±ê³¼ ë¦¬í¬íŠ¸ ë“± ì•Œë¦¼ ë° ë¦¬í¬íŒ… ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          28,
          29,
          30,
          31
        ],
        "priority": "low",
        "details": "1. ì•Œë¦¼ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ êµ¬í˜„ (utils/notification.py):\n```python\nclass NotificationSystem:\n    def __init__(self, config=None):\n        self.config = config or {}\n        self.handlers = {\n            'email': EmailNotifier(self.config.get('email')),\n            'slack': SlackNotifier(self.config.get('slack')),\n            'telegram': TelegramNotifier(self.config.get('telegram')),\n            'web': WebNotifier()\n        }\n        \n    async def send_notification(self, message, level='info', channels=None):\n        # ì•Œë¦¼ ì „ì†¡ ë¡œì§\n        channels = channels or ['web']\n        for channel in channels:\n            if channel in self.handlers:\n                await self.handlers[channel].send(message, level)\n                \n    async def send_trade_notification(self, trade_data):\n        # ê±°ë˜ ì•Œë¦¼ ì „ì†¡\n        \n    async def send_risk_alert(self, risk_data):\n        # ë¦¬ìŠ¤í¬ ì•Œë¦¼ ì „ì†¡\n        \n    async def send_system_alert(self, system_data):\n        # ì‹œìŠ¤í…œ ì•Œë¦¼ ì „ì†¡\n        \n    async def send_daily_report(self, report_data):\n        # ì¼ì¼ ë¦¬í¬íŠ¸ ì „ì†¡\n```\n2. ë‹¤ì–‘í•œ ì•Œë¦¼ ì±„ë„ êµ¬í˜„:\n   - ì´ë©”ì¼ ì•Œë¦¼\n   - Slack/Discord ì•Œë¦¼\n   - Telegram ì•Œë¦¼\n   - ì›¹ í‘¸ì‹œ ì•Œë¦¼\n3. ì•Œë¦¼ ìš°ì„ ìˆœìœ„ ë° í•„í„°ë§ ì‹œìŠ¤í…œ:\n   - ì¤‘ìš”ë„ë³„ ì•Œë¦¼ ë¶„ë¥˜\n   - ì‚¬ìš©ì ì„¤ì • ê¸°ë°˜ í•„í„°ë§\n4. ì£¼ìš” ì•Œë¦¼ ì´ë²¤íŠ¸ êµ¬í˜„:\n   - ê±°ë˜ ì‹¤í–‰/ì²´ê²° ì•Œë¦¼\n   - ì†ì ˆ/ìµì ˆ ì•Œë¦¼\n   - ë¦¬ìŠ¤í¬ í•œë„ ì ‘ê·¼/ì´ˆê³¼ ì•Œë¦¼\n   - ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì•Œë¦¼\n5. ì •ê¸° ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ:\n   - ì¼ì¼ ê±°ë˜ ìš”ì•½ ë¦¬í¬íŠ¸\n   - ì£¼ê°„/ì›”ê°„ ì„±ê³¼ ë¦¬í¬íŠ¸\n   - ë¦¬ìŠ¤í¬ ë¶„ì„ ë¦¬í¬íŠ¸\n6. ë¦¬í¬íŠ¸ í…œí”Œë¦¿ ì‹œìŠ¤í…œ:\n   - HTML ì´ë©”ì¼ í…œí”Œë¦¿\n   - PDF ë¦¬í¬íŠ¸ ìƒì„±\n   - ëŒ€ì‹œë³´ë“œ ë‚´ ë¦¬í¬íŠ¸ ë·°\n7. ì•Œë¦¼ ì„¤ì • ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤\n8. ì•Œë¦¼ ì´ë ¥ ì €ì¥ ë° ì¡°íšŒ ê¸°ëŠ¥\n\nì°¸ê³ : ì´ ê¸°ëŠ¥ì€ ì‹¤ì œ ë§¤ë§¤ ì‹œìŠ¤í…œ ì™„ì„± í›„ ë‚˜ì¤‘ì— ê°œë°œí•  ë¶€ê°€ ê¸°ëŠ¥ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.",
        "testStrategy": "1. ë‹¤ì–‘í•œ ì•Œë¦¼ ì±„ë„ ì „ì†¡ í…ŒìŠ¤íŠ¸\n2. ì•Œë¦¼ ìš°ì„ ìˆœìœ„ ë° í•„í„°ë§ í…ŒìŠ¤íŠ¸\n3. ì£¼ìš” ì•Œë¦¼ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸\n4. ì •ê¸° ë¦¬í¬íŠ¸ ìƒì„± ë° ì „ì†¡ í…ŒìŠ¤íŠ¸\n5. ë¦¬í¬íŠ¸ í…œí”Œë¦¿ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n6. ì•Œë¦¼ ì„¤ì • ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n7. ì•Œë¦¼ ì´ë ¥ ì €ì¥ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n8. ëŒ€ëŸ‰ ì•Œë¦¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n9. ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸",
        "subtasks": []
      },
      {
        "id": 36,
        "title": "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… êµ¬í˜„",
        "description": "ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§, ì„±ëŠ¥ ì¶”ì , ë¡œê¹… ë° ì˜¤ë¥˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "status": "pending",
        "dependencies": [
          19,
          30,
          31
        ],
        "priority": "medium",
        "details": "1. ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„ (utils/logging.py):\n```python\nimport logging\nimport sys\nfrom pathlib import Path\nfrom logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\n\nclass LoggingSystem:\n    def __init__(self, log_dir='logs', app_name='qb'):\n        self.log_dir = Path(log_dir)\n        self.log_dir.mkdir(exist_ok=True)\n        self.app_name = app_name\n        self.loggers = {}\n        \n    def get_logger(self, name, level=logging.INFO):\n        if name in self.loggers:\n            return self.loggers[name]\n            \n        logger = logging.getLogger(f\"{self.app_name}.{name}\")\n        logger.setLevel(level)\n        \n        # ì½˜ì†” í•¸ë“¤ëŸ¬\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(self._get_formatter())\n        logger.addHandler(console_handler)\n        \n        # íŒŒì¼ í•¸ë“¤ëŸ¬\n        file_handler = RotatingFileHandler(\n            self.log_dir / f\"{name}.log\",\n            maxBytes=10*1024*1024,  # 10MB\n            backupCount=5\n        )\n        file_handler.setFormatter(self._get_formatter())\n        logger.addHandler(file_handler)\n        \n        # ì—ëŸ¬ íŒŒì¼ í•¸ë“¤ëŸ¬\n        error_handler = RotatingFileHandler(\n            self.log_dir / f\"{name}_error.log\",\n            maxBytes=10*1024*1024,\n            backupCount=5\n        )\n        error_handler.setLevel(logging.ERROR)\n        error_handler.setFormatter(self._get_formatter())\n        logger.addHandler(error_handler)\n        \n        self.loggers[name] = logger\n        return logger\n        \n    def _get_formatter(self):\n        return logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n```\n2. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ êµ¬í˜„:\n   - CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì \n   - ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n   - API ì‘ë‹µ ì‹œê°„ ì¶”ì \n   - ì£¼ë¬¸ ì²˜ë¦¬ ì‹œê°„ ëª¨ë‹ˆí„°ë§\n3. í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ êµ¬í˜„:\n   - ì£¼ìš” ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸\n   - ì™¸ë¶€ API ì—°ê²° ìƒíƒœ í™•ì¸\n   - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸\n   - ì •ê¸°ì ì¸ ìê°€ ì§„ë‹¨\n4. ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ:\n   - ì˜ˆì™¸ ìº¡ì²˜ ë° ë¡œê¹…\n   - ìë™ ì¬ì‹œì‘ ë©”ì»¤ë‹ˆì¦˜\n   - ì¥ì•  ë³µêµ¬ í”„ë¡œì„¸ìŠ¤\n5. ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ë¶„ì„:\n   - ì£¼ìš” ì‘ì—… ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n   - ë³‘ëª© ì§€ì  ì‹ë³„\n   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì„¸ ë¶„ì„\n6. ëŒ€ì‹œë³´ë“œ ëª¨ë‹ˆí„°ë§ í˜ì´ì§€ êµ¬í˜„:\n   - ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½\n   - ë¡œê·¸ ë·°ì–´\n   - ì„±ëŠ¥ ê·¸ë˜í”„\n   - ì•Œë¦¼ ì´ë ¥",
        "testStrategy": "1. ë¡œê¹… ì‹œìŠ¤í…œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n2. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì§€í‘œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸\n3. í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ ì‘ë™ í…ŒìŠ¤íŠ¸\n4. ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²˜ë¦¬ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸\n5. ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ë¶„ì„ í…ŒìŠ¤íŠ¸\n6. ëŒ€ì‹œë³´ë“œ ëª¨ë‹ˆí„°ë§ í˜ì´ì§€ ë Œë”ë§ í…ŒìŠ¤íŠ¸\n7. ë¡œê·¸ ë¡œí…Œì´ì…˜ ë° ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n8. ì¥ê¸°ê°„ ì‹¤í–‰ ì‹œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸\n9. ëŒ€ìš©ëŸ‰ ë¡œê·¸ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "utils/logging.pyì— LoggingSystem í´ë˜ìŠ¤ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ êµ¬í˜„",
            "description": "CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, DB ì„±ëŠ¥, API ì‘ë‹µ ì‹œê°„, ì£¼ë¬¸ ì²˜ë¦¬ ì‹œê°„ ë“± ëª¨ë‹ˆí„°ë§ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ì£¼ìš” ì„œë¹„ìŠ¤, ì™¸ë¶€ API, DB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ìê°€ ì§„ë‹¨ ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ì˜ˆì™¸ ìº¡ì²˜, ë¡œê¹…, ìë™ ì¬ì‹œì‘ ë° ì¥ì•  ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„",
            "description": "ì£¼ìš” ì‘ì—… ì‹¤í–‰ ì‹œê°„ ì¸¡ì •, ë³‘ëª© ì§€ì  ì‹ë³„, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì„¸ ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ëŒ€ì‹œë³´ë“œ ëª¨ë‹ˆí„°ë§ í˜ì´ì§€ êµ¬í˜„",
            "description": "ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½, ë¡œê·¸ ë·°ì–´, ì„±ëŠ¥ ê·¸ë˜í”„, ì•Œë¦¼ ì´ë ¥ ë“±ì„ í‘œì‹œí•˜ëŠ” ëŒ€ì‹œë³´ë“œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 37,
        "title": "GCP Compute Engine ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ë°°í¬ ì¸í”„ë¼ ì„¤ê³„ ë° êµ¬ì¶•",
        "description": "GCP Compute Engine e2-standard-2 VMì— PostgreSQL+TimescaleDB, Redis, Python ë°±ì—”ë“œ, Next.js í”„ë¡ íŠ¸ì—”ë“œë¥¼ Docker Composeë¡œ êµ¬ì„±í•˜ì—¬ 24/7 ì•ˆì •ì  ìš´ì˜ í™˜ê²½ êµ¬ì¶•",
        "status": "pending",
        "dependencies": [
          19,
          20,
          33,
          36
        ],
        "priority": "low",
        "details": "1. GCP Compute Engine ì¸í”„ë¼ ì„¤ê³„:\n   - e2-standard-2 VM ì¸ìŠ¤í„´ìŠ¤ í”„ë¡œë¹„ì €ë‹ (2 vCPU, 8GB RAM)\n   - ì˜êµ¬ ë””ìŠ¤í¬ ì„¤ì •: 100GB SSD (ë°ì´í„°ë² ì´ìŠ¤ ë° ë¡œê·¸ ì €ì¥ìš©)\n   - ë„¤íŠ¸ì›Œí¬ ì„¤ì •: ì •ì  IP í• ë‹¹, ë°©í™”ë²½ ê·œì¹™ êµ¬ì„± (80, 443, 22 í¬íŠ¸ ê°œë°©)\n   - ë¶€í•˜ ë¶„ì‚° ë° ìë™ í™•ì¥ ì„¤ì • ê²€í† \n\n2. Docker Compose ê¸°ë°˜ ë°°í¬ í™˜ê²½ êµ¬ì„±:\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  db:\n    image: timescale/timescaledb:latest-pg15\n    restart: always\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./init-scripts:/docker-entrypoint-initdb.d\n    environment:\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_USER: ${DB_USER}\n      POSTGRES_DB: qb_trading\n    ports:\n      - \"5432:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USER} -d qb_trading\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    restart: always\n    volumes:\n      - redis_data:/data\n    ports:\n      - \"6379:6379\"\n    command: redis-server --appendonly yes\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    environment:\n      - DB_HOST=db\n      - DB_PORT=5432\n      - DB_USER=${DB_USER}\n      - DB_PASSWORD=${DB_PASSWORD}\n      - DB_NAME=qb_trading\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n      - API_KEY=${KIS_API_KEY}\n      - API_SECRET=${KIS_API_SECRET}\n    volumes:\n      - ./backend:/app\n      - ./logs:/app/logs\n    ports:\n      - \"8000:8000\"\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - backend\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NEXT_PUBLIC_API_URL=http://backend:8000\n\n  nginx:\n    image: nginx:alpine\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/conf:/etc/nginx/conf.d\n      - ./nginx/certbot/conf:/etc/letsencrypt\n      - ./nginx/certbot/www:/var/www/certbot\n    depends_on:\n      - frontend\n      - backend\n\n  certbot:\n    image: certbot/certbot\n    volumes:\n      - ./nginx/certbot/conf:/etc/letsencrypt\n      - ./nginx/certbot/www:/var/www/certbot\n\nvolumes:\n  postgres_data:\n  redis_data:\n```\n\n3. ë°±ì—”ë“œ Dockerfile êµ¬ì„±:\n```dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n4. í”„ë¡ íŠ¸ì—”ë“œ Dockerfile êµ¬ì„±:\n```dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package.json package-lock.json ./\nRUN npm ci\n\nCOPY . .\n\nRUN npm run build\n\nCMD [\"npm\", \"start\"]\n```\n\n5. Nginx ì„¤ì • êµ¬ì„±:\n```nginx\n# nginx/conf/default.conf\nserver {\n    listen 80;\n    server_name trading.example.com;\n    \n    location /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n    \n    location / {\n        return 301 https://$host$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl;\n    server_name trading.example.com;\n    \n    ssl_certificate /etc/letsencrypt/live/trading.example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/trading.example.com/privkey.pem;\n    \n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n    \n    location /api {\n        proxy_pass http://backend:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n    \n    location /ws {\n        proxy_pass http://backend:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n    }\n}\n```\n\n6. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì„¤ì •:\n   - Prometheus + Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ êµ¬ì„±\n   - ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„ì„ ìœ„í•œ ELK ìŠ¤íƒ ë˜ëŠ” Loki ì„¤ì •\n   - ì‹œìŠ¤í…œ ìƒíƒœ ì•Œë¦¼ ì„¤ì • (Slack, ì´ë©”ì¼)\n\n7. ë°±ì—… ë° ë³µêµ¬ ì „ëµ:\n   - ë°ì´í„°ë² ì´ìŠ¤ ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„\n   - GCP Cloud Storageë¥¼ í™œìš©í•œ ë°±ì—… ì €ì¥\n   - ì¥ì•  ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”\n\n8. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì„±:\n   - GitHub Actions ë˜ëŠ” GitLab CIë¥¼ í™œìš©í•œ ìë™ ë°°í¬\n   - í…ŒìŠ¤íŠ¸ ìë™í™” ë° ë°°í¬ ì „ ê²€ì¦\n   - ë¡¤ë°± ì „ëµ ìˆ˜ë¦½\n\n9. ë³´ì•ˆ ê°•í™”:\n   - í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•œ ë¯¼ê° ì •ë³´ ê´€ë¦¬\n   - ë°©í™”ë²½ ê·œì¹™ ìµœì†Œí™”\n   - ì •ê¸°ì ì¸ ë³´ì•ˆ ì—…ë°ì´íŠ¸ ì ìš© ê³„íš\n   - SSL/TLS ì¸ì¦ì„œ ìë™ ê°±ì‹  ì„¤ì •\n\n10. ìš´ì˜ ë¬¸ì„œ ì‘ì„±:\n    - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨\n    - ë°°í¬ ë° ì—…ë°ì´íŠ¸ ì ˆì°¨\n    - ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n    - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•",
        "testStrategy": "1. GCP ì¸í”„ë¼ ê²€ì¦:\n   - VM ì¸ìŠ¤í„´ìŠ¤ í”„ë¡œë¹„ì €ë‹ ë° ì ‘ì† í…ŒìŠ¤íŠ¸\n   - ë””ìŠ¤í¬ ë§ˆìš´íŠ¸ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (dd, fio ë„êµ¬ í™œìš©)\n   - ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± ë° ë°©í™”ë²½ ê·œì¹™ í…ŒìŠ¤íŠ¸\n\n2. Docker Compose í™˜ê²½ í…ŒìŠ¤íŠ¸:\n   - `docker-compose up -d` ëª…ë ¹ìœ¼ë¡œ ì „ì²´ ìŠ¤íƒ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n   - ê° ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸: `docker-compose ps`\n   - ì»¨í…Œì´ë„ˆ ê°„ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± í…ŒìŠ¤íŠ¸\n   - ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸: `docker-compose logs`\n\n3. ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦:\n   - PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸: `psql -h localhost -U <user> -d qb_trading`\n   - TimescaleDB í™•ì¥ í™œì„±í™” í™•ì¸: `SELECT * FROM pg_extension;`\n   - í…Œì´ë¸” ë° í•˜ì´í¼í…Œì´ë¸” ìƒì„± í…ŒìŠ¤íŠ¸\n   - ë°ì´í„° ì‚½ì… ë° ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n\n4. Redis ê²€ì¦:\n   - Redis ì—°ê²° í…ŒìŠ¤íŠ¸: `redis-cli ping`\n   - ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸\n   - ì˜ì†ì„± ì„¤ì • ê²€ì¦ (ì¬ì‹œì‘ í›„ ë°ì´í„° ìœ ì§€ ì—¬ë¶€)\n\n5. ë°±ì—”ë“œ API í…ŒìŠ¤íŠ¸:\n   - í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸: `curl http://localhost:8000/health`\n   - ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Postman ë˜ëŠ” curl í™œìš©)\n   - WebSocket ì—°ê²° ë° ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  í…ŒìŠ¤íŠ¸\n\n6. í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸:\n   - ì›¹ í˜ì´ì§€ ë¡œë”© í…ŒìŠ¤íŠ¸: `curl http://localhost:3000`\n   - ë¸Œë¼ìš°ì €ì—ì„œ UI ë Œë”ë§ í™•ì¸\n   - API ì—°ë™ ë° ë°ì´í„° í‘œì‹œ í…ŒìŠ¤íŠ¸\n   - ë°˜ì‘í˜• ë””ìì¸ í…ŒìŠ¤íŠ¸ (ë‹¤ì–‘í•œ í™”ë©´ í¬ê¸°)\n\n7. Nginx ë° SSL í…ŒìŠ¤íŠ¸:\n   - HTTPì—ì„œ HTTPS ë¦¬ë‹¤ì´ë ‰ì…˜ í…ŒìŠ¤íŠ¸\n   - SSL ì¸ì¦ì„œ ìœ íš¨ì„± í™•ì¸: `openssl s_client -connect trading.example.com:443`\n   - í”„ë¡ì‹œ ì„¤ì • í…ŒìŠ¤íŠ¸ (API ë° WebSocket ìš”ì²­)\n\n8. ë¶€í•˜ í…ŒìŠ¤íŠ¸:\n   - ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Apache Bench, JMeter ë“± í™œìš©)\n   - ë™ì‹œ ì‚¬ìš©ì ì ‘ì† í…ŒìŠ¤íŠ¸\n   - ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (24ì‹œê°„ ì´ìƒ)\n\n9. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… í…ŒìŠ¤íŠ¸:\n   - Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸\n   - Grafana ëŒ€ì‹œë³´ë“œ ì ‘ê·¼ ë° ë°ì´í„° í‘œì‹œ í…ŒìŠ¤íŠ¸\n   - ë¡œê·¸ ì§‘ê³„ ì‹œìŠ¤í…œ ì‘ë™ í™•ì¸\n   - ì•Œë¦¼ ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸\n\n10. ì¥ì•  ë³µêµ¬ í…ŒìŠ¤íŠ¸:\n    - ì»¨í…Œì´ë„ˆ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ ë° ìë™ ë³µêµ¬ í…ŒìŠ¤íŠ¸\n    - ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ë° ë³µì› í…ŒìŠ¤íŠ¸\n    - ì „ì²´ ì‹œìŠ¤í…œ ì¬ì‹œì‘ í…ŒìŠ¤íŠ¸\n    - ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ ì‹œë®¬ë ˆì´ì…˜ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸",
        "subtasks": [
          {
            "id": 1,
            "title": "ë°°í¬ ìš°ì„ ìˆœìœ„ ì¡°ì • ë° ê°œë°œ ì™„ë£Œ í›„ ì§„í–‰ ê³„íš ìˆ˜ë¦½",
            "description": "ì‹¤ì œ íŠ¸ë ˆì´ë”© ì‹œì‘ì„ ìœ„í•´ ë°°í¬ ì‘ì—…ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë‚®ì¶”ê³ , ê°œë°œ ì™„ë£Œ í›„ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ê³„íš ìˆ˜ë¦½",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 38,
        "title": "Docker Compose ê¸°ë°˜ GCP ë¬´ë£Œ VM ë°°í¬ ì‹œìŠ¤í…œ êµ¬í˜„",
        "description": "1GB RAMê³¼ 1 vCPU ì œì•½ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ PostgreSQL, TimescaleDB, Redis, FastAPI, Next.jsë¥¼ Docker ì»¨í…Œì´ë„ˆë¡œ êµ¬ì„±í•˜ê³  ì›í´ë¦­ ë°°í¬ê°€ ê°€ëŠ¥í•œ ìµœì í™”ëœ ë°°í¬ ì‹œìŠ¤í…œ êµ¬í˜„. ì•„í‚¤í…ì²˜ ì„¤ê³„ ë¬¸ì„œì— ë”°ë¼ 8ê°œì˜ ì´ë²¤íŠ¸ ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì—”ì§„ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ ë°°í¬.",
        "status": "pending",
        "dependencies": [
          37,
          20,
          21,
          30,
          31,
          36
        ],
        "priority": "low",
        "details": "1. ë¦¬ì†ŒìŠ¤ ìµœì í™” Docker Compose êµ¬ì„±:\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  db:\n    image: timescale/timescaledb:latest-pg15\n    restart: always\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: ${DB_USER}\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_DB: ${DB_NAME}\n    command: >\n      postgres -c shared_buffers=128MB -c max_connections=20 \n              -c effective_cache_size=256MB -c work_mem=4MB\n              -c maintenance_work_mem=32MB -c random_page_cost=1.1\n    deploy:\n      resources:\n        limits:\n          memory: 300M\n          cpus: '0.3'\n\n  redis:\n    image: redis:7-alpine\n    restart: always\n    volumes:\n      - redis_data:/data\n    command: redis-server --save 60 1 --loglevel warning --maxmemory 100mb --maxmemory-policy allkeys-lru\n    deploy:\n      resources:\n        limits:\n          memory: 150M\n          cpus: '0.1'\n\n  api:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENV_FILE=.env\n    volumes:\n      - ./backend:/app\n      - ./logs:/app/logs\n    deploy:\n      resources:\n        limits:\n          memory: 250M\n          cpus: '0.3'\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - api\n    environment:\n      - NEXT_PUBLIC_API_URL=http://api:8000\n    volumes:\n      - ./frontend:/app\n    deploy:\n      resources:\n        limits:\n          memory: 200M\n          cpus: '0.2'\n\n  nginx:\n    image: nginx:alpine\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./nginx/conf.d:/etc/nginx/conf.d\n      - ./certbot/conf:/etc/letsencrypt\n      - ./certbot/www:/var/www/certbot\n    depends_on:\n      - api\n      - frontend\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.1'\n\n  # ì´ë²¤íŠ¸ ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì—”ì§„ë“¤\n  market_data_engine:\n    build:\n      context: ./engines/market_data\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${MARKET_DATA_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  signal_engine:\n    build:\n      context: ./engines/signal\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${SIGNAL_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  strategy_engine:\n    build:\n      context: ./engines/strategy\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${STRATEGY_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  risk_engine:\n    build:\n      context: ./engines/risk\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${RISK_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  order_engine:\n    build:\n      context: ./engines/order\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${ORDER_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  execution_engine:\n    build:\n      context: ./engines/execution\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${EXECUTION_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  portfolio_engine:\n    build:\n      context: ./engines/portfolio\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${PORTFOLIO_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  analytics_engine:\n    build:\n      context: ./engines/analytics\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${ANALYTICS_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\nvolumes:\n  postgres_data:\n  redis_data:\n```\n\n2. ìµœì í™”ëœ Dockerfile êµ¬ì„±:\n\n```dockerfile\n# backend/Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# ì˜ì¡´ì„± ì„¤ì¹˜ ë ˆì´ì–´ ìµœì í™”\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬\nCOPY . .\n\n# ì‹¤í–‰ ëª…ë ¹\nCMD [\"uvicorn\", \"api.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n```dockerfile\n# frontend/Dockerfile\nFROM node:18-alpine AS builder\n\nWORKDIR /app\n\n# ì˜ì¡´ì„± ì„¤ì¹˜ ë ˆì´ì–´ ìµœì í™”\nCOPY package.json package-lock.json ./\nRUN npm ci\n\n# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬ ë° ë¹Œë“œ\nCOPY . .\nRUN npm run build\n\n# ì‹¤í–‰ ì´ë¯¸ì§€ - ë¹Œë“œ ê²°ê³¼ë¬¼ë§Œ í¬í•¨\nFROM node:18-alpine\n\nWORKDIR /app\n\n# ë¹Œë“œ ê²°ê³¼ë¬¼ë§Œ ë³µì‚¬\nCOPY --from=builder /app/next.config.js ./\nCOPY --from=builder /app/public ./public\nCOPY --from=builder /app/.next ./.next\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/package.json ./\n\n# ì‹¤í–‰ ëª…ë ¹\nCMD [\"npm\", \"start\"]\n```\n\n```dockerfile\n# engines/base/Dockerfile (ê¸°ë³¸ ì—”ì§„ í…œí”Œë¦¿)\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# ì˜ì¡´ì„± ì„¤ì¹˜ ë ˆì´ì–´ ìµœì í™”\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬\nCOPY . .\n\n# ì‹¤í–‰ ëª…ë ¹\nCMD [\"python\", \"main.py\"]\n```\n\n3. ì›í´ë¦­ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ (setup.sh):\n\n```bash\n#!/bin/bash\nset -e\n\n# ìƒ‰ìƒ ì •ì˜\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\necho -e \"${GREEN}===== QB Trading System ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ =====${NC}\"\n\n# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\necho -e \"${YELLOW}í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...${NC}\"\nsudo apt-get update\nsudo apt-get install -y docker.io docker-compose git curl\n\n# Docker ì„œë¹„ìŠ¤ ì‹œì‘ ë° ìë™ ì‹œì‘ ì„¤ì •\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# í˜„ì¬ ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€\nsudo usermod -aG docker $USER\necho \"í˜„ì¬ ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ë ¤ë©´ ì¬ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n\n# í”„ë¡œì íŠ¸ í´ë¡ \necho -e \"${YELLOW}í”„ë¡œì íŠ¸ ì €ì¥ì†Œ í´ë¡  ì¤‘...${NC}\"\ngit clone https://github.com/your-username/qb-trading.git\ncd qb-trading\n\n# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\necho -e \"${YELLOW}í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì¤‘...${NC}\"\ncp .env.example .env\necho \"í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env)ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° ìˆ˜ì •í•´ì£¼ì„¸ìš”.\"\nread -p \"í™˜ê²½ ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \" edit_env\nif [ \"$edit_env\" = \"y\" ]; then\n  nano .env\nfi\n\n# ì—”ì§„ë³„ í™˜ê²½ë³€ìˆ˜ ì„¤ì •\ncat >> .env << 'EOF'\n\n# ì—”ì§„ë³„ ì„¤ì •\nMARKET_DATA_CONFIG='{\"sources\":[\"yahoo\",\"alphavantage\"],\"update_interval\":300}'\nSIGNAL_CONFIG='{\"indicators\":[\"macd\",\"rsi\",\"bollinger\"],\"timeframes\":[\"1m\",\"5m\",\"15m\",\"1h\",\"1d\"]}'\nSTRATEGY_CONFIG='{\"strategies\":[\"momentum\",\"mean_reversion\",\"trend_following\"],\"backtest_period\":30}'\nRISK_CONFIG='{\"max_position_size\":0.05,\"max_drawdown\":0.02,\"stop_loss\":0.01}'\nORDER_CONFIG='{\"default_order_type\":\"limit\",\"time_in_force\":\"gtc\"}'\nEXECUTION_CONFIG='{\"retry_attempts\":3,\"timeout\":10}'\nPORTFOLIO_CONFIG='{\"rebalance_interval\":86400,\"max_positions\":10}'\nANALYTICS_CONFIG='{\"metrics\":[\"sharpe\",\"sortino\",\"max_drawdown\",\"win_rate\"],\"report_interval\":86400}'\nEOF\n\n# ë””ë ‰í† ë¦¬ ìƒì„±\nmkdir -p logs nginx/conf.d certbot/conf certbot/www\nmkdir -p engines/market_data engines/signal engines/strategy engines/risk\nmkdir -p engines/order engines/execution engines/portfolio engines/analytics\n\n# Nginx ì„¤ì • ìƒì„±\ncat > nginx/conf.d/default.conf << 'EOF'\nserver {\n    listen 80;\n    server_name _;\n\n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    location /api {\n        proxy_pass http://api:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    location /ws {\n        proxy_pass http://api:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n    }\n}\nEOF\n\n# ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\ncat > monitor.sh << 'EOF'\n#!/bin/bash\n\n# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë° ë¡œê¹…\nlog_file=\"logs/system_monitor.log\"\nmkdir -p logs\n\ncheck_system() {\n  echo \"===== $(date) =====\" >> $log_file\n  echo \"CPU ì‚¬ìš©ëŸ‰:\" >> $log_file\n  top -bn1 | grep \"Cpu(s)\" >> $log_file\n  echo \"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\" >> $log_file\n  free -m >> $log_file\n  echo \"ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:\" >> $log_file\n  df -h >> $log_file\n  echo \"Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ:\" >> $log_file\n  docker ps >> $log_file\n  echo \"ì»¨í…Œì´ë„ˆë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:\" >> $log_file\n  docker stats --no-stream >> $log_file\n  echo \"\" >> $log_file\n}\n\n# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸ ë° ì¬ì‹œì‘\ncheck_containers() {\n  for container in $(docker-compose ps -q); do\n    if [ ! \"$(docker ps -q -f id=$container)\" ]; then\n      echo \"$(date) - ì»¨í…Œì´ë„ˆ $containerê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ì‹œì‘í•©ë‹ˆë‹¤.\" >> $log_file\n      docker-compose up -d\n      break\n    fi\n  done\n}\n\n# ì—”ì§„ ìƒíƒœ í™•ì¸\ncheck_engines() {\n  engines=(\"market_data_engine\" \"signal_engine\" \"strategy_engine\" \"risk_engine\" \n          \"order_engine\" \"execution_engine\" \"portfolio_engine\" \"analytics_engine\")\n  \n  for engine in \"${engines[@]}\"; do\n    container_id=$(docker-compose ps -q $engine)\n    if [ -z \"$container_id\" ] || [ ! \"$(docker ps -q -f id=$container_id)\" ]; then\n      echo \"$(date) - $engineì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤. ì¬ì‹œì‘í•©ë‹ˆë‹¤.\" >> $log_file\n      docker-compose up -d $engine\n    fi\n  done\n}\n\n# ë””ìŠ¤í¬ ê³µê°„ ì •ë¦¬\ncleanup_disk() {\n  # ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜\n  find logs -name \"*.log\" -size +100M -exec sh -c 'gzip -f \"{}\" && mv \"{}.gz\" \"{}.$(date +%Y%m%d).gz\"' \\;\n  \n  # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ\n  find logs -name \"*.gz\" -mtime +30 -delete\n  \n  # Docker ì •ë¦¬\n  docker system prune -af --volumes >> $log_file 2>&1\n}\n\n# ë©”ì¸ ì‹¤í–‰\ncheck_system\ncheck_containers\ncheck_engines\n\n# ë§¤ì£¼ ì¼ìš”ì¼ ë””ìŠ¤í¬ ì •ë¦¬\nif [ \"$(date +%u)\" = \"7\" ]; then\n  cleanup_disk\nfi\nEOF\n\nchmod +x monitor.sh\n\n# ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\ncat > backup.sh << 'EOF'\n#!/bin/bash\n\n# ì„¤ì •\nBACKUP_DIR=\"backups\"\nDB_CONTAINER=\"qb-trading_db_1\"\nDB_USER=\"${DB_USER:-postgres}\"\nDB_NAME=\"${DB_NAME:-qb_trading}\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"$BACKUP_DIR/db_backup_$TIMESTAMP.sql.gz\"\nRETENTION_DAYS=14\n\n# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±\nmkdir -p $BACKUP_DIR\n\n# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…\necho \"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì¤‘...\"\ndocker exec $DB_CONTAINER pg_dump -U $DB_USER $DB_NAME | gzip > $BACKUP_FILE\n\n# ë°±ì—… íŒŒì¼ ì •ë³´ ì¶œë ¥\necho \"ë°±ì—… ì™„ë£Œ: $BACKUP_FILE ($(du -h $BACKUP_FILE | cut -f1))\"\n\n# ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì‚­ì œ\nfind $BACKUP_DIR -name \"db_backup_*.sql.gz\" -mtime +$RETENTION_DAYS -delete\necho \"$RETENTION_DAYSì¼ ì´ìƒ ì§€ë‚œ ë°±ì—… íŒŒì¼ ì‚­ì œ ì™„ë£Œ\"\nEOF\n\nchmod +x backup.sh\n\n# ë³µì› ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\ncat > restore.sh << 'EOF'\n#!/bin/bash\n\n# ì„¤ì •\nBACKUP_DIR=\"backups\"\nDB_CONTAINER=\"qb-trading_db_1\"\nDB_USER=\"${DB_USER:-postgres}\"\nDB_NAME=\"${DB_NAME:-qb_trading}\"\n\n# ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… íŒŒì¼ ëª©ë¡ í‘œì‹œ\necho \"ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… íŒŒì¼:\"\nls -lh $BACKUP_DIR | grep db_backup\n\n# ë³µì›í•  ë°±ì—… íŒŒì¼ ì„ íƒ\nread -p \"ë³µì›í•  ë°±ì—… íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: \" BACKUP_FILE\n\nif [ ! -f \"$BACKUP_DIR/$BACKUP_FILE\" ]; then\n  echo \"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n  exit 1\nfi\n\n# ë³µì› ì „ í™•ì¸\nread -p \"ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  '$BACKUP_FILE'ì—ì„œ ë³µì›í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \" CONFIRM\nif [ \"$CONFIRM\" != \"y\" ]; then\n  echo \"ë³µì› ì·¨ì†Œë¨\"\n  exit 0\nfi\n\n# ë°ì´í„°ë² ì´ìŠ¤ ë³µì›\necho \"ë°ì´í„°ë² ì´ìŠ¤ ë³µì› ì¤‘...\"\ngunzip -c \"$BACKUP_DIR/$BACKUP_FILE\" | docker exec -i $DB_CONTAINER psql -U $DB_USER -d $DB_NAME\n\necho \"ë³µì› ì™„ë£Œ\"\nEOF\n\nchmod +x restore.sh\n\n# Cron ì‘ì—… ì„¤ì •\necho -e \"${YELLOW}Cron ì‘ì—… ì„¤ì • ì¤‘...${NC}\"\n(crontab -l 2>/dev/null; echo \"*/5 * * * * $(pwd)/monitor.sh\") | crontab -\n(crontab -l 2>/dev/null; echo \"0 1 * * * $(pwd)/backup.sh\") | crontab -\n\n# Docker Compose ì‹¤í–‰\necho -e \"${YELLOW}Docker Compose ì‹¤í–‰ ì¤‘...${NC}\"\ndocker-compose up -d\n\n# GitHub Actions CI/CD ì„¤ì • íŒŒì¼ ìƒì„±\nmkdir -p .github/workflows\ncat > .github/workflows/deploy.yml << 'EOF'\nname: Deploy to GCP VM\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Set up SSH\n        uses: webfactory/ssh-agent@v0.7.0\n        with:\n          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}\n          \n      - name: Add host key\n        run: |\n          mkdir -p ~/.ssh\n          ssh-keyscan ${{ secrets.VM_HOST }} >> ~/.ssh/known_hosts\n          \n      - name: Deploy to VM\n        run: |\n          ssh ${{ secrets.VM_USER }}@${{ secrets.VM_HOST }} \"cd ~/qb-trading && git pull && docker-compose up -d --build\"\n          \n      - name: Check deployment status\n        run: |\n          ssh ${{ secrets.VM_USER }}@${{ secrets.VM_HOST }} \"cd ~/qb-trading && ./monitor.sh && cat logs/system_monitor.log | tail -n 30\"\nEOF\n\necho -e \"${GREEN}===== ë°°í¬ ì™„ë£Œ =====${NC}\"\necho \"ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤.\"\necho \"ì›¹ ëŒ€ì‹œë³´ë“œ: http://$(curl -s ifconfig.me)\"\necho \"\"\necho \"ìœ ìš©í•œ ëª…ë ¹ì–´:\"\necho \"  - ë¡œê·¸ í™•ì¸: docker-compose logs -f\"\necho \"  - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸: ./monitor.sh\"\necho \"  - ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…: ./backup.sh\"\necho \"  - ë°ì´í„°ë² ì´ìŠ¤ ë³µì›: ./restore.sh\"\necho \"\"\necho \"GitHub Actions CI/CD ì„¤ì •ì„ ì™„ë£Œí•˜ë ¤ë©´ ì €ì¥ì†Œì— ë‹¤ìŒ ì‹œí¬ë¦¿ì„ ì¶”ê°€í•˜ì„¸ìš”:\"\necho \"  - SSH_PRIVATE_KEY: VM ì ‘ì†ìš© SSH ê°œì¸ í‚¤\"\necho \"  - VM_HOST: VMì˜ IP ì£¼ì†Œ\"\necho \"  - VM_USER: VM ì ‘ì† ì‚¬ìš©ìëª…\"",
        "testStrategy": "1. GCP ë¬´ë£Œ VM í™˜ê²½ í…ŒìŠ¤íŠ¸:\n   - e2-micro ì¸ìŠ¤í„´ìŠ¤(1 vCPU, 1GB RAM)ì—ì„œ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§: `free -m` ë° `docker stats`\n   - CPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§: `top` ë° `docker stats`\n   - ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸: `df -h`\n\n2. Docker Compose êµ¬ì„± í…ŒìŠ¤íŠ¸:\n   - `docker-compose up -d` ëª…ë ¹ìœ¼ë¡œ ì „ì²´ ìŠ¤íƒ ì‹¤í–‰\n   - ê° ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì œí•œ ì¤€ìˆ˜ í™•ì¸: `docker stats`\n   - ì»¨í…Œì´ë„ˆ ê°„ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± í…ŒìŠ¤íŠ¸: `docker exec -it api ping db`\n   - ë¡œê·¸ í™•ì¸: `docker-compose logs -f`\n\n3. ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n   - PostgreSQL ìµœì í™” ì„¤ì • ê²€ì¦: `docker exec -it db psql -U postgres -c \"SHOW shared_buffers;\"`\n   - TimescaleDB ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸: í•˜ì´í¼í…Œì´ë¸” ìƒì„± ë° ì¿¼ë¦¬\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§: `docker stats db`\n\n4. Redis ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n   - ë©”ëª¨ë¦¬ ì œí•œ ì¤€ìˆ˜ í™•ì¸: `docker exec -it redis redis-cli info memory`\n   - ìºì‹œ ì‘ë™ í…ŒìŠ¤íŠ¸: ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ\n   - ë©”ëª¨ë¦¬ ì •ì±… í…ŒìŠ¤íŠ¸: ìµœëŒ€ ë©”ëª¨ë¦¬ ë„ë‹¬ ì‹œ ë™ì‘ í™•ì¸\n\n5. ë°±ì—”ë“œ API í…ŒìŠ¤íŠ¸:\n   - ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸: `curl http://localhost/api/health`\n   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§: `docker stats api`\n   - ë¡œê·¸ ìƒì„± ë° ì €ì¥ í™•ì¸\n\n6. í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸:\n   - ì›¹ í˜ì´ì§€ ë¡œë”© í…ŒìŠ¤íŠ¸: ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†\n   - ë°˜ì‘í˜• ë””ìì¸ í…ŒìŠ¤íŠ¸: ë‹¤ì–‘í•œ í™”ë©´ í¬ê¸°ì—ì„œ í™•ì¸\n   - API ì—°ë™ í…ŒìŠ¤íŠ¸: ë°ì´í„° ì¡°íšŒ ë° í‘œì‹œ\n\n7. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸:\n   - í´ë¦° VMì—ì„œ ì›í´ë¦­ ë°°í¬ í…ŒìŠ¤íŠ¸\n   - í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ê²€ì¦\n   - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n\n8. ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜ í…ŒìŠ¤íŠ¸:\n   - ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ë¡œê·¸ í™•ì¸\n   - ì»¨í…Œì´ë„ˆ ê°•ì œ ì¢…ë£Œ í›„ ìë™ ì¬ì‹œì‘ í™•ì¸\n   - ë””ìŠ¤í¬ ì •ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n\n9. ë°±ì—… ë° ë³µì› í…ŒìŠ¤íŠ¸:\n   - ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ë°±ì—… íŒŒì¼ ìƒì„± í™•ì¸\n   - ë³µì› ìŠ¤í¬ë¦½íŠ¸ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ë³µì› í…ŒìŠ¤íŠ¸\n   - ë°±ì—… íŒŒì¼ ìë™ ì •ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n\n10. CI/CD íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸:\n    - GitHub ì €ì¥ì†Œ ì„¤ì • ë° ì‹œí¬ë¦¿ ì¶”ê°€\n    - ì½”ë“œ ë³€ê²½ í›„ ìë™ ë°°í¬ í…ŒìŠ¤íŠ¸\n    - ë¡¤ë°± ì ˆì°¨ í…ŒìŠ¤íŠ¸\n\n11. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì—”ì§„ í…ŒìŠ¤íŠ¸:\n    - ê° ì—”ì§„ë³„ ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n    - ì—”ì§„ ê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  í…ŒìŠ¤íŠ¸\n    - ì—”ì§„ ì¥ì•  ì‹œ ìë™ ë³µêµ¬ í…ŒìŠ¤íŠ¸\n    - ì—”ì§„ë³„ ë¡œê·¸ ìƒì„± ë° ëª¨ë‹ˆí„°ë§ í™•ì¸\n\n12. í†µí•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n    - ì „ì²´ ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸\n    - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸: ì¥ì‹œê°„ ì‹¤í–‰ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§\n    - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìµœì í™” ê²€ì¦: ì „ì²´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 1GB ì´ë‚´ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸",
        "subtasks": [
          {
            "id": 1,
            "title": "Docker Compose ë¦¬ì†ŒìŠ¤ ìµœì í™” êµ¬ì„±",
            "description": "1GB RAMê³¼ 1 vCPU ì œì•½ì‚¬í•­ì— ë§ê²Œ ê° ì„œë¹„ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "8ê°œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì—”ì§„ êµ¬í˜„",
            "description": "ì´ë²¤íŠ¸ ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì— ë”°ë¥¸ 8ê°œ ì—”ì§„ êµ¬í˜„ ë° ë°°í¬ ì„¤ì •",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "ì—”ì§„ë³„ í™˜ê²½ë³€ìˆ˜ ì„¤ì • êµ¬í˜„",
            "description": "ê° ì—”ì§„ë³„ ì„¤ì •ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ì—”ì§„ ì§€ì› ê¸°ëŠ¥ ì¶”ê°€",
            "description": "ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ì— 8ê°œ ì—”ì§„ ìƒíƒœ í™•ì¸ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ ì¶”ê°€",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "GitHub Actions CI/CD íŒŒì´í”„ë¼ì¸ êµ¬í˜„",
            "description": "ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ë°°í¬ ë° ìƒíƒœ í™•ì¸ì„ ìœ„í•œ GitHub Actions ì›Œí¬í”Œë¡œìš° êµ¬í˜„",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "ê°œë°œ ì™„ë£Œ í›„ ë°°í¬ ê³„íš ìˆ˜ë¦½",
            "description": "ì‹¤ì œ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ê°œë°œì´ ì™„ë£Œëœ í›„ Docker ë°°í¬ë¥¼ ìœ„í•œ ê³„íš ë° ì¼ì • ìˆ˜ë¦½",
            "status": "pending",
            "dependencies": [],
            "details": "1. ê°œë°œ ì™„ë£Œ ê¸°ì¤€ ì •ì˜\n2. ë°°í¬ ì „ í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½\n3. ë°°í¬ ì¼ì • ë° ë‹´ë‹¹ì ì§€ì •\n4. ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ê³„íš ìˆ˜ë¦½",
            "testStrategy": "1. ê°œë°œ ì™„ë£Œ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ í™•ì¸\n2. í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œì˜ ë°°í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n3. ë°°í¬ ê³„íš ë¬¸ì„œ ê²€í†  ë° ìŠ¹ì¸"
          }
        ]
      },
      {
        "id": 39,
        "title": "Redis Pub/Sub ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œìŠ¤í…œ êµ¬í˜„",
        "description": "Redis Pub/Subì„ í™œìš©í•œ ë¹„ë™ê¸° ì´ë²¤íŠ¸ í†µì‹  ì‹œìŠ¤í…œ êµ¬í˜„ìœ¼ë¡œ ì‹œìŠ¤í…œ ì „ì²´ ì´ë²¤íŠ¸ ì¤‘ê³„, ë¼ìš°íŒ…, í•„í„°ë§ ë° ì´ë²¤íŠ¸ ê¸°ë¡ ë©”ì»¤ë‹ˆì¦˜ ì œê³µ",
        "details": "1. EventBus í´ë˜ìŠ¤ êµ¬í˜„ (utils/event_bus.py):\n```python\nimport json\nimport asyncio\nimport logging\nfrom typing import Dict, List, Callable, Any, Optional, Union\nfrom redis.asyncio import Redis\n\nclass EventBus:\n    def __init__(self, redis_client: Redis):\n        self.redis = redis_client\n        self.logger = logging.getLogger(\"event_bus\")\n        self.subscribers = {}\n        self.pubsub = self.redis.pubsub()\n        self.running = False\n        self.event_history = {}  # ìµœê·¼ ì´ë²¤íŠ¸ ê¸°ë¡\n        self.request_handlers = {}  # Request/Response í•¸ë“¤ëŸ¬\n        self.request_futures = {}  # ì‘ë‹µ ëŒ€ê¸° Future ê°ì²´\n        \n    async def start(self):\n        \"\"\"ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘\"\"\"\n        if self.running:\n            return\n        self.running = True\n        asyncio.create_task(self._message_listener())\n        self.logger.info(\"EventBus started\")\n        \n    async def stop(self):\n        \"\"\"ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€\"\"\"\n        self.running = False\n        await self.pubsub.unsubscribe()\n        await self.pubsub.close()\n        self.logger.info(\"EventBus stopped\")\n        \n    async def publish(self, event_type: str, data: Any, retain: bool = False):\n        \"\"\"ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        message = {\n            \"type\": event_type,\n            \"data\": data,\n            \"timestamp\": asyncio.get_event_loop().time()\n        }\n        \n        serialized = json.dumps(message)\n        await self.redis.publish(event_type, serialized)\n        \n        if retain:\n            # ì´ë²¤íŠ¸ ê¸°ë¡ ë³´ì¡´\n            self.event_history[event_type] = message\n            # Redisì—ë„ ìµœê·¼ ì´ë²¤íŠ¸ ì €ì¥ (TTL ì„¤ì •)\n            await self.redis.set(f\"event_history:{event_type}\", serialized, ex=3600)\n            \n        self.logger.debug(f\"Published event: {event_type}\")\n        \n    async def subscribe(self, event_type: str, callback: Callable):\n        \"\"\"ì´ë²¤íŠ¸ êµ¬ë…\"\"\"\n        if event_type not in self.subscribers:\n            self.subscribers[event_type] = []\n            await self.pubsub.subscribe(event_type)\n            \n        self.subscribers[event_type].append(callback)\n        self.logger.debug(f\"Subscribed to event: {event_type}\")\n        \n        # ë³´ì¡´ëœ ì´ë²¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì „ë‹¬\n        if event_type in self.event_history:\n            await callback(self.event_history[event_type])\n            \n    async def unsubscribe(self, event_type: str, callback: Callable = None):\n        \"\"\"ì´ë²¤íŠ¸ êµ¬ë… ì·¨ì†Œ\"\"\"\n        if event_type not in self.subscribers:\n            return\n            \n        if callback is None:\n            self.subscribers[event_type] = []\n        else:\n            self.subscribers[event_type] = [cb for cb in self.subscribers[event_type] if cb != callback]\n            \n        if not self.subscribers[event_type]:\n            await self.pubsub.unsubscribe(event_type)\n            self.subscribers.pop(event_type)\n            \n        self.logger.debug(f\"Unsubscribed from event: {event_type}\")\n        \n    async def _message_listener(self):\n        \"\"\"ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ ë£¨í”„\"\"\"\n        while self.running:\n            try:\n                message = await self.pubsub.get_message(ignore_subscribe_messages=True)\n                if message is not None:\n                    channel = message[\"channel\"].decode(\"utf-8\")\n                    data = json.loads(message[\"data\"].decode(\"utf-8\"))\n                    \n                    # Request/Response íŒ¨í„´ ì²˜ë¦¬\n                    if channel.startswith(\"request:\"):\n                        await self._handle_request(channel, data)\n                    elif channel.startswith(\"response:\"):\n                        await self._handle_response(channel, data)\n                    # ì¼ë°˜ ì´ë²¤íŠ¸ ì²˜ë¦¬\n                    elif channel in self.subscribers:\n                        for callback in self.subscribers[channel]:\n                            try:\n                                await callback(data)\n                            except Exception as e:\n                                self.logger.error(f\"Error in event handler: {e}\")\n                                \n                await asyncio.sleep(0.001)  # CPU ë¶€í•˜ ë°©ì§€\n            except Exception as e:\n                self.logger.error(f\"Error in message listener: {e}\")\n                await asyncio.sleep(1)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸°\n                \n    # Request/Response íŒ¨í„´ êµ¬í˜„\n    async def register_request_handler(self, request_type: str, handler: Callable):\n        \"\"\"ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        full_channel = f\"request:{request_type}\"\n        if full_channel not in self.request_handlers:\n            self.request_handlers[full_channel] = []\n            await self.pubsub.subscribe(full_channel)\n            \n        self.request_handlers[full_channel].append(handler)\n        \n    async def _handle_request(self, channel: str, data: Dict):\n        \"\"\"ìš”ì²­ ë©”ì‹œì§€ ì²˜ë¦¬\"\"\"\n        if channel not in self.request_handlers:\n            return\n            \n        request_id = data.get(\"request_id\")\n        if not request_id:\n            return\n            \n        for handler in self.request_handlers[channel]:\n            try:\n                response = await handler(data[\"data\"])\n                # ì‘ë‹µ ë°œí–‰\n                response_channel = f\"response:{channel.split(':', 1)[1]}\"\n                response_data = {\n                    \"request_id\": request_id,\n                    \"data\": response,\n                    \"timestamp\": asyncio.get_event_loop().time()\n                }\n                await self.redis.publish(response_channel, json.dumps(response_data))\n            except Exception as e:\n                self.logger.error(f\"Error in request handler: {e}\")\n                \n    async def send_request(self, request_type: str, data: Any, timeout: float = 5.0) -> Any:\n        \"\"\"ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°\"\"\"\n        request_id = f\"{request_type}:{id(data)}:{asyncio.get_event_loop().time()}\"\n        response_channel = f\"response:{request_type}\"\n        \n        # ì‘ë‹µ ëŒ€ê¸° Future ìƒì„±\n        future = asyncio.get_event_loop().create_future()\n        self.request_futures[request_id] = future\n        \n        # ì‘ë‹µ ì±„ë„ êµ¬ë…\n        if response_channel not in self.subscribers:\n            await self.pubsub.subscribe(response_channel)\n            self.subscribers[response_channel] = []\n            \n        # ì‘ë‹µ í•¸ë“¤ëŸ¬ ë“±ë¡\n        async def response_handler(response_data):\n            if response_data.get(\"request_id\") == request_id and not future.done():\n                future.set_result(response_data.get(\"data\"))\n                \n        self.subscribers[response_channel].append(response_handler)\n        \n        # ìš”ì²­ ë°œí–‰\n        request_data = {\n            \"request_id\": request_id,\n            \"data\": data,\n            \"timestamp\": asyncio.get_event_loop().time()\n        }\n        await self.redis.publish(f\"request:{request_type}\", json.dumps(request_data))\n        \n        try:\n            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‘ë‹µ ëŒ€ê¸°\n            return await asyncio.wait_for(future, timeout)\n        except asyncio.TimeoutError:\n            self.logger.warning(f\"Request timed out: {request_type}\")\n            raise TimeoutError(f\"Request {request_type} timed out\")\n        finally:\n            # ì •ë¦¬\n            self.request_futures.pop(request_id, None)\n            if response_channel in self.subscribers:\n                self.subscribers[response_channel] = [\n                    cb for cb in self.subscribers[response_channel] if cb != response_handler\n                ]\n                \n    async def _handle_response(self, channel: str, data: Dict):\n        \"\"\"ì‘ë‹µ ë©”ì‹œì§€ ì²˜ë¦¬\"\"\"\n        request_id = data.get(\"request_id\")\n        if not request_id or request_id not in self.request_futures:\n            return\n            \n        future = self.request_futures[request_id]\n        if not future.done():\n            future.set_result(data.get(\"data\"))\n```\n\n2. EventRouter í´ë˜ìŠ¤ êµ¬í˜„ (utils/event_router.py):\n```python\nfrom typing import Dict, List, Callable, Pattern, Any\nimport re\nimport asyncio\nimport logging\nfrom .event_bus import EventBus\n\nclass EventRouter:\n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self.routes = {}  # ì´ë²¤íŠ¸ íƒ€ì… -> í•¸ë“¤ëŸ¬ ë§¤í•‘\n        self.pattern_routes = []  # (íŒ¨í„´, í•¸ë“¤ëŸ¬) íŠœí”Œ ë¦¬ìŠ¤íŠ¸\n        self.logger = logging.getLogger(\"event_router\")\n        \n    async def start(self):\n        \"\"\"ë¼ìš°í„° ì‹œì‘ ë° ì´ë²¤íŠ¸ êµ¬ë…\"\"\"\n        for event_type in self.routes:\n            await self.event_bus.subscribe(event_type, self._create_handler(event_type))\n            \n        # íŒ¨í„´ ê¸°ë°˜ ë¼ìš°íŒ…ì„ ìœ„í•œ ì™€ì¼ë“œì¹´ë“œ êµ¬ë…\n        await self.event_bus.subscribe(\"*\", self._pattern_handler)\n        \n    async def add_route(self, event_type: str, handler: Callable):\n        \"\"\"íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì…ì— ëŒ€í•œ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        if event_type not in self.routes:\n            self.routes[event_type] = []\n            await self.event_bus.subscribe(event_type, self._create_handler(event_type))\n            \n        self.routes[event_type].append(handler)\n        self.logger.debug(f\"Added route for event: {event_type}\")\n        \n    async def add_pattern_route(self, pattern: str, handler: Callable):\n        \"\"\"ì •ê·œì‹ íŒ¨í„´ ê¸°ë°˜ ì´ë²¤íŠ¸ ë¼ìš°íŒ… ë“±ë¡\"\"\"\n        compiled_pattern = re.compile(pattern)\n        self.pattern_routes.append((compiled_pattern, handler))\n        self.logger.debug(f\"Added pattern route: {pattern}\")\n        \n    def _create_handler(self, event_type: str):\n        \"\"\"íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì…ì— ëŒ€í•œ í•¸ë“¤ëŸ¬ ìƒì„±\"\"\"\n        async def handler(event_data):\n            if event_type in self.routes:\n                for route_handler in self.routes[event_type]:\n                    try:\n                        await route_handler(event_data)\n                    except Exception as e:\n                        self.logger.error(f\"Error in event handler for {event_type}: {e}\")\n        return handler\n        \n    async def _pattern_handler(self, event_data):\n        \"\"\"íŒ¨í„´ ê¸°ë°˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\"\"\"\n        event_type = event_data.get(\"type\", \"\")\n        for pattern, handler in self.pattern_routes:\n            if pattern.match(event_type):\n                try:\n                    await handler(event_data)\n                except Exception as e:\n                    self.logger.error(f\"Error in pattern handler for {event_type}: {e}\")\n```\n\n3. EventLogger í´ë˜ìŠ¤ êµ¬í˜„ (utils/event_logger.py):\n```python\nimport json\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom sqlalchemy import insert\nfrom .event_bus import EventBus\nfrom database.models import EventLog\n\nclass EventLogger:\n    def __init__(self, event_bus: EventBus, db_session_maker, log_level: str = \"INFO\"):\n        self.event_bus = event_bus\n        self.db_session_maker = db_session_maker\n        self.logger = logging.getLogger(\"event_logger\")\n        self.log_level = getattr(logging, log_level.upper())\n        self.buffer = []\n        self.buffer_size = 100\n        self.flush_interval = 5  # ì´ˆ\n        self.running = False\n        self.event_types_to_log = set()  # ë¡œê¹…í•  ì´ë²¤íŠ¸ íƒ€ì…\n        \n    async def start(self):\n        \"\"\"ì´ë²¤íŠ¸ ë¡œê±° ì‹œì‘\"\"\"\n        if self.running:\n            return\n            \n        self.running = True\n        # ëª¨ë“  ì´ë²¤íŠ¸ êµ¬ë…\n        await self.event_bus.subscribe(\"*\", self._log_event)\n        # ì£¼ê¸°ì  ë²„í¼ í”ŒëŸ¬ì‹œ íƒœìŠ¤í¬ ì‹œì‘\n        asyncio.create_task(self._periodic_flush())\n        self.logger.info(\"EventLogger started\")\n        \n    async def stop(self):\n        \"\"\"ì´ë²¤íŠ¸ ë¡œê±° ì¤‘ì§€\"\"\"\n        self.running = False\n        await self._flush_buffer()\n        self.logger.info(\"EventLogger stopped\")\n        \n    def add_event_type(self, event_type: str):\n        \"\"\"ë¡œê¹…í•  ì´ë²¤íŠ¸ íƒ€ì… ì¶”ê°€\"\"\"\n        self.event_types_to_log.add(event_type)\n        \n    def remove_event_type(self, event_type: str):\n        \"\"\"ë¡œê¹…í•  ì´ë²¤íŠ¸ íƒ€ì… ì œê±°\"\"\"\n        self.event_types_to_log.discard(event_type)\n        \n    async def _log_event(self, event_data: Dict):\n        \"\"\"ì´ë²¤íŠ¸ ë¡œê¹…\"\"\"\n        event_type = event_data.get(\"type\", \"\")\n        \n        # íŠ¹ì • ì´ë²¤íŠ¸ íƒ€ì…ë§Œ ë¡œê¹…í•˜ê±°ë‚˜, ì„¤ì •ì´ ì—†ìœ¼ë©´ ëª¨ë‘ ë¡œê¹…\n        if self.event_types_to_log and event_type not in self.event_types_to_log:\n            return\n            \n        # ë¡œê·¸ ë ˆë²¨ì— ë”°ë¼ ë¡œê¹…\n        log_entry = {\n            \"event_type\": event_type,\n            \"data\": json.dumps(event_data.get(\"data\", {})),\n            \"timestamp\": datetime.utcnow(),\n            \"metadata\": json.dumps({\n                \"source\": event_data.get(\"source\", \"unknown\"),\n                \"correlation_id\": event_data.get(\"correlation_id\", None)\n            })\n        }\n        \n        # ë²„í¼ì— ì¶”ê°€\n        self.buffer.append(log_entry)\n        \n        # ë²„í¼ í¬ê¸° ì´ˆê³¼ ì‹œ í”ŒëŸ¬ì‹œ\n        if len(self.buffer) >= self.buffer_size:\n            await self._flush_buffer()\n            \n    async def _flush_buffer(self):\n        \"\"\"ë²„í¼ ë‚´ìš©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\"\"\"\n        if not self.buffer:\n            return\n            \n        buffer_to_flush = self.buffer.copy()\n        self.buffer = []\n        \n        try:\n            async with self.db_session_maker() as session:\n                await session.execute(insert(EventLog).values(buffer_to_flush))\n                await session.commit()\n                self.logger.debug(f\"Flushed {len(buffer_to_flush)} events to database\")\n        except Exception as e:\n            self.logger.error(f\"Error flushing event buffer: {e}\")\n            # ì‹¤íŒ¨í•œ ì´ë²¤íŠ¸ ë‹¤ì‹œ ë²„í¼ì— ì¶”ê°€\n            self.buffer.extend(buffer_to_flush)\n            \n    async def _periodic_flush(self):\n        \"\"\"ì£¼ê¸°ì ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ\"\"\"\n        while self.running:\n            await asyncio.sleep(self.flush_interval)\n            await self._flush_buffer()\n            \n    async def get_recent_events(self, event_type: Optional[str] = None, limit: int = 100) -> List[Dict]:\n        \"\"\"ìµœê·¼ ì´ë²¤íŠ¸ ì¡°íšŒ\"\"\"\n        async with self.db_session_maker() as session:\n            query = select(EventLog).order_by(EventLog.timestamp.desc()).limit(limit)\n            \n            if event_type:\n                query = query.where(EventLog.event_type == event_type)\n                \n            result = await session.execute(query)\n            events = result.scalars().all()\n            \n            return [\n                {\n                    \"id\": event.id,\n                    \"event_type\": event.event_type,\n                    \"data\": json.loads(event.data),\n                    \"timestamp\": event.timestamp.isoformat(),\n                    \"metadata\": json.loads(event.metadata)\n                }\n                for event in events\n            ]\n```\n\n4. RequestResponseManager í´ë˜ìŠ¤ êµ¬í˜„ (utils/request_response.py):\n```python\nimport asyncio\nimport logging\nimport uuid\nfrom typing import Dict, Any, Callable, Optional\nfrom .event_bus import EventBus\n\nclass RequestResponseManager:\n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self.logger = logging.getLogger(\"request_response\")\n        self.handlers = {}  # ìš”ì²­ íƒ€ì… -> í•¸ë“¤ëŸ¬ ë§¤í•‘\n        \n    async def start(self):\n        \"\"\"ìš”ì²­/ì‘ë‹µ ê´€ë¦¬ì ì‹œì‘\"\"\"\n        # ì´ë²¤íŠ¸ ë²„ìŠ¤ì— ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\n        for request_type in self.handlers:\n            await self.event_bus.register_request_handler(\n                request_type, \n                self._create_request_handler(request_type)\n            )\n        self.logger.info(\"RequestResponseManager started\")\n        \n    async def register_handler(self, request_type: str, handler: Callable):\n        \"\"\"ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        if request_type not in self.handlers:\n            self.handlers[request_type] = []\n            await self.event_bus.register_request_handler(\n                request_type,\n                self._create_request_handler(request_type)\n            )\n            \n        self.handlers[request_type].append(handler)\n        self.logger.debug(f\"Registered handler for request type: {request_type}\")\n        \n    def _create_request_handler(self, request_type: str):\n        \"\"\"ìš”ì²­ í•¸ë“¤ëŸ¬ ìƒì„±\"\"\"\n        async def handler(request_data: Any) -> Any:\n            if request_type in self.handlers:\n                # ì²« ë²ˆì§¸ í•¸ë“¤ëŸ¬ë§Œ ì‚¬ìš© (ìš”ì²­ì€ ë‹¨ì¼ ì‘ë‹µë§Œ ê°€ëŠ¥)\n                try:\n                    return await self.handlers[request_type][0](request_data)\n                except Exception as e:\n                    self.logger.error(f\"Error in request handler for {request_type}: {e}\")\n                    return {\"error\": str(e)}\n            return None\n        return handler\n        \n    async def send_request(self, request_type: str, data: Any, timeout: float = 5.0) -> Any:\n        \"\"\"ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°\"\"\"\n        try:\n            return await self.event_bus.send_request(request_type, data, timeout)\n        except TimeoutError:\n            self.logger.warning(f\"Request timed out: {request_type}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Error sending request {request_type}: {e}\")\n            raise\n```\n\n5. ì´ë²¤íŠ¸ ì •ì˜ ë° ìƒìˆ˜ (utils/event_types.py):\n```python\n# ì‹œì¥ ë°ì´í„° ì´ë²¤íŠ¸\nMARKET_DATA_RECEIVED = \"market_data_received\"\nINDICATORS_UPDATED = \"indicators_updated\"\nCANDLE_CLOSED = \"candle_closed\"\nPRICE_ALERT = \"price_alert\"\n\n# ê±°ë˜ ì´ë²¤íŠ¸\nTRADING_SIGNAL = \"trading_signal\"\nORDER_PLACED = \"order_placed\"\nORDER_EXECUTED = \"order_executed\"\nORDER_FAILED = \"order_failed\"\nORDER_CANCELED = \"order_canceled\"\nPOSITION_OPENED = \"position_opened\"\nPOSITION_CLOSED = \"position_closed\"\nPOSITION_UPDATED = \"position_updated\"\n\n# ë¦¬ìŠ¤í¬ ì´ë²¤íŠ¸\nRISK_ALERT = \"risk_alert\"\nSTOP_LOSS_TRIGGERED = \"stop_loss_triggered\"\nTAKE_PROFIT_TRIGGERED = \"take_profit_triggered\"\nRISK_LIMIT_REACHED = \"risk_limit_reached\"\n\n# ì‹œìŠ¤í…œ ì´ë²¤íŠ¸\nSYSTEM_ERROR = \"system_error\"\nENGINE_STARTED = \"engine_started\"\nENGINE_STOPPED = \"engine_stopped\"\nCONFIG_UPDATED = \"config_updated\"\nHEALTH_CHECK = \"health_check\"\n```\n\n6. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì´ˆê¸°í™” ë° í†µí•© (utils/event_system.py):\n```python\nimport logging\nfrom redis.asyncio import Redis\nfrom .event_bus import EventBus\nfrom .event_router import EventRouter\nfrom .event_logger import EventLogger\nfrom .request_response import RequestResponseManager\nfrom database.session import async_session_maker\n\nclass EventSystem:\n    def __init__(self, redis_client: Redis):\n        self.logger = logging.getLogger(\"event_system\")\n        self.event_bus = EventBus(redis_client)\n        self.event_router = EventRouter(self.event_bus)\n        self.event_logger = EventLogger(self.event_bus, async_session_maker)\n        self.request_response = RequestResponseManager(self.event_bus)\n        \n    async def start(self):\n        \"\"\"ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘\"\"\"\n        await self.event_bus.start()\n        await self.event_router.start()\n        await self.event_logger.start()\n        await self.request_response.start()\n        self.logger.info(\"Event system started\")\n        \n    async def stop(self):\n        \"\"\"ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì¤‘ì§€\"\"\"\n        await self.event_logger.stop()\n        await self.event_bus.stop()\n        self.logger.info(\"Event system stopped\")\n        \n    # í¸ì˜ ë©”ì„œë“œë“¤\n    async def publish(self, event_type: str, data: any, retain: bool = False):\n        \"\"\"ì´ë²¤íŠ¸ ë°œí–‰\"\"\"\n        await self.event_bus.publish(event_type, data, retain)\n        \n    async def subscribe(self, event_type: str, callback):\n        \"\"\"ì´ë²¤íŠ¸ êµ¬ë…\"\"\"\n        await self.event_bus.subscribe(event_type, callback)\n        \n    async def add_route(self, event_type: str, handler):\n        \"\"\"ì´ë²¤íŠ¸ ë¼ìš°íŒ… ì¶”ê°€\"\"\"\n        await self.event_router.add_route(event_type, handler)\n        \n    async def add_pattern_route(self, pattern: str, handler):\n        \"\"\"íŒ¨í„´ ê¸°ë°˜ ì´ë²¤íŠ¸ ë¼ìš°íŒ… ì¶”ê°€\"\"\"\n        await self.event_router.add_pattern_route(pattern, handler)\n        \n    async def register_request_handler(self, request_type: str, handler):\n        \"\"\"ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\"\"\"\n        await self.request_response.register_handler(request_type, handler)\n        \n    async def send_request(self, request_type: str, data: any, timeout: float = 5.0):\n        \"\"\"ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°\"\"\"\n        return await self.request_response.send_request(request_type, data, timeout)\n```\n\n7. ë°ì´í„°ë² ì´ìŠ¤ ì´ë²¤íŠ¸ ë¡œê·¸ ëª¨ë¸ (database/models.pyì— ì¶”ê°€):\n```python\nfrom sqlalchemy import Column, Integer, String, DateTime, Text\nfrom sqlalchemy.sql import func\nfrom .base import Base\n\nclass EventLog(Base):\n    __tablename__ = \"event_logs\"\n    \n    id = Column(Integer, primary_key=True)\n    event_type = Column(String(100), index=True, nullable=False)\n    data = Column(Text, nullable=False)  # JSON ë¬¸ìì—´\n    timestamp = Column(DateTime(timezone=True), server_default=func.now(), index=True)\n    metadata = Column(Text, nullable=False)  # JSON ë¬¸ìì—´\n```\n\n8. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‚¬ìš© ì˜ˆì‹œ:\n```python\nimport asyncio\nfrom redis.asyncio import Redis\nfrom utils.event_system import EventSystem\nfrom utils.event_types import *\n\nasync def main():\n    # Redis í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    \n    # ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n    event_system = EventSystem(redis)\n    await event_system.start()\n    \n    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡\n    async def handle_market_data(event_data):\n        print(f\"Market data received: {event_data}\")\n        \n    async def handle_trading_signals(event_data):\n        print(f\"Trading signal received: {event_data}\")\n        \n    # ì´ë²¤íŠ¸ êµ¬ë…\n    await event_system.subscribe(MARKET_DATA_RECEIVED, handle_market_data)\n    await event_system.subscribe(TRADING_SIGNAL, handle_trading_signals)\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    await event_system.publish(MARKET_DATA_RECEIVED, {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.25,\n        \"timestamp\": \"2023-10-25T12:34:56Z\"\n    })\n    \n    # ìš”ì²­/ì‘ë‹µ íŒ¨í„´ ì‚¬ìš©\n    async def handle_price_request(request_data):\n        symbol = request_data.get(\"symbol\")\n        # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ê°€ê²© ì¡°íšŒ\n        return {\"symbol\": symbol, \"price\": 150.25}\n    \n    # ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\n    await event_system.register_request_handler(\"get_price\", handle_price_request)\n    \n    # ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°\n    response = await event_system.send_request(\"get_price\", {\"symbol\": \"AAPL\"})\n    print(f\"Price response: {response}\")\n    \n    # ì •ë¦¬\n    await event_system.stop()\n    await redis.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n9. êµ¬í˜„ ì‹œ ê³ ë ¤ì‚¬í•­:\n   - Redis ì—°ê²° í’€ ê´€ë¦¬: ë‹¤ìˆ˜ì˜ ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… ì‹œ ì—°ê²° ê´€ë¦¬ ì¤‘ìš”\n   - ë©”ì‹œì§€ ì§ë ¬í™”/ì—­ì§ë ¬í™”: JSON ì‚¬ìš©, í•„ìš”ì‹œ MessagePack ë“± ê³ ë ¤\n   - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, Redis ì—°ê²° ë¬¸ì œ ë“± ì²˜ë¦¬\n   - ì´ë²¤íŠ¸ ë¡œê¹…: ë””ë²„ê¹… ë° ê°ì‚¬ë¥¼ ìœ„í•œ ì´ë²¤íŠ¸ ê¸°ë¡\n   - ì„±ëŠ¥ ìµœì í™”: ëŒ€ëŸ‰ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œ ë²„í¼ë§ ë° ë°°ì¹˜ ì²˜ë¦¬\n   - ë©”ëª¨ë¦¬ ê´€ë¦¬: ì´ë²¤íŠ¸ ê¸°ë¡ ë³´ì¡´ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ\n   - ë³´ì•ˆ: ë¯¼ê°í•œ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì•”í˜¸í™” ê³ ë ¤",
        "testStrategy": "1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:\n   - EventBus ì´ˆê¸°í™” ë° ì‹œì‘/ì¤‘ì§€ í…ŒìŠ¤íŠ¸\n   - ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì´ë²¤íŠ¸ ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸\n   - ìš”ì²­/ì‘ë‹µ íŒ¨í„´ í…ŒìŠ¤íŠ¸\n   - ì´ë²¤íŠ¸ ë¡œê¹… í…ŒìŠ¤íŠ¸\n\n2. ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… í…ŒìŠ¤íŠ¸:\n```python\nimport pytest\nimport asyncio\nfrom redis.asyncio import Redis\nfrom utils.event_bus import EventBus\n\n@pytest.mark.asyncio\nasync def test_event_publish_subscribe():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    received_events = []\n    \n    async def event_handler(event_data):\n        received_events.append(event_data)\n        \n    # ì´ë²¤íŠ¸ êµ¬ë…\n    await event_bus.subscribe(\"test_event\", event_handler)\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    test_data = {\"message\": \"Hello, World!\"}\n    await event_bus.publish(\"test_event\", test_data)\n    \n    # ì´ë²¤íŠ¸ ìˆ˜ì‹  ëŒ€ê¸°\n    await asyncio.sleep(0.1)\n    \n    # ê²€ì¦\n    assert len(received_events) == 1\n    assert received_events[0][\"data\"] == test_data\n    \n    # ì •ë¦¬\n    await event_bus.stop()\n    await redis.close()\n```\n\n3. ì´ë²¤íŠ¸ ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_event_routing():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    event_router = EventRouter(event_bus)\n    await event_bus.start()\n    await event_router.start()\n    \n    route_called = False\n    pattern_route_called = False\n    \n    async def route_handler(event_data):\n        nonlocal route_called\n        route_called = True\n        \n    async def pattern_handler(event_data):\n        nonlocal pattern_route_called\n        pattern_route_called = True\n        \n    # ë¼ìš°íŠ¸ ë“±ë¡\n    await event_router.add_route(\"specific_event\", route_handler)\n    await event_router.add_pattern_route(\"pattern_.*\", pattern_handler)\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    await event_bus.publish(\"specific_event\", {\"test\": \"data\"})\n    await event_bus.publish(\"pattern_test\", {\"test\": \"data\"})\n    \n    # ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°\n    await asyncio.sleep(0.1)\n    \n    # ê²€ì¦\n    assert route_called\n    assert pattern_route_called\n    \n    # ì •ë¦¬\n    await event_bus.stop()\n    await redis.close()\n```\n\n4. ìš”ì²­/ì‘ë‹µ íŒ¨í„´ í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_request_response():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    req_res_manager = RequestResponseManager(event_bus)\n    await event_bus.start()\n    await req_res_manager.start()\n    \n    # ìš”ì²­ í•¸ë“¤ëŸ¬ ë“±ë¡\n    async def price_handler(request_data):\n        symbol = request_data.get(\"symbol\")\n        return {\"symbol\": symbol, \"price\": 150.25}\n        \n    await req_res_manager.register_handler(\"get_price\", price_handler)\n    \n    # ìš”ì²­ ì „ì†¡\n    response = await req_res_manager.send_request(\"get_price\", {\"symbol\": \"AAPL\"})\n    \n    # ê²€ì¦\n    assert response[\"symbol\"] == \"AAPL\"\n    assert response[\"price\"] == 150.25\n    \n    # íƒ€ì„ì•„ì›ƒ í…ŒìŠ¤íŠ¸\n    with pytest.raises(TimeoutError):\n        await req_res_manager.send_request(\"non_existent\", {}, timeout=0.1)\n        \n    # ì •ë¦¬\n    await event_bus.stop()\n    await redis.close()\n```\n\n5. ì´ë²¤íŠ¸ ë¡œê¹… í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_event_logging():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    event_logger = EventLogger(event_bus, async_session_maker)\n    await event_bus.start()\n    await event_logger.start()\n    \n    # ë¡œê¹…í•  ì´ë²¤íŠ¸ íƒ€ì… ì¶”ê°€\n    event_logger.add_event_type(\"test_event\")\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    await event_bus.publish(\"test_event\", {\"message\": \"Test message\"})\n    \n    # ë¡œê·¸ í”ŒëŸ¬ì‹œ ëŒ€ê¸°\n    await asyncio.sleep(0.1)\n    await event_logger._flush_buffer()\n    \n    # ë¡œê·¸ ì¡°íšŒ\n    logs = await event_logger.get_recent_events(\"test_event\", limit=1)\n    \n    # ê²€ì¦\n    assert len(logs) == 1\n    assert logs[0][\"event_type\"] == \"test_event\"\n    assert logs[0][\"data\"][\"message\"] == \"Test message\"\n    \n    # ì •ë¦¬\n    await event_logger.stop()\n    await event_bus.stop()\n    await redis.close()\n```\n\n6. í†µí•© í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_event_system_integration():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_system = EventSystem(redis)\n    await event_system.start()\n    \n    # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n    test_events = []\n    \n    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\n    async def market_data_handler(event_data):\n        test_events.append((\"market\", event_data))\n        \n    async def trading_handler(event_data):\n        test_events.append((\"trading\", event_data))\n        \n    # ìš”ì²­ í•¸ë“¤ëŸ¬\n    async def data_request_handler(request_data):\n        return {\"result\": f\"Processed {request_data}\"}\n        \n    # í•¸ë“¤ëŸ¬ ë“±ë¡\n    await event_system.subscribe(MARKET_DATA_RECEIVED, market_data_handler)\n    await event_system.subscribe(TRADING_SIGNAL, trading_handler)\n    await event_system.register_request_handler(\"data_request\", data_request_handler)\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰\n    market_data = {\"symbol\": \"AAPL\", \"price\": 150.25}\n    trading_data = {\"symbol\": \"AAPL\", \"action\": \"BUY\", \"quantity\": 10}\n    \n    await event_system.publish(MARKET_DATA_RECEIVED, market_data)\n    await event_system.publish(TRADING_SIGNAL, trading_data)\n    \n    # ìš”ì²­ ì „ì†¡\n    response = await event_system.send_request(\"data_request\", {\"query\": \"test\"})\n    \n    # ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°\n    await asyncio.sleep(0.1)\n    \n    # ê²€ì¦\n    assert len(test_events) == 2\n    assert test_events[0][0] == \"market\"\n    assert test_events[0][1][\"data\"] == market_data\n    assert test_events[1][0] == \"trading\"\n    assert test_events[1][1][\"data\"] == trading_data\n    assert \"result\" in response\n    \n    # ì •ë¦¬\n    await event_system.stop()\n    await redis.close()\n```\n\n7. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_event_bus_performance():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    # ì¹´ìš´í„°\n    received_count = 0\n    \n    async def event_handler(event_data):\n        nonlocal received_count\n        received_count += 1\n        \n    # ì´ë²¤íŠ¸ êµ¬ë…\n    await event_bus.subscribe(\"perf_test\", event_handler)\n    \n    # ëŒ€ëŸ‰ ì´ë²¤íŠ¸ ë°œí–‰ (1000ê°œ)\n    start_time = asyncio.get_event_loop().time()\n    for i in range(1000):\n        await event_bus.publish(\"perf_test\", {\"index\": i})\n        \n    # ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°\n    while received_count < 1000:\n        await asyncio.sleep(0.01)\n        \n    end_time = asyncio.get_event_loop().time()\n    duration = end_time - start_time\n    \n    # ê²€ì¦ (ì´ˆë‹¹ ìµœì†Œ 500ê°œ ì´ìƒ ì²˜ë¦¬)\n    events_per_second = 1000 / duration\n    assert events_per_second >= 500, f\"Performance too low: {events_per_second:.2f} events/sec\"\n    \n    print(f\"Performance: {events_per_second:.2f} events/sec\")\n    \n    # ì •ë¦¬\n    await event_bus.stop()\n    await redis.close()\n```\n\n8. ì˜¤ë¥˜ ë³µêµ¬ í…ŒìŠ¤íŠ¸:\n```python\n@pytest.mark.asyncio\nasync def test_error_recovery():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    error_count = 0\n    success_count = 0\n    \n    async def failing_handler(event_data):\n        nonlocal error_count, success_count\n        if event_data[\"data\"][\"index\"] % 2 == 0:\n            error_count += 1\n            raise Exception(\"Simulated error\")\n        else:\n            success_count += 1\n            \n    # ì´ë²¤íŠ¸ êµ¬ë…\n    await event_bus.subscribe(\"error_test\", failing_handler)\n    \n    # ì´ë²¤íŠ¸ ë°œí–‰ (100ê°œ)\n    for i in range(100):\n        await event_bus.publish(\"error_test\", {\"index\": i})\n        \n    # ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°\n    await asyncio.sleep(0.5)\n    \n    # ê²€ì¦ (ì˜¤ë¥˜ê°€ ìˆì–´ë„ ê³„ì† ì²˜ë¦¬)\n    assert error_count == 50  # ì§ìˆ˜ ì¸ë±ìŠ¤ì—ì„œ ì˜¤ë¥˜\n    assert success_count == 50  # í™€ìˆ˜ ì¸ë±ìŠ¤ëŠ” ì„±ê³µ\n    \n    # ì •ë¦¬\n    await event_bus.stop()\n    await redis.close()\n```\n\n9. ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸:\n   - ì‹¤ì œ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ê³¼ í†µí•©í•˜ì—¬ ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‘ë™ í™•ì¸\n   - ì‹œì¥ ë°ì´í„° ìˆ˜ì‹  â†’ ì‹ í˜¸ ìƒì„± â†’ ì£¼ë¬¸ ì‹¤í–‰ íë¦„ í…ŒìŠ¤íŠ¸\n   - ì˜¤ë¥˜ ë°œìƒ ì‹œ ì´ë²¤íŠ¸ ê¸°ë¡ ë° ì•Œë¦¼ í™•ì¸\n   - ì‹œìŠ¤í…œ ì‹œì‘/ì¤‘ì§€ ì‹œ ì´ë²¤íŠ¸ ë°œí–‰ í™•ì¸\n\n10. ë¶€í•˜ í…ŒìŠ¤íŠ¸:\n    - ì´ˆë‹¹ 1000ê°œ ì´ìƒì˜ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥ í™•ì¸\n    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 100MB)\n    - ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (24ì‹œê°„ ì—°ì† ìš´ì˜)",
        "status": "pending",
        "dependencies": [
          21,
          19,
          36
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-25T04:33:23.955Z",
      "updated": "2025-07-27T00:41:59.323Z",
      "description": "Tasks for master context"
    }
  }
}