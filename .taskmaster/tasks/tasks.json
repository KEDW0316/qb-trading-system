{
  "master": {
    "tasks": [
      {
        "id": 19,
        "title": "개발 환경 설정 및 프로젝트 구조화",
        "description": "Python 3.11+ 가상환경 설정, 필수 라이브러리 설치, 프로젝트 구조 설계 및 Git 저장소 초기화",
        "details": "1. Python 3.11+ 설치 확인 및 가상환경 생성: `python -m venv venv`\n2. 필수 패키지 설치: pandas 2.1+, numpy 1.24+, TA-Lib 0.4.28+, websockets 11.0+, sqlalchemy 2.0+, fastapi 0.104+, uvicorn 0.23+, psycopg2-binary 2.9.9+, redis 5.0+\n3. requirements.txt 생성\n4. 프로젝트 구조 설계:\n```\nqb/\n  ├── api/            # FastAPI 서버\n  ├── collectors/     # 데이터 수집 모듈\n  ├── database/       # DB 모델 및 연결\n  ├── strategies/     # 트레이딩 전략\n  ├── backtesting/    # 백테스팅 엔진\n  ├── risk/           # 리스크 관리\n  ├── orders/         # 주문 관리\n  ├── utils/          # 유틸리티 함수\n  ├── config/         # 설정 파일\n  └── tests/          # 테스트 코드\n```\n5. Git 저장소 초기화: `git init`\n6. .gitignore 파일 생성 (API 키, 환경 변수, 가상환경 등 제외)\n7. 환경 변수 관리를 위한 python-dotenv 설정\n8. 로깅 시스템 구성: loguru 라이브러리 활용\n<info added on 2025-07-25T05:53:53.475Z>\n9. 코딩 규칙 설정:\n   - QB Trading System 전용 코딩 규칙 파일 생성 (.cursor/rules/qb_trading_rules.mdc)\n   - 기본 설계 원칙: KISS, YAGNI, DRY 적용\n   - 이벤트 기반 아키텍처 규칙 (Redis Pub/Sub) 정의\n   - 금융 데이터 처리 표준화 (Decimal 타입, UTC 시간)\n   - 안전성 및 신뢰성 확보 (에러 처리, 로깅 표준)\n   - 보안 관련 규칙 (API 키 관리, 입력 검증)\n   - 테스트 및 성능 최적화 가이드라인\n   - 코드 구조 및 네이밍 컨벤션 표준화\n</info added on 2025-07-25T05:53:53.475Z>",
        "testStrategy": "1. 가상환경 활성화 및 의존성 설치 테스트\n2. 각 주요 라이브러리 import 테스트\n3. 프로젝트 구조 검증\n4. Git 저장소 초기 커밋 및 푸시 테스트\n5. 로깅 시스템 작동 확인",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "PostgreSQL 및 TimescaleDB 설정",
        "description": "시계열 데이터 최적화를 위한 PostgreSQL 및 TimescaleDB 설치, 설정 및 스키마 구현",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "medium",
        "details": "1. PostgreSQL 15+ 설치 및 설정\n2. TimescaleDB 2.11+ 확장 설치\n3. 데이터베이스 생성: `CREATE DATABASE qb_trading;`\n4. TimescaleDB 확장 활성화: `CREATE EXTENSION IF NOT EXISTS timescaledb;`\n5. 스키마 구현:\n   - PRD에 명시된 stock_prices 테이블 생성\n   - trades 테이블 생성\n   - strategy_performance 테이블 생성\n   - 추가 필요 테이블: stocks_metadata, risk_metrics, system_logs\n6. 하이퍼테이블 설정 및 압축 정책 구성:\n```sql\nSELECT create_hypertable('stock_prices', 'time');\nALTER TABLE stock_prices SET (timescaledb.compress, timescaledb.compress_segmentby = 'symbol');\nSELECT add_compression_policy('stock_prices', INTERVAL '7 days');\n```\n7. 인덱스 생성:\n```sql\nCREATE INDEX idx_stock_prices_symbol ON stock_prices(symbol, time DESC);\nCREATE INDEX idx_trades_symbol ON trades(symbol, timestamp DESC);\n```\n8. 백업 정책 설정\n9. SQLAlchemy ORM 모델 구현 (database/models.py)\n10. 데이터베이스 연결 관리 클래스 구현 (database/connection.py)\n\n**개발 순서 참고:**\n1. 우선 Redis + 실시간 데이터 처리로 트레이딩 시작\n2. 시스템 안정화 후 PostgreSQL 추가하여 데이터 영속성 확보",
        "testStrategy": "1. 데이터베이스 연결 테스트\n2. 테이블 생성 및 스키마 검증\n3. 샘플 데이터 삽입 및 조회 테스트\n4. 하이퍼테이블 기능 테스트 (시계열 쿼리 성능)\n5. 압축 정책 테스트\n6. SQLAlchemy ORM 모델 CRUD 테스트\n7. 백업 및 복원 테스트",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Redis 캐시 설정 및 실시간 데이터 버퍼링",
        "description": "실시간 데이터 처리를 위한 Redis 캐시 설정 및 데이터 버퍼링 시스템 구현, 이벤트 버스 시스템 및 캔들/지표 데이터 관리 포함",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "high",
        "details": "1. Redis 7.0+ 설치 및 설정\n2. Python redis-py 클라이언트 설정\n3. 실시간 데이터 버퍼링을 위한 데이터 구조 설계:\n   - market:SYMBOL (Hash) - 실시간 시장 데이터\n   - candles:SYMBOL:1m (List) - 최근 200개 캔들\n   - indicators:SYMBOL (Hash) - 기술적 지표 캐시\n   - 실시간 호가 데이터: Sorted Set 구조\n   - 최근 체결 내역: List 구조 (제한된 길이)\n4. 데이터 만료 정책 설정 (TTL)\n5. Redis Pub/Sub 이벤트 버스 시스템 구현:\n   - market_data_received: 시장 데이터 수신 이벤트\n   - trading_signal: 트레이딩 신호 이벤트\n   - order_executed: 주문 실행 이벤트\n   - risk_alert: 리스크 알림 이벤트\n6. Redis 연결 풀 관리 클래스 구현 (utils/redis_manager.py):\n```python\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0):\n        self.pool = redis.ConnectionPool(host=host, port=port, db=db)\n        self.redis = redis.Redis(connection_pool=self.pool)\n        \n    def set_market_data(self, symbol, market_data):\n        # 실시간 시장 데이터 저장 로직\n        self.redis.hset(f\"market:{symbol}\", mapping=market_data)\n        self.redis.expire(f\"market:{symbol}\", 86400)  # 1일 후 만료\n        \n    def get_market_data(self, symbol):\n        return self.redis.hgetall(f\"market:{symbol}\")\n        \n    def add_candle(self, symbol, timeframe, candle_data):\n        # 캔들 데이터 추가 (최대 200개 유지)\n        key = f\"candles:{symbol}:{timeframe}\"\n        self.redis.lpush(key, json.dumps(candle_data))\n        self.redis.ltrim(key, 0, 199)  # 최근 200개만 유지\n        \n    def cache_indicator(self, symbol, indicator_name, value):\n        # 기술적 지표 캐싱\n        self.redis.hset(f\"indicators:{symbol}\", indicator_name, json.dumps(value))\n        \n    def publish_event(self, channel, message):\n        # 이벤트 발행\n        self.redis.publish(channel, json.dumps(message))\n```\n7. 데이터 직렬화/역직렬화 유틸리티 함수 구현 (JSON 또는 MessagePack)\n8. Redis 모니터링 및 상태 확인 기능 구현\n9. 메모리 사용량 최적화 (20-25MB 목표):\n   - 데이터 압축 기법 적용\n   - 불필요한 데이터 자동 제거 정책 설정\n   - 메모리 사용량 모니터링 도구 구현",
        "testStrategy": "1. Redis 연결 및 기본 작동 테스트\n2. 데이터 구조별 CRUD 작업 테스트\n3. Pub/Sub 채널 메시지 전송 및 수신 테스트\n4. 대량 데이터 처리 성능 테스트\n5. 연결 풀 관리 테스트\n6. 직렬화/역직렬화 정확성 테스트\n7. TTL 정책 작동 확인\n8. 메모리 사용량 모니터링 테스트 (20-25MB 목표 달성 확인)\n9. 캔들 데이터 관리 테스트 (200개 제한 확인)\n10. 기술적 지표 캐싱 및 조회 테스트\n11. 이벤트 버스 시스템 통합 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "Redis 설치 및 기본 연결 설정",
            "description": "Redis 7.0+ 설치 및 Python redis-py 클라이언트 설정, 기본 연결 풀 관리 클래스 구현",
            "dependencies": [],
            "details": "1. Redis 7.0+ 설치 및 기본 설정:\n   - Linux: `sudo apt install redis-server`\n   - macOS: `brew install redis`\n   - 설정 파일 수정: `/etc/redis/redis.conf`\n     - 메모리 제한: `maxmemory 25mb`\n     - 메모리 정책: `maxmemory-policy allkeys-lru`\n\n2. Python redis-py 클라이언트 설치:\n   - `pip install redis==5.0.0`\n\n3. utils/redis_manager.py 파일 생성 및 기본 연결 풀 관리 클래스 구현:\n```python\nimport redis\nimport json\nimport logging\nfrom typing import Dict, Any, List, Optional\n\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0, password=None):\n        self.logger = logging.getLogger(__name__)\n        self.pool = redis.ConnectionPool(\n            host=host, \n            port=port, \n            db=db,\n            password=password,\n            decode_responses=True  # 자동으로 바이트를 문자열로 디코딩\n        )\n        self.redis = redis.Redis(connection_pool=self.pool)\n        self.logger.info(f\"Redis connection pool initialized: {host}:{port} DB:{db}\")\n        \n    def ping(self) -> bool:\n        \"\"\"Redis 서버 연결 확인\"\"\"\n        try:\n            return self.redis.ping()\n        except Exception as e:\n            self.logger.error(f\"Redis connection error: {e}\")\n            return False\n            \n    def get_info(self) -> Dict[str, Any]:\n        \"\"\"Redis 서버 정보 조회\"\"\"\n        try:\n            return self.redis.info()\n        except Exception as e:\n            self.logger.error(f\"Failed to get Redis info: {e}\")\n            return {}\n            \n    def get_memory_stats(self) -> Dict[str, Any]:\n        \"\"\"Redis 메모리 사용량 통계 조회\"\"\"\n        try:\n            info = self.redis.info('memory')\n            return {\n                'used_memory_human': info.get('used_memory_human'),\n                'used_memory_peak_human': info.get('used_memory_peak_human'),\n                'maxmemory_human': info.get('maxmemory_human'),\n                'maxmemory_policy': info.get('maxmemory_policy')\n            }\n        except Exception as e:\n            self.logger.error(f\"Failed to get memory stats: {e}\")\n            return {}\n```\n<info added on 2025-07-25T06:37:18.644Z>\n4. 구현 완료 및 테스트 결과:\n   - Redis 8.0.3 설치 완료 (Homebrew 사용)\n   - redis-py 5.2.0 라이브러리 설치 완료 (conda 환경)\n   - RedisManager 클래스 구현 완료 (qb/utils/redis_manager.py)\n   - 연결 테스트 결과:\n     - Redis 서버 연결: 성공\n     - 서버 정보: Redis 8.0.3, 연결된 클라이언트 1개\n     - 메모리 사용량: 888.55K 사용 중\n     - 기본 데이터 저장/조회: 정상 작동\n\n5. 해결된 기술적 이슈:\n   - conda 환경에서 redis 모듈 import 문제 해결\n   - conda install redis-py 명령으로 정상 설치\n   - $CONDA_PREFIX/bin/python 사용하여 테스트 진행\n</info added on 2025-07-25T06:37:18.644Z>",
            "status": "done",
            "testStrategy": "1. Redis 서버 설치 및 실행 확인:\n   - `redis-cli ping` 명령으로 PONG 응답 확인\n   - `redis-cli info` 명령으로 서버 정보 확인\n\n2. RedisManager 클래스 테스트:\n```python\nimport unittest\nfrom utils.redis_manager import RedisManager\n\nclass TestRedisManager(unittest.TestCase):\n    def setUp(self):\n        self.redis_manager = RedisManager()\n        \n    def test_connection(self):\n        self.assertTrue(self.redis_manager.ping())\n        \n    def test_get_info(self):\n        info = self.redis_manager.get_info()\n        self.assertIsInstance(info, dict)\n        self.assertIn('redis_version', info)\n        \n    def test_get_memory_stats(self):\n        stats = self.redis_manager.get_memory_stats()\n        self.assertIsInstance(stats, dict)\n        self.assertIn('used_memory_human', stats)\n```"
          },
          {
            "id": 2,
            "title": "데이터 구조 설계 및 CRUD 메서드 구현",
            "description": "실시간 데이터 버퍼링을 위한 Redis 데이터 구조 설계 및 CRUD 메서드 구현",
            "dependencies": [
              "21.1"
            ],
            "details": "RedisManager 클래스에 다음 데이터 구조 관련 메서드를 추가합니다:\n\n```python\n# utils/redis_manager.py에 추가\n\n# 시장 데이터 관련 메서드\ndef set_market_data(self, symbol: str, market_data: Dict[str, Any], ttl: int = 86400) -> bool:\n    \"\"\"실시간 시장 데이터 저장\"\"\"\n    try:\n        # 문자열 값으로 변환 필요한 경우 처리\n        processed_data = {k: json.dumps(v) if isinstance(v, (dict, list)) else str(v) \n                         for k, v in market_data.items()}\n        self.redis.hset(f\"market:{symbol}\", mapping=processed_data)\n        if ttl > 0:\n            self.redis.expire(f\"market:{symbol}\", ttl)  # TTL 설정\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to set market data for {symbol}: {e}\")\n        return False\n\ndef get_market_data(self, symbol: str) -> Dict[str, Any]:\n    \"\"\"실시간 시장 데이터 조회\"\"\"\n    try:\n        data = self.redis.hgetall(f\"market:{symbol}\")\n        # JSON 문자열을 객체로 변환 시도\n        for k, v in data.items():\n            try:\n                data[k] = json.loads(v)\n            except (json.JSONDecodeError, TypeError):\n                pass  # 일반 문자열은 그대로 유지\n        return data\n    except Exception as e:\n        self.logger.error(f\"Failed to get market data for {symbol}: {e}\")\n        return {}\n\n# 캔들 데이터 관련 메서드\ndef add_candle(self, symbol: str, timeframe: str, candle_data: Dict[str, Any], \n              max_candles: int = 200) -> bool:\n    \"\"\"캔들 데이터 추가 (최대 개수 제한)\"\"\"\n    try:\n        key = f\"candles:{symbol}:{timeframe}\"\n        self.redis.lpush(key, json.dumps(candle_data))\n        self.redis.ltrim(key, 0, max_candles - 1)  # 최근 max_candles개만 유지\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to add candle for {symbol}:{timeframe}: {e}\")\n        return False\n\ndef get_candles(self, symbol: str, timeframe: str, limit: int = 200) -> List[Dict[str, Any]]:\n    \"\"\"캔들 데이터 조회\"\"\"\n    try:\n        candles = self.redis.lrange(f\"candles:{symbol}:{timeframe}\", 0, limit - 1)\n        return [json.loads(candle) for candle in candles]\n    except Exception as e:\n        self.logger.error(f\"Failed to get candles for {symbol}:{timeframe}: {e}\")\n        return []\n\n# 기술적 지표 관련 메서드\ndef cache_indicator(self, symbol: str, indicator_name: str, value: Any, ttl: int = 3600) -> bool:\n    \"\"\"기술적 지표 캐싱\"\"\"\n    try:\n        self.redis.hset(f\"indicators:{symbol}\", indicator_name, json.dumps(value))\n        if ttl > 0:\n            self.redis.expire(f\"indicators:{symbol}\", ttl)\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to cache indicator {indicator_name} for {symbol}: {e}\")\n        return False\n\ndef get_indicator(self, symbol: str, indicator_name: str) -> Any:\n    \"\"\"기술적 지표 조회\"\"\"\n    try:\n        value = self.redis.hget(f\"indicators:{symbol}\", indicator_name)\n        return json.loads(value) if value else None\n    except Exception as e:\n        self.logger.error(f\"Failed to get indicator {indicator_name} for {symbol}: {e}\")\n        return None\n\n# 호가 데이터 관련 메서드\ndef update_orderbook(self, symbol: str, price: float, quantity: float, \n                   is_bid: bool, ttl: int = 300) -> bool:\n    \"\"\"호가 데이터 업데이트 (Sorted Set 사용)\"\"\"\n    try:\n        key = f\"orderbook:{symbol}:{'bids' if is_bid else 'asks'}\"\n        # 가격을 점수로 사용 (매수는 높은 가격이 우선, 매도는 낮은 가격이 우선)\n        score = price if is_bid else -price\n        self.redis.zadd(key, {json.dumps({'price': price, 'quantity': quantity}): score})\n        if ttl > 0:\n            self.redis.expire(key, ttl)\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to update orderbook for {symbol}: {e}\")\n        return False\n\ndef get_orderbook(self, symbol: str, side: str, limit: int = 10) -> List[Dict[str, float]]:\n    \"\"\"호가 데이터 조회\"\"\"\n    try:\n        if side not in ['bids', 'asks']:\n            raise ValueError(\"Side must be 'bids' or 'asks'\")\n            \n        key = f\"orderbook:{symbol}:{side}\"\n        # 매수는 내림차순, 매도는 오름차순으로 정렬\n        if side == 'bids':\n            items = self.redis.zrevrange(key, 0, limit - 1, withscores=True)\n        else:\n            items = self.redis.zrange(key, 0, limit - 1, withscores=True)\n            \n        result = []\n        for item, score in items:\n            order = json.loads(item)\n            result.append(order)\n        return result\n    except Exception as e:\n        self.logger.error(f\"Failed to get orderbook for {symbol}: {e}\")\n        return []\n\n# 최근 체결 내역 관련 메서드\ndef add_trade(self, symbol: str, trade_data: Dict[str, Any], max_trades: int = 100) -> bool:\n    \"\"\"최근 체결 내역 추가\"\"\"\n    try:\n        key = f\"trades:{symbol}\"\n        self.redis.lpush(key, json.dumps(trade_data))\n        self.redis.ltrim(key, 0, max_trades - 1)  # 최근 max_trades개만 유지\n        return True\n    except Exception as e:\n        self.logger.error(f\"Failed to add trade for {symbol}: {e}\")\n        return False\n\ndef get_recent_trades(self, symbol: str, limit: int = 50) -> List[Dict[str, Any]]:\n    \"\"\"최근 체결 내역 조회\"\"\"\n    try:\n        trades = self.redis.lrange(f\"trades:{symbol}\", 0, limit - 1)\n        return [json.loads(trade) for trade in trades]\n    except Exception as e:\n        self.logger.error(f\"Failed to get recent trades for {symbol}: {e}\")\n        return []\n```\n<info added on 2025-07-25T06:48:16.864Z>\n## 구현 완료 보고\n\n### 1. 📊 시장 데이터 관리 (Hash 구조)\n- `set_market_data()` - 실시간 시장 데이터 저장 (TTL 지원)\n- `get_market_data()` - JSON 자동 변환과 함께 조회\n- 테스트: ✅ 복합 데이터 구조(dict 포함) 저장/조회 성공\n\n### 2. 🕯️ 캔들 데이터 관리 (List 구조)  \n- `add_candle()` - 캔들 데이터 추가 (최대 200개 제한)\n- `get_candles()` - 시계열 순서로 캔들 조회\n- 테스트: ✅ 5개 캔들 저장 후 최신순 조회 성공\n\n### 3. 📈 기술적 지표 캐싱 (Hash 구조)\n- `cache_indicator()` - 기술적 지표 캐싱 (TTL 지원)  \n- `get_indicator()` - 특정 지표 조회\n- 테스트: ✅ MA, RSI 등 복합 지표 캐싱/조회 성공\n\n### 4. 📋 호가 데이터 관리 (Sorted Set 구조)\n- `update_orderbook()` - 호가 데이터 업데이트\n- `get_orderbook()` - 매수/매도 호가 가격순 조회\n- **문제 해결**: 매도 호가 정렬 로직 수정 (낮은 가격 우선)\n- 테스트: ✅ 매수 내림차순, 매도 오름차순 정렬 성공\n\n### 5. 🔄 최근 체결 내역 관리 (List 구조)\n- `add_trade()` - 최근 체결 내역 추가 (최대 100개 제한)\n- `get_recent_trades()` - 최근 거래 시간순 조회\n- 테스트: ✅ 5개 거래 저장 후 최신순 조회 성공\n\n### 🔧 기술적 특징:\n- **JSON 자동 변환**: 복합 데이터 타입 자동 직렬화/역직렬화\n- **TTL 지원**: 시장 데이터(24시간), 지표(1시간), 호가(5분) 자동 만료\n- **메모리 효율성**: max_candles, max_trades 파라미터로 메모리 사용량 제한\n- **타입 안전성**: 모든 메서드에 타입 힌트 및 예외 처리\n\n### 🧪 종합 테스트 결과:\n**5/5 모든 데이터 구조 CRUD 테스트 통과!**\n- 시장 데이터: ✅ 저장/조회 성공\n- 캔들 데이터: ✅ 시계열 관리 성공  \n- 기술적 지표: ✅ 캐싱 시스템 성공\n- 호가 데이터: ✅ 가격순 정렬 성공\n- 체결 내역: ✅ 최신순 관리 성공\n\n🚀 **다음 단계 준비 완료**: Task 21.3 \"Redis Pub/Sub 이벤트 버스 시스템 구현\"으로 진행\n</info added on 2025-07-25T06:48:16.864Z>",
            "status": "done",
            "testStrategy": "1. 데이터 구조별 CRUD 작업 테스트:\n```python\nimport unittest\nimport time\nfrom utils.redis_manager import RedisManager\n\nclass TestRedisDataStructures(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        self.symbol = 'BTCUSDT'\n        \n    def test_market_data(self):\n        # 시장 데이터 저장 및 조회 테스트\n        market_data = {\n            'price': '50000.0',\n            'volume': '1000.5',\n            'change': '2.5',\n            'details': {'high': 51000, 'low': 49000}\n        }\n        self.assertTrue(self.redis.set_market_data(self.symbol, market_data))\n        retrieved = self.redis.get_market_data(self.symbol)\n        self.assertEqual(retrieved['price'], '50000.0')\n        self.assertEqual(retrieved['details']['high'], 51000)\n        \n    def test_candles(self):\n        # 캔들 데이터 추가 및 조회 테스트\n        for i in range(5):\n            candle = {\n                'timestamp': int(time.time()) - i * 60,\n                'open': 50000 + i,\n                'high': 50100 + i,\n                'low': 49900 + i,\n                'close': 50050 + i,\n                'volume': 100 + i\n            }\n            self.assertTrue(self.redis.add_candle(self.symbol, '1m', candle))\n            \n        candles = self.redis.get_candles(self.symbol, '1m')\n        self.assertEqual(len(candles), 5)\n        self.assertEqual(candles[0]['open'], 50004)  # 가장 최근 캔들\n        \n    def test_indicators(self):\n        # 지표 캐싱 및 조회 테스트\n        indicator = {'ma_20': 49500, 'ma_50': 48000, 'rsi': 65}\n        self.assertTrue(self.redis.cache_indicator(self.symbol, 'moving_averages', indicator))\n        retrieved = self.redis.get_indicator(self.symbol, 'moving_averages')\n        self.assertEqual(retrieved['ma_20'], 49500)\n        self.assertEqual(retrieved['rsi'], 65)\n        \n    def test_orderbook(self):\n        # 호가 데이터 업데이트 및 조회 테스트\n        # 매수 호가 추가\n        self.redis.update_orderbook(self.symbol, 49900, 1.5, True)\n        self.redis.update_orderbook(self.symbol, 49800, 2.5, True)\n        self.redis.update_orderbook(self.symbol, 50000, 1.0, True)\n        \n        # 매도 호가 추가\n        self.redis.update_orderbook(self.symbol, 50100, 1.2, False)\n        self.redis.update_orderbook(self.symbol, 50200, 2.0, False)\n        \n        bids = self.redis.get_orderbook(self.symbol, 'bids')\n        asks = self.redis.get_orderbook(self.symbol, 'asks')\n        \n        self.assertEqual(len(bids), 3)\n        self.assertEqual(len(asks), 2)\n        self.assertEqual(bids[0]['price'], 50000)  # 최고 매수가\n        self.assertEqual(asks[0]['price'], 50100)  # 최저 매도가\n        \n    def test_recent_trades(self):\n        # 최근 체결 내역 추가 및 조회 테스트\n        for i in range(5):\n            trade = {\n                'timestamp': int(time.time()) - i,\n                'price': 50000 + i * 10,\n                'quantity': 0.1 + i * 0.01,\n                'side': 'buy' if i % 2 == 0 else 'sell'\n            }\n            self.assertTrue(self.redis.add_trade(self.symbol, trade))\n            \n        trades = self.redis.get_recent_trades(self.symbol)\n        self.assertEqual(len(trades), 5)\n        self.assertEqual(trades[0]['price'], 50040)  # 가장 최근 거래\n        self.assertEqual(trades[0]['side'], 'sell')\n```"
          },
          {
            "id": 3,
            "title": "Redis Pub/Sub 이벤트 버스 시스템 구현",
            "description": "Redis Pub/Sub 기능을 활용한 이벤트 버스 시스템 구현 및 이벤트 채널 설정",
            "dependencies": [
              "21.2"
            ],
            "details": "RedisManager 클래스에 Pub/Sub 기능을 추가하고 이벤트 버스 시스템을 구현합니다:\n\n```python\n# utils/redis_manager.py에 추가\n\n# Pub/Sub 이벤트 관련 메서드\ndef publish_event(self, channel: str, message: Dict[str, Any]) -> bool:\n    \"\"\"이벤트 발행\"\"\"\n    try:\n        # 타임스탬프 추가\n        if 'timestamp' not in message:\n            message['timestamp'] = int(time.time() * 1000)  # 밀리초 단위\n            \n        result = self.redis.publish(channel, json.dumps(message))\n        self.logger.debug(f\"Published event to {channel}: {message}\")\n        return result > 0  # 구독자 수 반환\n    except Exception as e:\n        self.logger.error(f\"Failed to publish event to {channel}: {e}\")\n        return False\n\ndef subscribe(self, channels: List[str]):\n    \"\"\"채널 구독 (비동기 컨텍스트에서 사용)\"\"\"\n    try:\n        pubsub = self.redis.pubsub()\n        pubsub.subscribe(*channels)\n        self.logger.info(f\"Subscribed to channels: {channels}\")\n        return pubsub\n    except Exception as e:\n        self.logger.error(f\"Failed to subscribe to channels {channels}: {e}\")\n        return None\n```\n\n이제 이벤트 버스 시스템을 구현하는 별도의 클래스를 생성합니다:\n\n```python\n# utils/event_bus.py\n\nimport json\nimport asyncio\nimport logging\nfrom typing import Dict, List, Callable, Any, Optional\nfrom datetime import datetime\nfrom utils.redis_manager import RedisManager\n\nclass EventBus:\n    \"\"\"Redis Pub/Sub 기반 이벤트 버스 시스템\"\"\"\n    \n    # 정의된 이벤트 채널\n    CHANNELS = {\n        'MARKET_DATA': 'market_data_received',\n        'TRADING_SIGNAL': 'trading_signal',\n        'ORDER_EXECUTED': 'order_executed',\n        'RISK_ALERT': 'risk_alert',\n        'SYSTEM_STATUS': 'system_status',\n        'ERROR': 'error'\n    }\n    \n    def __init__(self, redis_manager: RedisManager):\n        self.redis = redis_manager\n        self.logger = logging.getLogger(__name__)\n        self.handlers = {channel: [] for channel in self.CHANNELS.values()}\n        self.running = False\n        self.pubsub = None\n        self.listener_task = None\n        \n    async def start(self):\n        \"\"\"이벤트 버스 시작\"\"\"\n        if self.running:\n            return\n            \n        self.pubsub = self.redis.subscribe(list(self.CHANNELS.values()))\n        if not self.pubsub:\n            self.logger.error(\"Failed to initialize pubsub\")\n            return False\n            \n        self.running = True\n        self.listener_task = asyncio.create_task(self._message_listener())\n        self.logger.info(\"Event bus started\")\n        return True\n        \n    async def stop(self):\n        \"\"\"이벤트 버스 중지\"\"\"\n        if not self.running:\n            return\n            \n        self.running = False\n        if self.listener_task:\n            self.listener_task.cancel()\n            try:\n                await self.listener_task\n            except asyncio.CancelledError:\n                pass\n                \n        if self.pubsub:\n            await self.pubsub.unsubscribe()\n            await self.pubsub.close()\n            \n        self.logger.info(\"Event bus stopped\")\n        \n    def register_handler(self, channel: str, handler: Callable[[Dict[str, Any]], None]):\n        \"\"\"이벤트 핸들러 등록\"\"\"\n        if channel not in self.CHANNELS.values():\n            self.logger.warning(f\"Unknown channel: {channel}\")\n            return False\n            \n        self.handlers[channel].append(handler)\n        self.logger.debug(f\"Handler registered for channel: {channel}\")\n        return True\n        \n    def publish(self, channel: str, data: Dict[str, Any]) -> bool:\n        \"\"\"이벤트 발행\"\"\"\n        if channel not in self.CHANNELS.values():\n            self.logger.warning(f\"Unknown channel: {channel}\")\n            return False\n            \n        return self.redis.publish_event(channel, data)\n        \n    async def _message_listener(self):\n        \"\"\"메시지 리스너 루프\"\"\"\n        self.logger.info(\"Message listener started\")\n        \n        while self.running:\n            try:\n                message = await self.pubsub.get_message(ignore_subscribe_messages=True, timeout=1.0)\n                if message is None:\n                    await asyncio.sleep(0.01)  # CPU 사용량 감소\n                    continue\n                    \n                channel = message['channel']\n                data = json.loads(message['data'])\n                \n                # 핸들러 호출\n                for handler in self.handlers.get(channel, []):\n                    try:\n                        handler(data)\n                    except Exception as e:\n                        self.logger.error(f\"Error in handler for {channel}: {e}\")\n                        \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in message listener: {e}\")\n                await asyncio.sleep(1)  # 오류 발생 시 잠시 대기\n                \n        self.logger.info(\"Message listener stopped\")\n```\n\n이벤트 버스 사용 예시:\n\n```python\n# 이벤트 버스 사용 예시\nasync def example_usage():\n    # 초기화\n    redis_manager = RedisManager()\n    event_bus = EventBus(redis_manager)\n    \n    # 이벤트 핸들러 정의\n    def market_data_handler(data):\n        print(f\"Market data received: {data}\")\n        \n    def trading_signal_handler(data):\n        print(f\"Trading signal received: {data}\")\n        \n    # 핸들러 등록\n    event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], market_data_handler)\n    event_bus.register_handler(EventBus.CHANNELS['TRADING_SIGNAL'], trading_signal_handler)\n    \n    # 이벤트 버스 시작\n    await event_bus.start()\n    \n    # 이벤트 발행\n    event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], {\n        'symbol': 'BTCUSDT',\n        'price': 50000,\n        'volume': 1000\n    })\n    \n    event_bus.publish(EventBus.CHANNELS['TRADING_SIGNAL'], {\n        'symbol': 'BTCUSDT',\n        'action': 'BUY',\n        'price': 50000,\n        'quantity': 0.1,\n        'reason': 'MA crossover'\n    })\n    \n    # 5초 대기 후 종료\n    await asyncio.sleep(5)\n    await event_bus.stop()\n```\n<info added on 2025-07-25T07:23:23.241Z>\nRedis Pub/Sub 이벤트 버스 시스템 구현이 완료되었습니다. 기존 구현에 다음 기능들이 추가되었습니다:\n\n1. 이벤트 타입 확장 - 기존 6개 채널에서 시장 데이터, 기술적 분석, 전략, 주문, 리스크 관리, 시스템 관련 이벤트로 세분화\n\n2. Event 데이터 클래스 구현:\n```python\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\nfrom typing import Any, Dict, Optional\n\n@dataclass\nclass Event:\n    \"\"\"구조화된 이벤트 메시지 포맷\"\"\"\n    event_type: str\n    source: str\n    data: Dict[str, Any]\n    timestamp: int = None\n    \n    def __post_init__(self):\n        if self.timestamp is None:\n            self.timestamp = int(datetime.now().timestamp() * 1000)\n            \n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n```\n\n3. 멀티스레드 환경에서 안전한 구독자 관리:\n```python\nfrom threading import RLock\n\nclass EventBus:\n    # 기존 코드에 추가\n    def __init__(self, redis_manager: RedisManager):\n        # 기존 초기화 코드...\n        self._subscribers_lock = RLock()\n        # ...\n        \n    def register_handler(self, channel: str, handler: Callable[[Dict[str, Any]], None]):\n        \"\"\"스레드 안전한 이벤트 핸들러 등록\"\"\"\n        with self._subscribers_lock:\n            if channel not in self.CHANNELS.values():\n                self.logger.warning(f\"Unknown channel: {channel}\")\n                return False\n                \n            self.handlers[channel].append(handler)\n            self.logger.debug(f\"Handler registered for channel: {channel}\")\n            return True\n```\n\n4. 비동기 콜백 실행을 위한 ThreadPoolExecutor 사용:\n```python\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass EventBus:\n    # 기존 코드에 추가\n    def __init__(self, redis_manager: RedisManager):\n        # 기존 초기화 코드...\n        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"event-worker\")\n        # ...\n        \n    async def _message_listener(self):\n        \"\"\"메시지 리스너 루프 - ThreadPoolExecutor 사용\"\"\"\n        # 기존 코드...\n        \n        # 핸들러 호출 부분 수정\n        for handler in self.handlers.get(channel, []):\n            try:\n                # 스레드 풀에서 핸들러 실행\n                self.executor.submit(handler, data)\n            except Exception as e:\n                self.logger.error(f\"Error submitting handler for {channel}: {e}\")\n```\n\n5. 에러 처리 및 복구 메커니즘:\n```python\nclass EventBus:\n    # 기존 코드에 추가\n    async def _reconnect(self):\n        \"\"\"Redis 연결 재시도\"\"\"\n        retry_count = 0\n        max_retries = 5\n        \n        while retry_count < max_retries:\n            try:\n                self.logger.info(f\"Attempting to reconnect (attempt {retry_count+1}/{max_retries})\")\n                self.pubsub = self.redis.subscribe(list(self.CHANNELS.values()))\n                if self.pubsub:\n                    self.logger.info(\"Reconnection successful\")\n                    return True\n            except Exception as e:\n                self.logger.error(f\"Reconnection failed: {e}\")\n                \n            retry_count += 1\n            await asyncio.sleep(min(2 ** retry_count, 30))  # 지수 백오프\n            \n        self.logger.critical(\"Failed to reconnect after maximum retries\")\n        return False\n```\n\n6. 이벤트 통계 추적:\n```python\nclass EventBus:\n    # 기존 코드에 추가\n    def __init__(self, redis_manager: RedisManager):\n        # 기존 초기화 코드...\n        self.stats = {channel: {\"published\": 0, \"received\": 0, \"errors\": 0} \n                      for channel in self.CHANNELS.values()}\n        # ...\n        \n    def get_stats(self) -> Dict[str, Dict[str, int]]:\n        \"\"\"이벤트 통계 반환\"\"\"\n        return self.stats\n```\n\n7. 하트비트 브로드캐스트 기능:\n```python\nclass EventBus:\n    # 기존 코드에 추가\n    async def start_heartbeat(self, interval_seconds: int = 30):\n        \"\"\"시스템 하트비트 브로드캐스트 시작\"\"\"\n        while self.running:\n            try:\n                heartbeat_event = Event(\n                    event_type=\"heartbeat\",\n                    source=\"event_bus\",\n                    data={\"status\": \"alive\", \"stats\": self.get_stats()}\n                )\n                self.publish(self.CHANNELS['SYSTEM_STATUS'], heartbeat_event.to_dict())\n                await asyncio.sleep(interval_seconds)\n            except Exception as e:\n                self.logger.error(f\"Error in heartbeat: {e}\")\n                await asyncio.sleep(interval_seconds)\n```\n\n8. 종합적인 단위 테스트가 작성되어 모든 기능의 정상 작동을 검증했습니다.\n</info added on 2025-07-25T07:23:23.241Z>",
            "status": "done",
            "testStrategy": "1. Pub/Sub 기능 테스트:\n```python\nimport unittest\nimport asyncio\nimport json\nfrom utils.redis_manager import RedisManager\nfrom utils.event_bus import EventBus\n\nclass TestPubSub(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        self.test_channel = 'test_channel'\n        \n    def test_publish_event(self):\n        message = {'test': 'data', 'value': 123}\n        result = self.redis.publish_event(self.test_channel, message)\n        self.assertTrue(result)  # 발행 성공 여부 확인\n        \n    def test_subscribe(self):\n        pubsub = self.redis.subscribe([self.test_channel])\n        self.assertIsNotNone(pubsub)\n        pubsub.close()\n\nclass TestEventBus(unittest.IsolatedAsyncioTestCase):\n    async def asyncSetUp(self):\n        self.redis = RedisManager()\n        self.event_bus = EventBus(self.redis)\n        self.received_messages = []\n        \n    async def asyncTearDown(self):\n        await self.event_bus.stop()\n        \n    def message_handler(self, data):\n        self.received_messages.append(data)\n        \n    async def test_event_bus_flow(self):\n        # 핸들러 등록\n        self.event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], self.message_handler)\n        \n        # 이벤트 버스 시작\n        await self.event_bus.start()\n        \n        # 이벤트 발행\n        test_data = {'symbol': 'BTCUSDT', 'price': 50000, 'test_id': 12345}\n        self.event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], test_data)\n        \n        # 메시지 수신 대기\n        await asyncio.sleep(0.5)\n        \n        # 검증\n        self.assertEqual(len(self.received_messages), 1)\n        self.assertEqual(self.received_messages[0]['symbol'], 'BTCUSDT')\n        self.assertEqual(self.received_messages[0]['test_id'], 12345)\n        \n    async def test_multiple_channels(self):\n        # 여러 채널 핸들러 등록\n        self.event_bus.register_handler(EventBus.CHANNELS['MARKET_DATA'], self.message_handler)\n        self.event_bus.register_handler(EventBus.CHANNELS['TRADING_SIGNAL'], self.message_handler)\n        \n        # 이벤트 버스 시작\n        await self.event_bus.start()\n        \n        # 여러 채널에 이벤트 발행\n        self.event_bus.publish(EventBus.CHANNELS['MARKET_DATA'], {'type': 'market', 'id': 1})\n        self.event_bus.publish(EventBus.CHANNELS['TRADING_SIGNAL'], {'type': 'signal', 'id': 2})\n        \n        # 메시지 수신 대기\n        await asyncio.sleep(0.5)\n        \n        # 검증\n        self.assertEqual(len(self.received_messages), 2)\n        self.assertTrue(any(msg['type'] == 'market' for msg in self.received_messages))\n        self.assertTrue(any(msg['type'] == 'signal' for msg in self.received_messages))\n```"
          },
          {
            "id": 4,
            "title": "데이터 직렬화/역직렬화 및 압축 기능 구현",
            "description": "Redis 데이터 직렬화/역직렬화 유틸리티 및 메모리 최적화를 위한 데이터 압축 기능 구현",
            "dependencies": [
              "21.2"
            ],
            "details": "데이터 직렬화/역직렬화 및 압축 기능을 구현하는 유틸리티 클래스를 생성합니다:\n\n```python\n# utils/serialization.py\n\nimport json\nimport zlib\nimport base64\nimport msgpack\nimport logging\nfrom typing import Any, Dict, List, Union, Optional\n\nclass Serializer:\n    \"\"\"데이터 직렬화/역직렬화 및 압축 유틸리티\"\"\"\n    \n    FORMAT_JSON = 'json'\n    FORMAT_MSGPACK = 'msgpack'\n    \n    def __init__(self, default_format=FORMAT_JSON, compress=False, compression_level=6):\n        self.logger = logging.getLogger(__name__)\n        self.default_format = default_format\n        self.compress = compress\n        self.compression_level = compression_level\n        \n    def serialize(self, data: Any, format: Optional[str] = None, compress: Optional[bool] = None) -> str:\n        \"\"\"데이터 직렬화\"\"\"\n        format = format or self.default_format\n        compress = self.compress if compress is None else compress\n        \n        try:\n            # 직렬화\n            if format == self.FORMAT_JSON:\n                serialized = json.dumps(data)\n            elif format == self.FORMAT_MSGPACK:\n                serialized = base64.b64encode(msgpack.packb(data)).decode('ascii')\n            else:\n                raise ValueError(f\"Unsupported format: {format}\")\n                \n            # 압축\n            if compress:\n                compressed = zlib.compress(serialized.encode('utf-8'), self.compression_level)\n                return f\"c:{base64.b64encode(compressed).decode('ascii')}\"\n            else:\n                return f\"{format[0]}:{serialized}\"\n                \n        except Exception as e:\n            self.logger.error(f\"Serialization error: {e}\")\n            # 오류 시 기본 JSON으로 대체\n            return f\"j:{json.dumps(str(data))}\"\n            \n    def deserialize(self, data_str: str) -> Any:\n        \"\"\"데이터 역직렬화\"\"\"\n        if not data_str or len(data_str) < 2 or data_str[1] != ':':\n            return data_str  # 직렬화된 형식이 아님\n            \n        prefix = data_str[0]\n        payload = data_str[2:]\n        \n        try:\n            # 압축 해제\n            if prefix == 'c':\n                decompressed = zlib.decompress(base64.b64decode(payload))\n                # 압축 해제 후 다시 역직렬화 (j: 또는 m: 접두어 확인)\n                return self.deserialize(decompressed.decode('utf-8'))\n                \n            # JSON 역직렬화\n            elif prefix == 'j':\n                return json.loads(payload)\n                \n            # MessagePack 역직렬화\n            elif prefix == 'm':\n                return msgpack.unpackb(base64.b64decode(payload))\n                \n            else:\n                self.logger.warning(f\"Unknown serialization prefix: {prefix}\")\n                return data_str\n                \n        except Exception as e:\n            self.logger.error(f\"Deserialization error: {e}\")\n            return data_str\n```\n\n이제 RedisManager 클래스를 확장하여 직렬화/역직렬화 및 압축 기능을 통합합니다:\n\n```python\n# utils/redis_manager.py 수정\n\n# 필요한 import 추가\nfrom utils.serialization import Serializer\n\nclass RedisManager:\n    def __init__(self, host='localhost', port=6379, db=0, password=None, \n                 use_compression=False, compression_level=6):\n        # 기존 초기화 코드...\n        \n        # 직렬화 도구 초기화\n        self.serializer = Serializer(\n            default_format=Serializer.FORMAT_JSON,\n            compress=use_compression,\n            compression_level=compression_level\n        )\n        \n    # 압축 데이터 저장 메서드 추가\n    def set_compressed(self, key: str, value: Any, ttl: int = 0) -> bool:\n        \"\"\"데이터 압축 저장\"\"\"\n        try:\n            serialized = self.serializer.serialize(value, compress=True)\n            self.redis.set(key, serialized)\n            if ttl > 0:\n                self.redis.expire(key, ttl)\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to set compressed data for {key}: {e}\")\n            return False\n            \n    def get_compressed(self, key: str) -> Any:\n        \"\"\"압축 데이터 조회\"\"\"\n        try:\n            data = self.redis.get(key)\n            if not data:\n                return None\n            return self.serializer.deserialize(data)\n        except Exception as e:\n            self.logger.error(f\"Failed to get compressed data for {key}: {e}\")\n            return None\n            \n    # 대용량 데이터 저장 메서드 (자동 압축 적용)\n    def set_large_data(self, key: str, value: Any, ttl: int = 0, \n                      size_threshold: int = 1024) -> bool:\n        \"\"\"대용량 데이터 저장 (크기에 따라 자동 압축)\"\"\"\n        try:\n            # 일반 JSON 직렬화\n            serialized = json.dumps(value)\n            \n            # 크기가 임계값을 초과하면 압축 적용\n            if len(serialized) > size_threshold:\n                return self.set_compressed(key, value, ttl)\n            else:\n                self.redis.set(key, serialized)\n                if ttl > 0:\n                    self.redis.expire(key, ttl)\n                return True\n        except Exception as e:\n            self.logger.error(f\"Failed to set large data for {key}: {e}\")\n            return False\n            \n    def get_large_data(self, key: str) -> Any:\n        \"\"\"대용량 데이터 조회 (압축 여부 자동 감지)\"\"\"\n        try:\n            data = self.redis.get(key)\n            if not data:\n                return None\n                \n            # 압축 데이터 확인 (c: 접두어)\n            if data.startswith(b'c:'):\n                return self.serializer.deserialize(data.decode('utf-8'))\n            else:\n                # 일반 JSON\n                try:\n                    return json.loads(data)\n                except json.JSONDecodeError:\n                    return data.decode('utf-8')\n        except Exception as e:\n            self.logger.error(f\"Failed to get large data for {key}: {e}\")\n            return None\n```\n\n메모리 사용량 모니터링 및 최적화 메서드 추가:\n\n```python\n# utils/redis_manager.py에 추가\n\ndef get_memory_usage(self) -> Dict[str, Any]:\n    \"\"\"Redis 메모리 사용량 상세 정보\"\"\"\n    try:\n        memory_info = self.redis.info('memory')\n        return {\n            'used_memory': memory_info['used_memory'],\n            'used_memory_human': memory_info['used_memory_human'],\n            'used_memory_peak': memory_info['used_memory_peak'],\n            'used_memory_peak_human': memory_info['used_memory_peak_human'],\n            'used_memory_lua': memory_info['used_memory_lua'],\n            'maxmemory': memory_info['maxmemory'],\n            'maxmemory_human': memory_info['maxmemory_human'],\n            'maxmemory_policy': memory_info['maxmemory_policy']\n        }\n    except Exception as e:\n        self.logger.error(f\"Failed to get memory usage: {e}\")\n        return {}\n        \ndef get_key_memory_usage(self, key: str) -> int:\n    \"\"\"특정 키의 메모리 사용량 (바이트)\"\"\"\n    try:\n        return self.redis.memory_usage(key)\n    except Exception as e:\n        self.logger.error(f\"Failed to get memory usage for key {key}: {e}\")\n        return -1\n        \ndef get_keys_by_pattern(self, pattern: str) -> List[str]:\n    \"\"\"패턴에 일치하는 키 목록 조회\"\"\"\n    try:\n        return self.redis.keys(pattern)\n    except Exception as e:\n        self.logger.error(f\"Failed to get keys by pattern {pattern}: {e}\")\n        return []\n        \ndef get_pattern_memory_usage(self, pattern: str) -> Dict[str, int]:\n    \"\"\"특정 패턴의 키들의 메모리 사용량\"\"\"\n    try:\n        keys = self.get_keys_by_pattern(pattern)\n        result = {}\n        for key in keys:\n            result[key] = self.get_key_memory_usage(key)\n        return result\n    except Exception as e:\n        self.logger.error(f\"Failed to get pattern memory usage for {pattern}: {e}\")\n        return {}\n        \ndef optimize_memory(self, target_mb: int = 20) -> bool:\n    \"\"\"메모리 사용량 최적화 (목표: target_mb)\"\"\"\n    try:\n        # 현재 메모리 사용량 확인\n        memory_info = self.get_memory_usage()\n        current_mb = memory_info['used_memory'] / (1024 * 1024)\n        \n        self.logger.info(f\"Current memory usage: {current_mb:.2f}MB, Target: {target_mb}MB\")\n        \n        # 이미 목표 이하면 최적화 필요 없음\n        if current_mb <= target_mb:\n            return True\n            \n        # 1. 만료 시간이 설정되지 않은 키에 기본 TTL 적용\n        for key in self.get_keys_by_pattern('*'):\n            if self.redis.ttl(key) == -1:  # -1은 만료 시간 없음\n                self.redis.expire(key, 86400)  # 1일 기본 TTL\n                \n        # 2. 큰 데이터셋 압축\n        large_keys = []\n        for key in self.get_keys_by_pattern('*'):\n            size = self.get_key_memory_usage(key)\n            if size > 10240:  # 10KB 이상\n                large_keys.append((key, size))\n                \n        # 크기 순으로 정렬\n        large_keys.sort(key=lambda x: x[1], reverse=True)\n        \n        # 큰 키부터 압축 시도\n        for key, size in large_keys:\n            try:\n                # 문자열 타입만 압축 가능\n                if self.redis.type(key) == 'string':\n                    value = self.redis.get(key)\n                    ttl = self.redis.ttl(key)\n                    if ttl < 0:\n                        ttl = 86400  # 기본 TTL\n                        \n                    # 압축 저장\n                    self.set_compressed(key, value, ttl)\n            except Exception as e:\n                self.logger.error(f\"Failed to compress key {key}: {e}\")\n                \n        # 3. 메모리 정책 확인 및 설정\n        if memory_info['maxmemory_policy'] != 'allkeys-lru':\n            # Redis 설정 파일 수정 필요 (여기서는 런타임에 변경 불가)\n            self.logger.warning(\"Consider changing maxmemory-policy to allkeys-lru\")\n            \n        # 최적화 후 메모리 사용량 확인\n        memory_info = self.get_memory_usage()\n        new_mb = memory_info['used_memory'] / (1024 * 1024)\n        self.logger.info(f\"Memory usage after optimization: {new_mb:.2f}MB\")\n        \n        return new_mb <= target_mb\n    except Exception as e:\n        self.logger.error(f\"Memory optimization failed: {e}\")\n        return False\n```\n<info added on 2025-07-25T09:37:55.939Z>\n구현 완료 보고:\n\n1. DataSerializer 클래스 구현 (qb/utils/serialization.py)\n   - JSON, Pickle 직렬화 포맷 지원\n   - zlib, lz4, snappy 압축 알고리즘 지원\n   - NumPy, Pandas, datetime 등 확장 타입 지원\n   - 메타데이터 기반 자동 역직렬화\n\n2. Redis Manager 통합\n   - 압축 지원 추가 (use_compression 파라미터)\n   - 복합 데이터 저장/조회 메서드 추가\n   - 배치 작업 메서드 추가\n   - 성능 최적화 메서드 추가\n\n3. 테스트 및 벤치마크\n   - 14개 단위 테스트 모두 통과 (tests/test_serialization.py)\n   - 성능 벤치마크 구현 (tests/benchmark_serialization.py)\n   - 벤치마크 결과: pickle+none이 가장 빠르고, json+lz4가 균형잡힌 선택\n   - Redis 통합 테스트 성공, 14.1% 압축률 달성\n</info added on 2025-07-25T09:37:55.939Z>",
            "status": "done",
            "testStrategy": "1. 직렬화/역직렬화 및 압축 테스트:\n```python\nimport unittest\nimport json\nimport sys\nfrom utils.serialization import Serializer\nfrom utils.redis_manager import RedisManager\n\nclass TestSerialization(unittest.TestCase):\n    def setUp(self):\n        self.serializer = Serializer(compress=False)\n        self.serializer_compressed = Serializer(compress=True)\n        \n    def test_json_serialization(self):\n        data = {'name': 'test', 'values': [1, 2, 3], 'nested': {'a': 1, 'b': 2}}\n        serialized = self.serializer.serialize(data)\n        deserialized = self.serializer.deserialize(serialized)\n        self.assertEqual(data, deserialized)\n        \n    def test_compression(self):\n        # 큰 데이터 생성\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        \n        # 압축 없이 직렬화\n        normal = self.serializer.serialize(large_data)\n        \n        # 압축 적용 직렬화\n        compressed = self.serializer_compressed.serialize(large_data)\n        \n        # 압축 효과 확인\n        self.assertLess(len(compressed), len(normal))\n        \n        # 압축 데이터 역직렬화 확인\n        decompressed = self.serializer_compressed.deserialize(compressed)\n        self.assertEqual(large_data, decompressed)\n        \nclass TestRedisCompression(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager(use_compression=True)\n        self.test_key = 'test:compression'\n        \n    def tearDown(self):\n        self.redis.redis.delete(self.test_key)\n        \n    def test_compressed_storage(self):\n        # 큰 데이터 생성\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        \n        # 압축 저장\n        self.assertTrue(self.redis.set_compressed(self.test_key, large_data))\n        \n        # 조회 및 검증\n        retrieved = self.redis.get_compressed(self.test_key)\n        self.assertEqual(large_data, retrieved)\n        \n    def test_auto_compression(self):\n        # 작은 데이터\n        small_data = {'name': 'test'}\n        self.redis.set_large_data(self.test_key + ':small', small_data)\n        \n        # 큰 데이터\n        large_data = {'data': ['item' + str(i) for i in range(1000)]}\n        self.redis.set_large_data(self.test_key + ':large', large_data)\n        \n        # 조회 및 검증\n        small_retrieved = self.redis.get_large_data(self.test_key + ':small')\n        large_retrieved = self.redis.get_large_data(self.test_key + ':large')\n        \n        self.assertEqual(small_data, small_retrieved)\n        self.assertEqual(large_data, large_retrieved)\n        \n        # 메모리 사용량 비교\n        small_size = self.redis.get_key_memory_usage(self.test_key + ':small')\n        large_size = self.redis.get_key_memory_usage(self.test_key + ':large')\n        \n        # 압축 효과 확인 (정확한 비교는 어렵지만 대략적인 비교)\n        normal_json_size = len(json.dumps(large_data))\n        self.assertLess(large_size, normal_json_size * 0.8)  # 최소 20% 압축 효과 기대\n\nclass TestMemoryOptimization(unittest.TestCase):\n    def setUp(self):\n        self.redis = RedisManager()\n        \n    def test_memory_usage_info(self):\n        memory_info = self.redis.get_memory_usage()\n        self.assertIn('used_memory_human', memory_info)\n        self.assertIn('maxmemory_policy', memory_info)\n        \n    def test_key_memory_usage(self):\n        # 테스트 데이터 저장\n        test_key = 'test:memory:usage'\n        test_data = {'data': ['x' * 100 for _ in range(100)]}\n        self.redis.redis.set(test_key, json.dumps(test_data))\n        \n        # 메모리 사용량 확인\n        usage = self.redis.get_key_memory_usage(test_key)\n        self.assertGreater(usage, 0)\n        \n        # 정리\n        self.redis.redis.delete(test_key)\n        \n    def test_optimize_memory(self):\n        # 여러 테스트 데이터 저장\n        for i in range(10):\n            key = f'test:optimize:memory:{i}'\n            data = {'index': i, 'data': ['x' * 100 for _ in range(100)]}\n            self.redis.redis.set(key, json.dumps(data))\n            \n        # 최적화 실행\n        result = self.redis.optimize_memory(target_mb=100)  # 높은 값으로 설정하여 항상 성공하도록\n        self.assertTrue(result)\n        \n        # 정리\n        for i in range(10):\n            self.redis.redis.delete(f'test:optimize:memory:{i}')\n```"
          },
          {
            "id": 5,
            "title": "Redis 모니터링 및 상태 확인 기능 구현",
            "description": "Redis 서버 상태 모니터링, 메모리 사용량 추적, 성능 지표 수집 및 시각화 기능 구현",
            "dependencies": [
              "21.3",
              "21.4"
            ],
            "details": "Redis 모니터링 및 상태 확인을 위한 클래스를 구현합니다:\n\n```python\n# utils/redis_monitor.py\n\nimport time\nimport logging\nimport asyncio\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom utils.redis_manager import RedisManager\nfrom utils.event_bus import EventBus\n\nclass RedisMonitor:\n    \"\"\"Redis 서버 모니터링 및 상태 확인 도구\"\"\"\n    \n    def __init__(self, redis_manager: RedisManager, event_bus: Optional[EventBus] = None):\n        self.redis = redis_manager\n        self.event_bus = event_bus\n        self.logger = logging.getLogger(__name__)\n        self.stats_history = []  # 통계 기록\n        self.max_history = 100  # 최대 기록 수\n        self.running = False\n        self.monitor_task = None\n        \n    async def start_monitoring(self, interval_seconds: int = 60):\n        \"\"\"모니터링 시작\"\"\"\n        if self.running:\n            return\n            \n        self.running = True\n        self.monitor_task = asyncio.create_task(self._monitoring_loop(interval_seconds))\n        self.logger.info(f\"Redis monitoring started with {interval_seconds}s interval\")\n        \n    async def stop_monitoring(self):\n        \"\"\"모니터링 중지\"\"\"\n        if not self.running:\n            return\n            \n        self.running = False\n        if self.monitor_task:\n            self.monitor_task.cancel()\n            try:\n                await self.monitor_task\n            except asyncio.CancelledError:\n                pass\n                \n        self.logger.info(\"Redis monitoring stopped\")\n        \n    async def _monitoring_loop(self, interval_seconds: int):\n        \"\"\"모니터링 루프\"\"\"\n        while self.running:\n            try:\n                stats = self.collect_stats()\n                self._add_to_history(stats)\n                \n                # 메모리 사용량 경고\n                self._check_memory_alerts(stats)\n                \n                # 이벤트 버스로 상태 발행\n                if self.event_bus:\n                    self.event_bus.publish(EventBus.CHANNELS['SYSTEM_STATUS'], {\n                        'component': 'redis',\n                        'status': 'ok' if stats['is_connected'] else 'error',\n                        'memory_usage_percent': stats['memory_usage_percent'],\n                        'clients_connected': stats['clients_connected'],\n                        'timestamp': int(time.time())\n                    })\n                    \n                await asyncio.sleep(interval_seconds)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self.logger.error(f\"Error in monitoring loop: {e}\")\n                await asyncio.sleep(interval_seconds)\n                \n    def collect_stats(self) -> Dict[str, Any]:\n        \"\"\"Redis 서버 통계 수집\"\"\"\n        try:\n            # 연결 확인\n            is_connected = self.redis.ping()\n            \n            if not is_connected:\n                return {\n                    'timestamp': datetime.now().isoformat(),\n                    'is_connected': False\n                }\n                \n            # 서버 정보 조회\n            info = self.redis.get_info()\n            memory_info = self.redis.get_memory_usage()\n            \n            # 메모리 사용량 계산\n            used_memory = memory_info.get('used_memory', 0)\n            max_memory = memory_info.get('maxmemory', 0)\n            memory_usage_percent = (used_memory / max_memory * 100) if max_memory > 0 else 0\n            \n            # 통계 구성\n            stats = {\n                'timestamp': datetime.now().isoformat(),\n                'is_connected': True,\n                'redis_version': info.get('redis_version', 'unknown'),\n                'uptime_days': info.get('uptime_in_days', 0),\n                'used_memory': used_memory,\n                'used_memory_human': memory_info.get('used_memory_human', '0B'),\n                'max_memory': max_memory,\n                'max_memory_human': memory_info.get('maxmemory_human', '0B'),\n                'memory_usage_percent': memory_usage_percent,\n                'clients_connected': info.get('connected_clients', 0),\n                'total_commands': info.get('total_commands_processed', 0),\n                'keyspace_hits': info.get('keyspace_hits', 0),\n                'keyspace_misses': info.get('keyspace_misses', 0),\n                'hit_rate': self._calculate_hit_rate(info),\n                'evicted_keys': info.get('evicted_keys', 0),\n                'expired_keys': info.get('expired_keys', 0),\n                'db_keys': self._count_keys()\n            }\n            \n            return stats\n        except Exception as e:\n            self.logger.error(f\"Failed to collect Redis stats: {e}\")\n            return {\n                'timestamp': datetime.now().isoformat(),\n                'is_connected': False,\n                'error': str(e)\n            }\n            \n    def _calculate_hit_rate(self, info: Dict[str, Any]) -> float:\n        \"\"\"캐시 히트율 계산\"\"\"\n        hits = info.get('keyspace_hits', 0)\n        misses = info.get('keyspace_misses', 0)\n        total = hits + misses\n        return (hits / total * 100) if total > 0 else 0\n        \n    def _count_keys(self) -> Dict[str, int]:\n        \"\"\"데이터베이스별 키 개수 조회\"\"\"\n        result = {}\n        try:\n            info = self.redis.get_info()\n            for key, value in info.items():\n                if key.startswith('db'):\n                    db_number = key[2:]  # 'db0' -> '0'\n                    keys_count = int(value.get('keys', 0)) if isinstance(value, dict) else 0\n                    result[db_number] = keys_count\n        except Exception as e:\n            self.logger.error(f\"Failed to count keys: {e}\")\n        return result\n        \n    def _add_to_history(self, stats: Dict[str, Any]):\n        \"\"\"통계 기록에 추가\"\"\"\n        self.stats_history.append(stats)\n        if len(self.stats_history) > self.max_history:\n            self.stats_history.pop(0)  # 가장 오래된 기록 제거\n            \n    def _check_memory_alerts(self, stats: Dict[str, Any]):\n        \"\"\"메모리 사용량 경고 확인\"\"\"\n        if not stats.get('is_connected', False):\n            return\n            \n        memory_percent = stats.get('memory_usage_percent', 0)\n        \n        # 메모리 사용량 경고\n        if memory_percent > 90:\n            message = f\"CRITICAL: Redis memory usage at {memory_percent:.1f}%\"\n            self.logger.critical(message)\n            \n            # 이벤트 버스로 알림 발행\n            if self.event_bus:\n                self.event_bus.publish(EventBus.CHANNELS['RISK_ALERT'], {\n                    'level': 'critical',\n                    'component': 'redis',\n                    'message': message,\n                    'memory_percent': memory_percent,\n                    'timestamp': int(time.time())\n                })\n                \n            # 자동 메모리 최적화 시도\n            self.redis.optimize_memory()\n            \n        elif memory_percent > 75:\n            message = f\"WARNING: Redis memory usage at {memory_percent:.1f}%\"\n            self.logger.warning(message)\n            \n            # 이벤트 버스로 알림 발행\n            if self.event_bus:\n                self.event_bus.publish(EventBus.CHANNELS['RISK_ALERT'], {\n                    'level': 'warning',\n                    'component': 'redis',\n                    'message': message,\n                    'memory_percent': memory_percent,\n                    'timestamp': int(time.time())\n                })\n                \n    def get_stats_history(self, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"특정 기간 동안의 통계 기록 조회\"\"\"\n        if not self.stats_history:\n            return []\n            \n        cutoff = datetime.now() - timedelta(hours=hours)\n        cutoff_str = cutoff.isoformat()\n        \n        return [stats for stats in self.stats_history \n                if stats.get('timestamp', '') >= cutoff_str]\n                \n    def get_memory_trend(self, hours: int = 24) -> List[Tuple[str, float]]:\n        \"\"\"메모리 사용량 추이 조회\"\"\"\n        stats = self.get_stats_history(hours)\n        return [(s['timestamp'], s.get('memory_usage_percent', 0)) for s in stats \n                if s.get('is_connected', False)]\n                \n    def get_hit_rate_trend(self, hours: int = 24) -> List[Tuple[str, float]]:\n        \"\"\"캐시 히트율 추이 조회\"\"\"\n        stats = self.get_stats_history(hours)\n        return [(s['timestamp'], s.get('hit_rate', 0)) for s in stats \n                if s.get('is_connected', False)]\n                \n    def get_key_distribution(self) -> Dict[str, int]:\n        \"\"\"키 패턴별 분포 조회\"\"\"\n        patterns = [\n            'market:*',\n            'candles:*',\n            'indicators:*',\n            'orderbook:*',\n            'trades:*'\n        ]\n        \n        result = {}\n        for pattern in patterns:\n            keys = self.redis.get_keys_by_pattern(pattern)\n            result[pattern] = len(keys)\n            \n        return result\n        \n    def get_key_memory_distribution(self) -> Dict[str, int]:\n        \"\"\"키 패턴별 메모리 사용량 조회\"\"\"\n        patterns = [\n            'market:*',\n            'candles:*',\n            'indicators:*',\n            'orderbook:*',\n            'trades:*'\n        ]\n        \n        result = {}\n        for pattern in patterns:\n            memory_usage = self.redis.get_pattern_memory_usage(pattern)\n            result[pattern] = sum(memory_usage.values())\n            \n        return result\n        \n    def get_status_summary(self) -> Dict[str, Any]:\n        \"\"\"Redis 상태 요약 조회\"\"\"\n        stats = self.collect_stats()\n        \n        if not stats.get('is_connected', False):\n            return {\n                'status': 'disconnected',\n                'timestamp': stats.get('timestamp')\n            }\n            \n        # 상태 평가\n        memory_percent = stats.get('memory_usage_percent', 0)\n        if memory_percent > 90:\n            status = 'critical'\n        elif memory_percent > 75:\n            status = 'warning'\n        else:\n            status = 'ok'\n            \n        return {\n            'status': status,\n            'timestamp': stats.get('timestamp'),\n            'memory_usage_percent': memory_percent,\n            'used_memory_human': stats.get('used_memory_human'),\n            'max_memory_human': stats.get('max_memory_human'),\n            'clients_connected': stats.get('clients_connected'),\n            'hit_rate': stats.get('hit_rate'),\n            'total_keys': sum(stats.get('db_keys', {}).values()),\n            'uptime_days': stats.get('uptime_days')\n        }\n```\n\n모니터링 시각화를 위한 간단한 CLI 도구를 구현합니다:\n\n```python\n# utils/redis_cli_monitor.py\n\nimport asyncio\nimport argparse\nimport time\nfrom datetime import datetime\nfrom utils.redis_manager import RedisManager\nfrom utils.redis_monitor import RedisMonitor\n\nasync def display_stats(redis_host='localhost', redis_port=6379, interval=5):\n    \"\"\"Redis 상태 정보를 주기적으로 표시\"\"\"\n    redis = RedisManager(host=redis_host, port=redis_port)\n    monitor = RedisMonitor(redis)\n    \n    print(f\"Redis Monitor - {redis_host}:{redis_port}\")\n    print(\"-\" * 50)\n    \n    try:\n        while True:\n            stats = monitor.collect_stats()\n            \n            if not stats.get('is_connected', False):\n                print(f\"\\r[{datetime.now().strftime('%H:%M:%S')}] Connection Error: {stats.get('error', 'Unknown error')}\")\n                await asyncio.sleep(interval)\n                continue\n                \n            # 화면 지우기 (Windows/Linux 호환)\n            print(\"\\033[H\\033[J\", end=\"\")\n            \n            print(f\"Redis Monitor - {redis_host}:{redis_port} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n            print(\"-\" * 50)\n            print(f\"Redis Version: {stats.get('redis_version', 'Unknown')}\")\n            print(f\"Uptime: {stats.get('uptime_days', 0)} days\")\n            print(\"-\" * 50)\n            print(f\"Memory Usage: {stats.get('used_memory_human', '0B')} / {stats.get('max_memory_human', '0B')} \"\n                  f\"({stats.get('memory_usage_percent', 0):.1f}%)\")\n            print(f\"Connected Clients: {stats.get('clients_connected', 0)}\")\n            print(f\"Commands Processed: {stats.get('total_commands', 0)}\")\n            print(f\"Hit Rate: {stats.get('hit_rate', 0):.1f}%\")\n            print(\"-\" * 50)\n            \n            # 키 분포 표시\n            key_dist = monitor.get_key_distribution()\n            print(\"Key Distribution:\")\n            for pattern, count in key_dist.items():\n                print(f\"  {pattern}: {count}\")\n                \n            print(\"-\" * 50)\n            \n            # 메모리 분포 표시\n            mem_dist = monitor.get_key_memory_distribution()\n            print(\"Memory Distribution:\")\n            for pattern, mem in mem_dist.items():\n                print(f\"  {pattern}: {mem / 1024:.1f} KB\")\n                \n            print(\"-\" * 50)\n            print(f\"Press Ctrl+C to exit. Refreshing every {interval} seconds...\")\n            \n            await asyncio.sleep(interval)\n    except KeyboardInterrupt:\n        print(\"\\nMonitoring stopped.\")\n        \ndef main():\n    parser = argparse.ArgumentParser(description='Redis Monitoring CLI')\n    parser.add_argument('--host', default='localhost', help='Redis host')\n    parser.add_argument('--port', type=int, default=6379, help='Redis port')\n    parser.add_argument('--interval', type=int, default=5, help='Refresh interval in seconds')\n    args = parser.parse_args()\n    \n    asyncio.run(display_stats(args.host, args.port, args.interval))\n    \nif __name__ == '__main__':\n    main()\n```",
            "status": "done",
            "testStrategy": "1. Redis 모니터링 테스트:\n```python\nimport unittest\nimport asyncio\nfrom unittest.mock import MagicMock, patch\nfrom utils.redis_manager import RedisManager\nfrom utils.redis_monitor import RedisMonitor\nfrom utils.event_bus import EventBus\n\nclass TestRedisMonitor(unittest.IsolatedAsyncioTestCase):\n    async def asyncSetUp(self):\n        self.redis = RedisManager()\n        self.event_bus = MagicMock(spec=EventBus)\n        self.monitor = RedisMonitor(self.redis, self.event_bus)\n        \n    async def test_collect_stats(self):\n        # 기본 통계 수집 테스트\n        stats = self.monitor.collect_stats()\n        self.assertIsInstance(stats, dict)\n        self.assertIn('is_connected', stats)\n        self.assertIn('timestamp', stats)\n        \n        if stats['is_connected']:\n            self.assertIn('memory_usage_percent', stats)\n            self.assertIn('clients_connected', stats)\n            self.assertIn('hit_rate', stats)\n            \n    async def test_monitoring_loop(self):\n        # 모니터링 루프 테스트 (짧은 시간만 실행)\n        await self.monitor.start_monitoring(interval_seconds=1)\n        await asyncio.sleep(2)  # 최소 2회 실행되도록\n        await self.monitor.stop_monitoring()\n        \n        # 통계 기록 확인\n        self.assertGreater(len(self.monitor.stats_history), 0)\n        \n    async def test_memory_alerts(self):\n        # 메모리 경고 테스트 (모의 데이터 사용)\n        with patch.object(self.monitor, 'collect_stats') as mock_collect:\n            # 높은 메모리 사용량 모의\n            mock_collect.return_value = {\n                'is_connected': True,\n                'timestamp': '2023-01-01T00:00:00',\n                'memory_usage_percent': 95,\n                'used_memory_human': '95MB',\n                'max_memory_human': '100MB'\n            }\n            \n            # 모니터링 실행\n            await self.monitor.start_monitoring(interval_seconds=1)\n            await asyncio.sleep(1.5)  # 최소 1회 실행되도록\n            await self.monitor.stop_monitoring()\n            \n            # 이벤트 발행 확인\n            self.event_bus.publish.assert_called()\n            # RISK_ALERT 채널에 발행되었는지 확인\n            call_args = self.event_bus.publish.call_args_list\n            channel_used = False\n            for call in call_args:\n                args, _ = call\n                if args[0] == EventBus.CHANNELS['RISK_ALERT']:\n                    channel_used = True\n                    break\n            self.assertTrue(channel_used)\n            \n    async def test_get_stats_history(self):\n        # 통계 기록 테스트\n        # 몇 개의 모의 통계 추가\n        for i in range(5):\n            self.monitor._add_to_history({\n                'timestamp': f'2023-01-01T{i:02d}:00:00',\n                'is_connected': True,\n                'memory_usage_percent': 50 + i\n            })\n            \n        # 기록 조회\n        history = self.monitor.get_stats_history()\n        self.assertEqual(len(history), 5)\n        \n    def test_get_key_distribution(self):\n        # 키 분포 테스트\n        # 테스트 데이터 생성\n        for i in range(3):\n            self.redis.redis.set(f\"market:BTC{i}\", f\"value{i}\")\n            self.redis.redis.set(f\"candles:ETH{i}:1m\", f\"candle{i}\")\n            \n        # 분포 조회\n        dist = self.monitor.get_key_distribution()\n        self.assertIn('market:*', dist)\n        self.assertIn('candles:*', dist)\n        self.assertGreaterEqual(dist['market:*'], 3)\n        self.assertGreaterEqual(dist['candles:*'], 3)\n        \n        # 정리\n        for i in range(3):\n            self.redis.redis.delete(f\"market:BTC{i}\")\n            self.redis.redis.delete(f\"candles:ETH{i}:1m\")\n            \n    def test_get_status_summary(self):\n        # 상태 요약 테스트\n        summary = self.monitor.get_status_summary()\n        self.assertIn('status', summary)\n        self.assertIn('timestamp', summary)\n        \n        if summary['status'] != 'disconnected':\n            self.assertIn('memory_usage_percent', summary)\n            self.assertIn('used_memory_human', summary)\n\n# CLI 모니터링 도구 테스트 (수동 테스트 필요)\n# python -m utils.redis_cli_monitor --host localhost --port 6379 --interval 2\n```"
          }
        ]
      },
      {
        "id": 22,
        "title": "한국투자증권 API 연동 및 인증 시스템",
        "description": "한국투자증권 API 연동을 위한 인증 시스템 및 기본 API 클라이언트 구현",
        "details": "1. 한국투자증권 Open API 계정 설정 및 API 키 발급\n2. API 인증 모듈 구현 (utils/kis_auth.py):\n   - OAuth 토큰 발급 및 갱신\n   - API 키 안전한 저장 및 관리 (.env 파일 활용)\n3. 기본 API 클라이언트 클래스 구현 (collectors/kis_client.py):\n```python\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        self.mock = mock  # 모의투자 여부\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        self.token = None\n        self.token_expired_at = None\n        \n    async def get_access_token(self):\n        # 토큰 발급 로직\n        \n    async def refresh_token_if_needed(self):\n        # 토큰 만료 확인 및 갱신 로직\n        \n    async def request(self, method, endpoint, params=None, data=None):\n        # API 요청 공통 로직 (재시도, 에러 처리 포함)\n```\n4. API 호출 제한 관리 (Rate Limiting):\n   - 요청 간격 조절\n   - 일일 API 호출 횟수 추적\n5. 에러 처리 및 재시도 메커니즘 구현\n6. 모의투자와 실전투자 모드 전환 기능\n7. API 응답 로깅 및 모니터링\n8. 주요 API 엔드포인트 래퍼 함수 구현:\n   - 계좌 정보 조회\n   - 종목 정보 조회\n   - 주문 관련 기능",
        "testStrategy": "1. API 인증 및 토큰 발급 테스트\n2. 토큰 갱신 메커니즘 테스트\n3. 기본 API 엔드포인트 호출 테스트\n4. 에러 상황 시뮬레이션 및 재시도 로직 테스트\n5. Rate Limiting 준수 여부 테스트\n6. 모의투자 모드 전환 테스트\n7. 로깅 시스템 검증\n8. 장시간 실행 시 안정성 테스트",
        "priority": "high",
        "dependencies": [
          19
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "한국투자증권 API 계정 설정 및 환경 구성",
            "description": "한국투자증권 Open API 계정 생성, API 키 발급, 그리고 프로젝트에서 안전하게 사용하기 위한 환경 설정 구현",
            "dependencies": [],
            "details": "1. 한국투자증권 홈페이지에서 Open API 서비스 신청 및 계정 생성\n2. 실전투자 및 모의투자용 API 키(appkey, appsecret) 발급\n3. .env 파일 생성 및 API 키 저장 구조 설계:\n```\nKIS_APPKEY=발급받은앱키\nKIS_APPSECRET=발급받은앱시크릿\nKIS_ACCOUNT_NO=계좌번호\nKIS_MOCK=True  # 모의투자 여부\n```\n4. .env 파일 로드 유틸리티 함수 구현 (utils/config.py):\n```python\nimport os\nfrom dotenv import load_dotenv\n\ndef load_config():\n    load_dotenv()\n    return {\n        'kis_appkey': os.getenv('KIS_APPKEY'),\n        'kis_appsecret': os.getenv('KIS_APPSECRET'),\n        'kis_account_no': os.getenv('KIS_ACCOUNT_NO'),\n        'kis_mock': os.getenv('KIS_MOCK', 'True').lower() == 'true'\n    }\n```\n5. 필요한 패키지 설치: python-dotenv, aiohttp, cryptography",
            "status": "done",
            "testStrategy": "1. .env 파일 로드 테스트\n2. 환경 변수 접근 테스트\n3. 모의투자/실전투자 모드 전환 테스트\n4. API 키 암호화 저장 및 복호화 테스트"
          },
          {
            "id": 2,
            "title": "API 인증 모듈 구현",
            "description": "한국투자증권 API 인증을 위한 OAuth 토큰 발급, 갱신, 관리 기능을 제공하는 인증 모듈 구현",
            "dependencies": [
              "22.1"
            ],
            "details": "1. utils/kis_auth.py 파일 생성 및 KISAuth 클래스 구현:\n```python\nimport time\nimport hashlib\nimport json\nimport aiohttp\nfrom datetime import datetime, timedelta\n\nclass KISAuth:\n    def __init__(self, api_key, api_secret, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.mock = mock\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        # 모의투자 사용 시 URL 변경\n        if mock:\n            self.base_url = \"https://openapivts.koreainvestment.com:29443\"\n        self.token = None\n        self.token_expired_at = None\n        \n    async def issue_access_token(self):\n        \"\"\"OAuth 토큰 발급\"\"\"\n        endpoint = \"/oauth2/tokenP\"\n        url = f\"{self.base_url}{endpoint}\"\n        \n        # HMAC 기반 시그니처 생성\n        timestamp = str(int(time.time() * 1000))\n        message = timestamp + self.api_key + self.api_secret\n        hash_obj = hashlib.sha256(message.encode('utf-8'))\n        hashed = hash_obj.hexdigest()\n        \n        headers = {\n            \"content-type\": \"application/json\"\n        }\n        body = {\n            \"grant_type\": \"client_credentials\",\n            \"appkey\": self.api_key,\n            \"appsecret\": self.api_secret\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(url, headers=headers, json=body) as response:\n                if response.status == 200:\n                    result = await response.json()\n                    self.token = result.get('access_token')\n                    expires_in = result.get('expires_in', 86400)  # 기본 24시간\n                    self.token_expired_at = datetime.now() + timedelta(seconds=expires_in - 300)  # 5분 여유\n                    return self.token\n                else:\n                    error_text = await response.text()\n                    raise Exception(f\"Token issue failed: {response.status} - {error_text}\")\n    \n    async def ensure_token(self):\n        \"\"\"토큰이 없거나 만료 예정이면 갱신\"\"\"\n        if self.token is None or self.token_expired_at is None or datetime.now() >= self.token_expired_at:\n            await self.issue_access_token()\n        return self.token\n        \n    def get_auth_headers(self):\n        \"\"\"인증 헤더 반환\"\"\"\n        if not self.token:\n            raise Exception(\"Token not issued yet. Call ensure_token() first.\")\n        return {\n            \"Authorization\": f\"Bearer {self.token}\",\n            \"appkey\": self.api_key,\n            \"appsecret\": self.api_secret,\n            \"tr_id\": \"FHKST01010100\"  # 기본 TR ID, 실제 요청 시 오버라이드 필요\n        }\n```\n2. 토큰 저장 및 복원 메커니즘 추가 (선택적):\n   - 토큰 파일 저장 기능\n   - 애플리케이션 재시작 시 토큰 복원 기능",
            "status": "done",
            "testStrategy": "1. 토큰 발급 성공 테스트\n2. 토큰 만료 시 자동 갱신 테스트\n3. 인증 헤더 생성 테스트\n4. 잘못된 API 키로 인증 실패 테스트\n5. 모의투자/실전투자 URL 전환 테스트\n6. 네트워크 오류 시 예외 처리 테스트"
          },
          {
            "id": 3,
            "title": "기본 API 클라이언트 클래스 구현",
            "description": "한국투자증권 API 호출을 위한 기본 클라이언트 클래스 구현 및 공통 요청 처리 로직 개발",
            "dependencies": [
              "22.2"
            ],
            "details": "1. collectors/kis_client.py 파일 생성 및 KISClient 클래스 구현:\n```python\nimport json\nimport time\nimport logging\nimport asyncio\nimport aiohttp\nfrom datetime import datetime\nfrom utils.kis_auth import KISAuth\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=False):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        self.mock = mock  # 모의투자 여부\n        self.base_url = \"https://openapi.koreainvestment.com:9443\"\n        if mock:\n            self.base_url = \"https://openapivts.koreainvestment.com:29443\"\n        self.auth = KISAuth(api_key, api_secret, mock)\n        self.logger = logging.getLogger(\"KISClient\")\n        self.request_times = []  # Rate limiting 관리용\n        self.max_requests_per_sec = 5  # 초당 최대 요청 수\n        self.daily_request_count = 0  # 일일 요청 수 추적\n        self.last_day = datetime.now().day\n        \n    async def _manage_rate_limit(self):\n        \"\"\"API 호출 속도 제한 관리\"\"\"\n        now = time.time()\n        # 1초 이내 요청들만 유지\n        self.request_times = [t for t in self.request_times if now - t < 1.0]\n        \n        # 현재 초당 요청 수가 제한에 도달했으면 대기\n        if len(self.request_times) >= self.max_requests_per_sec:\n            wait_time = 1.0 - (now - self.request_times[0])\n            if wait_time > 0:\n                self.logger.debug(f\"Rate limit reached, waiting {wait_time:.2f}s\")\n                await asyncio.sleep(wait_time)\n        \n        # 일일 요청 수 관리\n        current_day = datetime.now().day\n        if current_day != self.last_day:\n            self.daily_request_count = 0\n            self.last_day = current_day\n        self.daily_request_count += 1\n        \n        # 현재 시간 기록\n        self.request_times.append(time.time())\n    \n    async def request(self, method, endpoint, tr_id=None, params=None, data=None, headers=None, retry_count=3):\n        \"\"\"API 요청 공통 로직 (재시도, 에러 처리 포함)\"\"\"\n        await self._manage_rate_limit()\n        \n        # 토큰 확인 및 갱신\n        await self.auth.ensure_token()\n        \n        # 기본 헤더 설정\n        request_headers = self.auth.get_auth_headers()\n        if tr_id:\n            request_headers[\"tr_id\"] = tr_id\n        if headers:\n            request_headers.update(headers)\n        \n        url = f\"{self.base_url}{endpoint}\"\n        \n        for attempt in range(retry_count):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    request_kwargs = {\n                        \"headers\": request_headers\n                    }\n                    \n                    if params:\n                        request_kwargs[\"params\"] = params\n                    \n                    if data:\n                        request_kwargs[\"json\"] = data\n                    \n                    self.logger.debug(f\"Requesting {method} {url}\")\n                    async with session.request(method, url, **request_kwargs) as response:\n                        response_text = await response.text()\n                        \n                        # 응답 로깅\n                        self.logger.debug(f\"Response {response.status}: {response_text[:200]}...\")\n                        \n                        if response.status == 200:\n                            try:\n                                return await response.json()\n                            except json.JSONDecodeError:\n                                return response_text\n                        elif response.status == 401:  # 인증 오류\n                            # 토큰 재발급 시도\n                            self.logger.warning(\"Authentication error, refreshing token\")\n                            await self.auth.issue_access_token()\n                            if attempt < retry_count - 1:  # 마지막 시도가 아니면 재시도\n                                continue\n                        \n                        # 기타 오류\n                        error_msg = f\"API request failed: {response.status} - {response_text}\"\n                        self.logger.error(error_msg)\n                        raise Exception(error_msg)\n            except aiohttp.ClientError as e:\n                if attempt < retry_count - 1:  # 마지막 시도가 아니면 재시도\n                    wait_time = 2 ** attempt  # 지수 백오프\n                    self.logger.warning(f\"Request failed: {str(e)}. Retrying in {wait_time}s\")\n                    await asyncio.sleep(wait_time)\n                else:\n                    self.logger.error(f\"Request failed after {retry_count} attempts: {str(e)}\")\n                    raise\n        \n        raise Exception(f\"Request failed after {retry_count} attempts\")\n```\n2. 로깅 설정 추가 (utils/logging_config.py):\n```python\nimport logging\nimport sys\nfrom logging.handlers import RotatingFileHandler\nimport os\n\ndef setup_logging(log_dir=\"logs\"):\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n        \n    # 로거 설정\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    \n    # 콘솔 핸들러\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.INFO)\n    console_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    console_handler.setFormatter(console_format)\n    \n    # 파일 핸들러 (일반 로그)\n    file_handler = RotatingFileHandler(\n        os.path.join(log_dir, 'app.log'), \n        maxBytes=10*1024*1024,  # 10MB\n        backupCount=5\n    )\n    file_handler.setLevel(logging.DEBUG)\n    file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(file_format)\n    \n    # API 요청 전용 로그 파일\n    api_file_handler = RotatingFileHandler(\n        os.path.join(log_dir, 'api_requests.log'), \n        maxBytes=10*1024*1024,  # 10MB\n        backupCount=5\n    )\n    api_file_handler.setLevel(logging.DEBUG)\n    api_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    api_file_handler.setFormatter(api_format)\n    \n    # API 로거 설정\n    api_logger = logging.getLogger('KISClient')\n    api_logger.addHandler(api_file_handler)\n    \n    # 기본 로거에 핸들러 추가\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n```",
            "status": "done",
            "testStrategy": "1. 기본 API 요청 성공 테스트\n2. 인증 오류 시 토큰 자동 갱신 테스트\n3. 네트워크 오류 시 재시도 로직 테스트\n4. Rate limiting 준수 테스트\n5. 일일 요청 수 추적 테스트\n6. 로깅 시스템 작동 테스트\n7. 다양한 HTTP 메소드(GET, POST, PUT, DELETE) 테스트"
          },
          {
            "id": 4,
            "title": "주요 API 엔드포인트 래퍼 함수 구현",
            "description": "한국투자증권 API의 주요 기능(계좌 정보, 종목 정보, 주문 기능 등)에 대한 래퍼 함수 구현",
            "dependencies": [
              "22.3"
            ],
            "details": "1. KISClient 클래스에 주요 API 엔드포인트 래퍼 함수 추가:\n```python\n# collectors/kis_client.py에 다음 메소드 추가\n\n# 계좌 정보 조회\nasync def get_account_info(self):\n    \"\"\"계좌 정보 조회\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/inquire-balance\"\n    tr_id = \"TTTC8434R\" if not self.mock else \"VTTC8434R\"  # 실전/모의 TR ID 구분\n    \n    params = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"AFHR_FLPR_YN\": \"N\",\n        \"OFL_YN\": \"N\",\n        \"INQR_DVSN\": \"01\",\n        \"UNPR_DVSN\": \"01\",\n        \"FUND_STTL_ICLD_YN\": \"N\",\n        \"FNCG_AMT_AUTO_RDPT_YN\": \"N\",\n        \"PRCS_DVSN\": \"01\",\n        \"CTX_AREA_FK100\": \"\",\n        \"CTX_AREA_NK100\": \"\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# 종목 정보 조회\nasync def get_stock_info(self, stock_code):\n    \"\"\"종목 기본 정보 조회\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-price\"\n    tr_id = \"FHKST01010100\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# 주식 현재가 조회\nasync def get_stock_price(self, stock_code):\n    \"\"\"종목 현재가 조회\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-price\"\n    tr_id = \"FHKST01010100\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# 주식 호가 조회\nasync def get_stock_orderbook(self, stock_code):\n    \"\"\"종목 호가 정보 조회\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-asking-price-exp-ccn\"\n    tr_id = \"FHKST01010200\"\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# 주식 일봉 조회\nasync def get_stock_daily_chart(self, stock_code, start_date=None, end_date=None, period=None):\n    \"\"\"종목 일봉 차트 조회\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/quotations/inquire-daily-price\"\n    tr_id = \"FHKST01010400\"\n    \n    # 기본값 설정\n    if not end_date:\n        end_date = datetime.now().strftime(\"%Y%m%d\")\n    \n    if not start_date and period:\n        # period일 전 데이터부터 조회\n        start_date = (datetime.now() - timedelta(days=period)).strftime(\"%Y%m%d\")\n    \n    params = {\n        \"FID_COND_MRKT_DIV_CODE\": \"J\",\n        \"FID_INPUT_ISCD\": stock_code,\n        \"FID_PERIOD_DIV_CODE\": \"D\",\n        \"FID_ORG_ADJ_PRC\": \"1\",\n        \"FID_INPUT_DATE_1\": start_date if start_date else \"\",\n        \"FID_INPUT_DATE_2\": end_date,\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"GET\", endpoint, params=params, headers=headers)\n\n# 주식 주문\nasync def place_order(self, stock_code, order_type, quantity, price=0, order_division=\"00\"):\n    \"\"\"주식 주문 실행\n    \n    Args:\n        stock_code (str): 종목코드\n        order_type (str): 주문 타입 (01: 매도, 02: 매수)\n        quantity (int): 주문 수량\n        price (int, optional): 주문 가격. 시장가 주문 시 0.\n        order_division (str, optional): 주문구분 (00: 지정가, 01: 시장가)\n    \"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-cash\"\n    \n    # 실전/모의투자 구분\n    tr_id = \"\"\n    if order_type == \"01\":  # 매도\n        tr_id = \"TTTC0801U\" if not self.mock else \"VTTC0801U\"\n    else:  # 매수\n        tr_id = \"TTTC0802U\" if not self.mock else \"VTTC0802U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"PDNO\": stock_code,\n        \"ORD_DVSN\": order_division,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": str(price),\n        \"CTAC_TLNO\": \"\",  # 연락처\n        \"SLL_BUY_DVSN_CD\": order_type,\n        \"ALGO_NO\": \"\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n\n# 주문 취소/정정\nasync def cancel_order(self, order_no, stock_code, quantity):\n    \"\"\"주문 취소\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-rvsecncl\"\n    tr_id = \"TTTC0803U\" if not self.mock else \"VTTC0803U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"KRX_FWDG_ORD_ORGNO\": \"\",  # 한국거래소 주문조직번호\n        \"ORGN_ODNO\": order_no,  # 원주문번호\n        \"ORD_DVSN\": \"00\",  # 주문구분(취소)\n        \"RVSE_CNCL_DVSN_CD\": \"02\",  # 정정취소구분코드(02: 취소)\n        \"PDNO\": stock_code,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": \"0\",\n        \"CTAC_TLNO\": \"\",\n        \"RSVN_ORD_YN\": \"N\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n\n# 주문 정정\nasync def modify_order(self, order_no, stock_code, quantity, price):\n    \"\"\"주문 정정\"\"\"\n    endpoint = \"/uapi/domestic-stock/v1/trading/order-rvsecncl\"\n    tr_id = \"TTTC0803U\" if not self.mock else \"VTTC0803U\"\n    \n    data = {\n        \"CANO\": self.account_no[:8],\n        \"ACNT_PRDT_CD\": self.account_no[8:],\n        \"KRX_FWDG_ORD_ORGNO\": \"\",\n        \"ORGN_ODNO\": order_no,\n        \"ORD_DVSN\": \"00\",\n        \"RVSE_CNCL_DVSN_CD\": \"01\",  # 정정취소구분코드(01: 정정)\n        \"PDNO\": stock_code,\n        \"ORD_QTY\": str(quantity),\n        \"ORD_UNPR\": str(price),\n        \"CTAC_TLNO\": \"\",\n        \"RSVN_ORD_YN\": \"N\"\n    }\n    \n    headers = {\n        \"tr_id\": tr_id\n    }\n    \n    return await self.request(\"POST\", endpoint, data=data, headers=headers)\n```\n\n2. 래퍼 함수 사용 예제 스크립트 작성 (examples/kis_api_example.py):\n```python\nimport asyncio\nimport sys\nimport os\n\n# 프로젝트 루트 디렉토리를 Python 경로에 추가\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.config import load_config\nfrom collectors.kis_client import KISClient\nfrom utils.logging_config import setup_logging\n\nasync def main():\n    # 로깅 설정\n    logger = setup_logging()\n    \n    # 설정 로드\n    config = load_config()\n    \n    # KIS 클라이언트 초기화\n    client = KISClient(\n        api_key=config['kis_appkey'],\n        api_secret=config['kis_appsecret'],\n        account_no=config['kis_account_no'],\n        mock=config['kis_mock']\n    )\n    \n    # 계좌 정보 조회\n    account_info = await client.get_account_info()\n    print(\"\\n계좌 정보:\")\n    print(account_info)\n    \n    # 삼성전자 종목 정보 조회\n    stock_info = await client.get_stock_info(\"005930\")\n    print(\"\\n삼성전자 종목 정보:\")\n    print(stock_info)\n    \n    # 삼성전자 호가 정보 조회\n    orderbook = await client.get_stock_orderbook(\"005930\")\n    print(\"\\n삼성전자 호가 정보:\")\n    print(orderbook)\n    \n    # 삼성전자 일봉 조회 (최근 10일)\n    daily_chart = await client.get_stock_daily_chart(\"005930\", period=10)\n    print(\"\\n삼성전자 일봉 차트 (최근 10일):\")\n    print(daily_chart)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```",
            "status": "done",
            "testStrategy": "1. 각 래퍼 함수 기본 동작 테스트\n2. 계좌 정보 조회 테스트\n3. 종목 정보 조회 테스트\n4. 호가 정보 조회 테스트\n5. 일봉 데이터 조회 테스트\n6. 주문 기능 테스트 (모의투자 환경에서)\n7. 주문 취소/정정 테스트 (모의투자 환경에서)\n8. 다양한 입력값에 대한 예외 처리 테스트"
          },
          {
            "id": 5,
            "title": "모의투자와 실전투자 모드 전환 기능 구현",
            "description": "모의투자와 실전투자 모드 간 안전한 전환 기능 및 모드별 설정 관리 시스템 구현",
            "dependencies": [
              "22.3",
              "22.4"
            ],
            "details": "1. 모드 전환 관리 클래스 구현 (utils/trading_mode.py):\n```python\nimport os\nimport json\nimport logging\nfrom pathlib import Path\n\nclass TradingModeManager:\n    def __init__(self, config_path=\"config/trading_mode.json\"):\n        self.logger = logging.getLogger(\"TradingModeManager\")\n        self.config_path = Path(config_path)\n        self.config = self._load_config()\n        \n    def _load_config(self):\n        \"\"\"설정 파일 로드\"\"\"\n        if not self.config_path.exists():\n            # 기본 설정 생성\n            default_config = {\n                \"mode\": \"mock\",  # 기본값은 모의투자\n                \"mock\": {\n                    \"base_url\": \"https://openapivts.koreainvestment.com:29443\",\n                    \"tr_id_prefix\": \"V\"\n                },\n                \"real\": {\n                    \"base_url\": \"https://openapi.koreainvestment.com:9443\",\n                    \"tr_id_prefix\": \"T\"\n                },\n                \"safety_checks\": {\n                    \"confirm_real_mode\": True,\n                    \"max_order_amount\": 1000000,  # 실전 모드 최대 주문 금액\n                    \"max_daily_orders\": 20  # 실전 모드 일일 최대 주문 수\n                }\n            }\n            \n            # 설정 디렉토리 생성\n            os.makedirs(self.config_path.parent, exist_ok=True)\n            \n            # 설정 파일 저장\n            with open(self.config_path, 'w', encoding='utf-8') as f:\n                json.dump(default_config, f, indent=2, ensure_ascii=False)\n                \n            return default_config\n        \n        # 기존 설정 파일 로드\n        try:\n            with open(self.config_path, 'r', encoding='utf-8') as f:\n                return json.load(f)\n        except Exception as e:\n            self.logger.error(f\"Failed to load config: {str(e)}\")\n            # 오류 시 기본 설정 반환\n            return {\"mode\": \"mock\"}\n    \n    def save_config(self):\n        \"\"\"설정 파일 저장\"\"\"\n        try:\n            with open(self.config_path, 'w', encoding='utf-8') as f:\n                json.dump(self.config, f, indent=2, ensure_ascii=False)\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to save config: {str(e)}\")\n            return False\n    \n    def get_current_mode(self):\n        \"\"\"현재 거래 모드 반환\"\"\"\n        return self.config.get(\"mode\", \"mock\")\n    \n    def is_mock_mode(self):\n        \"\"\"모의투자 모드인지 확인\"\"\"\n        return self.get_current_mode() == \"mock\"\n    \n    def switch_to_mock_mode(self):\n        \"\"\"모의투자 모드로 전환\"\"\"\n        self.config[\"mode\"] = \"mock\"\n        success = self.save_config()\n        if success:\n            self.logger.info(\"Switched to MOCK trading mode\")\n        return success\n    \n    def switch_to_real_mode(self, force=False):\n        \"\"\"실전투자 모드로 전환\"\"\"\n        if not force and self.config.get(\"safety_checks\", {}).get(\"confirm_real_mode\", True):\n            confirmation = input(\"WARNING: You are switching to REAL trading mode. Type 'CONFIRM' to proceed: \")\n            if confirmation != \"CONFIRM\":\n                self.logger.warning(\"Real mode switch cancelled\")\n                return False\n        \n        self.config[\"mode\"] = \"real\"\n        success = self.save_config()\n        if success:\n            self.logger.warning(\"Switched to REAL trading mode\")\n        return success\n    \n    def get_base_url(self):\n        \"\"\"현재 모드에 맞는 base_url 반환\"\"\"\n        mode = self.get_current_mode()\n        return self.config.get(mode, {}).get(\"base_url\")\n    \n    def get_tr_id_prefix(self):\n        \"\"\"현재 모드에 맞는 TR ID 접두사 반환\"\"\"\n        mode = self.get_current_mode()\n        return self.config.get(mode, {}).get(\"tr_id_prefix\")\n    \n    def get_safety_settings(self):\n        \"\"\"안전 설정 반환\"\"\"\n        return self.config.get(\"safety_checks\", {})\n```\n\n2. KISClient 클래스 수정하여 TradingModeManager 통합:\n```python\n# collectors/kis_client.py 수정\n\nfrom utils.trading_mode import TradingModeManager\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=None):\n        self.api_key = api_key\n        self.api_secret = api_secret\n        self.account_no = account_no\n        \n        # 모드 관리자 초기화\n        self.mode_manager = TradingModeManager()\n        \n        # mock 파라미터가 명시적으로 전달된 경우 모드 설정\n        if mock is not None:\n            if mock:\n                self.mode_manager.switch_to_mock_mode()\n            else:\n                self.mode_manager.switch_to_real_mode(force=True)\n        \n        # 현재 모드에 따른 설정\n        self.mock = self.mode_manager.is_mock_mode()\n        self.base_url = self.mode_manager.get_base_url()\n        self.auth = KISAuth(api_key, api_secret, self.mock)\n        \n        # 나머지 초기화 코드...\n    \n    def switch_to_mock_mode(self):\n        \"\"\"모의투자 모드로 전환\"\"\"\n        if self.mode_manager.switch_to_mock_mode():\n            self.mock = True\n            self.base_url = self.mode_manager.get_base_url()\n            self.auth = KISAuth(self.api_key, self.api_secret, self.mock)\n            return True\n        return False\n    \n    def switch_to_real_mode(self):\n        \"\"\"실전투자 모드로 전환\"\"\"\n        if self.mode_manager.switch_to_real_mode():\n            self.mock = False\n            self.base_url = self.mode_manager.get_base_url()\n            self.auth = KISAuth(self.api_key, self.api_secret, self.mock)\n            return True\n        return False\n    \n    # TR ID 생성 헬퍼 메소드 추가\n    def _get_tr_id(self, base_id):\n        \"\"\"현재 모드에 맞는 TR ID 생성\"\"\"\n        prefix = self.mode_manager.get_tr_id_prefix()\n        return f\"{prefix}{base_id}\"\n    \n    # 기존 메소드들에서 하드코딩된 TR ID 대신 _get_tr_id 사용하도록 수정\n    # 예: tr_id = self._get_tr_id(\"TTC0802U\")\n```\n\n3. 모드 전환 예제 스크립트 (examples/switch_trading_mode.py):\n```python\nimport asyncio\nimport sys\nimport os\n\n# 프로젝트 루트 디렉토리를 Python 경로에 추가\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.config import load_config\nfrom collectors.kis_client import KISClient\nfrom utils.logging_config import setup_logging\n\nasync def main():\n    # 로깅 설정\n    logger = setup_logging()\n    \n    # 설정 로드\n    config = load_config()\n    \n    # KIS 클라이언트 초기화\n    client = KISClient(\n        api_key=config['kis_appkey'],\n        api_secret=config['kis_appsecret'],\n        account_no=config['kis_account_no']\n    )\n    \n    # 현재 모드 출력\n    print(f\"현재 거래 모드: {'모의투자' if client.mock else '실전투자'}\")\n    \n    # 모드 전환 메뉴\n    print(\"\\n1. 모의투자 모드로 전환\")\n    print(\"2. 실전투자 모드로 전환\")\n    print(\"3. 종료\")\n    \n    choice = input(\"\\n선택: \")\n    \n    if choice == \"1\":\n        if client.switch_to_mock_mode():\n            print(\"모의투자 모드로 전환되었습니다.\")\n        else:\n            print(\"모드 전환에 실패했습니다.\")\n    elif choice == \"2\":\n        if client.switch_to_real_mode():\n            print(\"실전투자 모드로 전환되었습니다.\")\n        else:\n            print(\"모드 전환에 실패했습니다.\")\n    \n    # 전환 후 모드 출력\n    print(f\"현재 거래 모드: {'모의투자' if client.mock else '실전투자'}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```",
            "status": "done",
            "testStrategy": "1. 모드 설정 파일 생성 및 로드 테스트\n2. 모의투자 모드 전환 테스트\n3. 실전투자 모드 전환 테스트 (확인 프롬프트 포함)\n4. 모드 전환 후 API 요청 테스트\n5. 모드별 TR ID 생성 테스트\n6. 안전 설정 적용 테스트\n7. 설정 파일 저장 및 복원 테스트"
          },
          {
            "id": 6,
            "title": "API 응답 로깅 및 모니터링 시스템 구현",
            "description": "API 호출 및 응답을 체계적으로 로깅하고 모니터링하는 시스템 구현으로 디버깅 및 성능 분석 지원",
            "dependencies": [
              "22.3",
              "22.4"
            ],
            "details": "1. API 로깅 및 모니터링 클래스 구현 (utils/api_monitor.py):\n```python\nimport time\nimport json\nimport logging\nfrom datetime import datetime, timedelta\nimport asyncio\nimport os\nfrom pathlib import Path\nimport sqlite3\nfrom collections import deque\n\nclass APIMonitor:\n    def __init__(self, db_path=\"logs/api_monitor.db\", max_memory_logs=1000):\n        self.logger = logging.getLogger(\"APIMonitor\")\n        self.db_path = Path(db_path)\n        self.memory_logs = deque(maxlen=max_memory_logs)  # 최근 로그 메모리 캐시\n        self.daily_stats = {}  # 일일 통계\n        self.endpoint_stats = {}  # 엔드포인트별 통계\n        self.error_counts = {}  # 오류 카운트\n        \n        # 로그 디렉토리 생성\n        os.makedirs(self.db_path.parent, exist_ok=True)\n        \n        # DB 초기화\n        self._init_db()\n        \n        # 통계 로딩\n        self._load_stats()\n    \n    def _init_db(self):\n        \"\"\"SQLite DB 초기화\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # API 요청 로그 테이블\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS api_logs (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            timestamp TEXT,\n            method TEXT,\n            endpoint TEXT,\n            tr_id TEXT,\n            status_code INTEGER,\n            response_time REAL,\n            success INTEGER,\n            error_message TEXT,\n            request_data TEXT,\n            response_data TEXT\n        )\n        \"\"\")\n        \n        # 일일 통계 테이블\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS daily_stats (\n            date TEXT PRIMARY KEY,\n            total_requests INTEGER,\n            successful_requests INTEGER,\n            failed_requests INTEGER,\n            avg_response_time REAL\n        )\n        \"\"\")\n        \n        # 엔드포인트 통계 테이블\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS endpoint_stats (\n            endpoint TEXT PRIMARY KEY,\n            total_requests INTEGER,\n            successful_requests INTEGER,\n            failed_requests INTEGER,\n            avg_response_time REAL,\n            last_used TEXT\n        )\n        \"\"\")\n        \n        conn.commit()\n        conn.close()\n    \n    def _load_stats(self):\n        \"\"\"DB에서 통계 로드\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # 오늘 날짜\n            today = datetime.now().strftime(\"%Y-%m-%d\")\n            \n            # 일일 통계 로드\n            cursor.execute(\"SELECT * FROM daily_stats WHERE date = ?\", (today,))\n            row = cursor.fetchone()\n            if row:\n                self.daily_stats = {\n                    \"total_requests\": row[1],\n                    \"successful_requests\": row[2],\n                    \"failed_requests\": row[3],\n                    \"avg_response_time\": row[4]\n                }\n            else:\n                self.daily_stats = {\n                    \"total_requests\": 0,\n                    \"successful_requests\": 0,\n                    \"failed_requests\": 0,\n                    \"avg_response_time\": 0.0\n                }\n            \n            # 엔드포인트 통계 로드\n            cursor.execute(\"SELECT * FROM endpoint_stats\")\n            rows = cursor.fetchall()\n            for row in rows:\n                self.endpoint_stats[row[0]] = {\n                    \"total_requests\": row[1],\n                    \"successful_requests\": row[2],\n                    \"failed_requests\": row[3],\n                    \"avg_response_time\": row[4],\n                    \"last_used\": row[5]\n                }\n            \n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to load stats: {str(e)}\")\n    \n    def _save_stats(self):\n        \"\"\"통계 DB에 저장\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # 오늘 날짜\n            today = datetime.now().strftime(\"%Y-%m-%d\")\n            \n            # 일일 통계 저장\n            cursor.execute(\"\"\"\n            INSERT OR REPLACE INTO daily_stats \n            (date, total_requests, successful_requests, failed_requests, avg_response_time)\n            VALUES (?, ?, ?, ?, ?)\n            \"\"\", (\n                today,\n                self.daily_stats[\"total_requests\"],\n                self.daily_stats[\"successful_requests\"],\n                self.daily_stats[\"failed_requests\"],\n                self.daily_stats[\"avg_response_time\"]\n            ))\n            \n            # 엔드포인트 통계 저장\n            for endpoint, stats in self.endpoint_stats.items():\n                cursor.execute(\"\"\"\n                INSERT OR REPLACE INTO endpoint_stats\n                (endpoint, total_requests, successful_requests, failed_requests, avg_response_time, last_used)\n                VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\", (\n                    endpoint,\n                    stats[\"total_requests\"],\n                    stats[\"successful_requests\"],\n                    stats[\"failed_requests\"],\n                    stats[\"avg_response_time\"],\n                    stats[\"last_used\"]\n                ))\n            \n            conn.commit()\n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to save stats: {str(e)}\")\n    \n    async def log_request(self, method, endpoint, tr_id=None, request_data=None, response_data=None, \n                         status_code=None, response_time=None, success=True, error_message=None):\n        \"\"\"API 요청 로깅\"\"\"\n        timestamp = datetime.now().isoformat()\n        \n        # 로그 데이터 생성\n        log_data = {\n            \"timestamp\": timestamp,\n            \"method\": method,\n            \"endpoint\": endpoint,\n            \"tr_id\": tr_id,\n            \"status_code\": status_code,\n            \"response_time\": response_time,\n            \"success\": success,\n            \"error_message\": error_message,\n            \"request_data\": json.dumps(request_data) if request_data else None,\n            \"response_data\": json.dumps(response_data) if response_data else None\n        }\n        \n        # 메모리 캐시에 추가\n        self.memory_logs.append(log_data)\n        \n        # 통계 업데이트\n        self._update_stats(log_data)\n        \n        # DB에 로그 저장 (비동기로 처리)\n        asyncio.create_task(self._save_log_to_db(log_data))\n    \n    def _update_stats(self, log_data):\n        \"\"\"통계 업데이트\"\"\"\n        # 일일 통계 업데이트\n        self.daily_stats[\"total_requests\"] += 1\n        if log_data[\"success\"]:\n            self.daily_stats[\"successful_requests\"] += 1\n        else:\n            self.daily_stats[\"failed_requests\"] += 1\n        \n        # 평균 응답 시간 업데이트\n        if log_data[\"response_time\"] is not None:\n            current_avg = self.daily_stats[\"avg_response_time\"]\n            current_total = self.daily_stats[\"total_requests\"]\n            self.daily_stats[\"avg_response_time\"] = (\n                (current_avg * (current_total - 1) + log_data[\"response_time\"]) / current_total\n            )\n        \n        # 엔드포인트 통계 업데이트\n        endpoint = log_data[\"endpoint\"]\n        if endpoint not in self.endpoint_stats:\n            self.endpoint_stats[endpoint] = {\n                \"total_requests\": 0,\n                \"successful_requests\": 0,\n                \"failed_requests\": 0,\n                \"avg_response_time\": 0.0,\n                \"last_used\": log_data[\"timestamp\"]\n            }\n        \n        self.endpoint_stats[endpoint][\"total_requests\"] += 1\n        if log_data[\"success\"]:\n            self.endpoint_stats[endpoint][\"successful_requests\"] += 1\n        else:\n            self.endpoint_stats[endpoint][\"failed_requests\"] += 1\n        \n        # 평균 응답 시간 업데이트\n        if log_data[\"response_time\"] is not None:\n            current_avg = self.endpoint_stats[endpoint][\"avg_response_time\"]\n            current_total = self.endpoint_stats[endpoint][\"total_requests\"]\n            self.endpoint_stats[endpoint][\"avg_response_time\"] = (\n                (current_avg * (current_total - 1) + log_data[\"response_time\"]) / current_total\n            )\n        \n        self.endpoint_stats[endpoint][\"last_used\"] = log_data[\"timestamp\"]\n        \n        # 오류 카운트 업데이트\n        if not log_data[\"success\"] and log_data[\"error_message\"]:\n            error_key = log_data[\"error_message\"][:100]  # 오류 메시지 앞부분만 키로 사용\n            self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1\n        \n        # 주기적으로 통계 저장\n        if self.daily_stats[\"total_requests\"] % 100 == 0:\n            self._save_stats()\n    \n    async def _save_log_to_db(self, log_data):\n        \"\"\"로그를 DB에 저장\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute(\"\"\"\n            INSERT INTO api_logs \n            (timestamp, method, endpoint, tr_id, status_code, response_time, success, error_message, request_data, response_data)\n            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            \"\"\", (\n                log_data[\"timestamp\"],\n                log_data[\"method\"],\n                log_data[\"endpoint\"],\n                log_data[\"tr_id\"],\n                log_data[\"status_code\"],\n                log_data[\"response_time\"],\n                1 if log_data[\"success\"] else 0,\n                log_data[\"error_message\"],\n                log_data[\"request_data\"],\n                log_data[\"response_data\"]\n            ))\n            \n            conn.commit()\n            conn.close()\n        except Exception as e:\n            self.logger.error(f\"Failed to save log to DB: {str(e)}\")\n    \n    def get_recent_logs(self, limit=50):\n        \"\"\"최근 로그 조회\"\"\"\n        return list(self.memory_logs)[-limit:]\n    \n    def get_daily_stats(self):\n        \"\"\"일일 통계 조회\"\"\"\n        return self.daily_stats\n    \n    def get_endpoint_stats(self):\n        \"\"\"엔드포인트별 통계 조회\"\"\"\n        return self.endpoint_stats\n    \n    def get_error_stats(self):\n        \"\"\"오류 통계 조회\"\"\"\n        return self.error_counts\n    \n    def get_logs_by_endpoint(self, endpoint, limit=50):\n        \"\"\"특정 엔드포인트의 로그 조회\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE endpoint = ? \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (endpoint, limit))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n    \n    def get_logs_by_timerange(self, start_time, end_time=None, limit=100):\n        \"\"\"특정 시간 범위의 로그 조회\"\"\"\n        if end_time is None:\n            end_time = datetime.now().isoformat()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE timestamp BETWEEN ? AND ? \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (start_time, end_time, limit))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n    \n    def get_error_logs(self, limit=50):\n        \"\"\"오류 로그 조회\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT * FROM api_logs \n        WHERE success = 0 \n        ORDER BY timestamp DESC \n        LIMIT ?\n        \"\"\", (limit,))\n        \n        rows = cursor.fetchall()\n        conn.close()\n        \n        return rows\n```\n\n2. KISClient 클래스에 APIMonitor 통합:\n```python\n# collectors/kis_client.py 수정\n\nfrom utils.api_monitor import APIMonitor\nimport time\n\nclass KISClient:\n    def __init__(self, api_key, api_secret, account_no, mock=None):\n        # 기존 초기화 코드...\n        \n        # API 모니터 초기화\n        self.api_monitor = APIMonitor()\n    \n    async def request(self, method, endpoint, tr_id=None, params=None, data=None, headers=None, retry_count=3):\n        \"\"\"API 요청 공통 로직 (재시도, 에러 처리, 모니터링 포함)\"\"\"\n        await self._manage_rate_limit()\n        \n        # 토큰 확인 및 갱신\n        await self.auth.ensure_token()\n        \n        # 기본 헤더 설정\n        request_headers = self.auth.get_auth_headers()\n        if tr_id:\n            request_headers[\"tr_id\"] = tr_id\n        if headers:\n            request_headers.update(headers)\n        \n        url = f\"{self.base_url}{endpoint}\"\n        start_time = time.time()\n        response_data = None\n        status_code = None\n        success = False\n        error_message = None\n        \n        for attempt in range(retry_count):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    request_kwargs = {\n                        \"headers\": request_headers\n                    }\n                    \n                    if params:\n                        request_kwargs[\"params\"] = params\n                    \n                    if data:\n                        request_kwargs[\"json\"] = data\n                    \n                    self.logger.debug(f\"Requesting {method} {url}\")\n                    async with session.request(method, url, **request_kwargs) as response:\n                        response_text = await response.text()\n                        status_code = response.status\n                        \n                        # 응답 로깅\n                        self.logger.debug(f\"Response {response.status}: {response_text[:200]}...\")\n                        \n                        if response.status == 200:\n                            try:\n                                response_data = await response.json()\n                                success = True\n                                break  # 성공하면 루프 종료\n                            except json.JSONDecodeError:\n                                response_data = response_text\n                                success = True\n                                break  # 성공하면 루프 종료\n                        elif response.status == 401:  # 인증 오류\n                            # 토큰 재발급 시도\n                            error_message = \"Authentication error\"\n                            self.logger.warning(\"Authentication error, refreshing token\")\n                            await self.auth.issue_access_token()\n                            if attempt < retry_count - 1:  # 마지막 시도가 아니면 재시도\n                                continue\n                        \n                        # 기타 오류\n                        error_message = f\"API request failed: {response.status} - {response_text}\"\n                        self.logger.error(error_message)\n                        response_data = response_text\n            except aiohttp.ClientError as e:\n                error_message = str(e)\n                if attempt < retry_count - 1:  # 마지막 시도가 아니면 재시도\n                    wait_time = 2 ** attempt  # 지수 백오프\n                    self.logger.warning(f\"Request failed: {error_message}. Retrying in {wait_time}s\")\n                    await asyncio.sleep(wait_time)\n                else:\n                    self.logger.error(f\"Request failed after {retry_count} attempts: {error_message}\")\n        \n        # 응답 시간 계산\n        response_time = time.time() - start_time\n        \n        # API 모니터에 로깅\n        await self.api_monitor.log_request(\n            method=method,\n            endpoint=endpoint,\n            tr_id=tr_id,\n            request_data=data if data else params,\n            response_data=response_data,\n            status_code=status_code,\n            response_time=response_time,\n            success=success,\n            error_message=error_message\n        )\n        \n        if not success:\n            raise Exception(error_message or f\"Request failed after {retry_count} attempts\")\n        \n        return response_data\n```\n\n3. API 모니터링 대시보드 스크립트 (examples/api_monitor_dashboard.py):\n```python\nimport asyncio\nimport sys\nimport os\nfrom datetime import datetime, timedelta\n\n# 프로젝트 루트 디렉토리를 Python 경로에 추가\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom utils.api_monitor import APIMonitor\n\nasync def show_dashboard():\n    monitor = APIMonitor()\n    \n    # 일일 통계 출력\n    daily_stats = monitor.get_daily_stats()\n    print(\"\\n===== 일일 API 통계 =====\")\n    print(f\"총 요청 수: {daily_stats['total_requests']}\")\n    print(f\"성공 요청 수: {daily_stats['successful_requests']}\")\n    print(f\"실패 요청 수: {daily_stats['failed_requests']}\")\n    print(f\"평균 응답 시간: {daily_stats['avg_response_time']:.4f}초\")\n    \n    # 엔드포인트 통계 출력\n    endpoint_stats = monitor.get_endpoint_stats()\n    print(\"\\n===== 엔드포인트별 통계 =====\")\n    for endpoint, stats in endpoint_stats.items():\n        print(f\"\\n엔드포인트: {endpoint}\")\n        print(f\"  총 요청 수: {stats['total_requests']}\")\n        print(f\"  성공률: {stats['successful_requests'] / stats['total_requests'] * 100:.1f}%\")\n        print(f\"  평균 응답 시간: {stats['avg_response_time']:.4f}초\")\n        print(f\"  마지막 사용: {stats['last_used']}\")\n    \n    # 오류 통계 출력\n    error_stats = monitor.get_error_stats()\n    if error_stats:\n        print(\"\\n===== 오류 통계 =====\")\n        for error, count in sorted(error_stats.items(), key=lambda x: x[1], reverse=True):\n            print(f\"{error}: {count}회\")\n    \n    # 최근 로그 출력\n    recent_logs = monitor.get_recent_logs(10)\n    print(\"\\n===== 최근 API 요청 로그 =====\")\n    for log in recent_logs:\n        status = \"성공\" if log[\"success\"] else \"실패\"\n        print(f\"{log['timestamp']} - {log['method']} {log['endpoint']} - {status} ({log['response_time']:.4f}초)\")\n    \n    # 최근 오류 로그 출력\n    error_logs = monitor.get_error_logs(5)\n    if error_logs:\n        print(\"\\n===== 최근 오류 로그 =====\")\n        for log in error_logs:\n            print(f\"{log[1]} - {log[2]} {log[3]} - {log[7]}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(show_dashboard())\n```",
            "status": "done",
            "testStrategy": "1. API 모니터 초기화 및 DB 생성 테스트\n2. API 요청 로깅 테스트\n3. 통계 업데이트 및 저장 테스트\n4. 로그 조회 기능 테스트\n5. 일일 통계 및 엔드포인트 통계 테스트\n6. 오류 로그 및 통계 테스트\n7. 대시보드 출력 테스트\n8. 장기간 실행 시 성능 및 안정성 테스트\n9. 대용량 로그 처리 성능 테스트"
          }
        ]
      },
      {
        "id": 23,
        "title": "실시간 데이터 수집 WebSocket 클라이언트",
        "description": "한국투자증권 WebSocket API를 활용한 실시간 시세, 호가, 체결 데이터 수집 시스템 구현 및 다중 소스 데이터 통합",
        "status": "done",
        "dependencies": [
          21,
          22
        ],
        "priority": "high",
        "details": "1. 이벤트 기반 아키텍처로 독립적인 데이터 수집기 엔진 구현:\n```python\nclass DataCollector:\n    def __init__(self, redis_manager, event_manager):\n        self.redis_manager = redis_manager\n        self.event_manager = event_manager\n        self.adapters = {}\n        self.normalizer = DataNormalizer()\n        self.connection_manager = ConnectionManager()\n        self.subscribed_symbols = set()\n        self.running = False\n        \n    async def initialize(self):\n        # 어댑터 초기화 및 연결 관리자 설정\n        self.adapters['kis'] = KISDataAdapter()\n        self.adapters['naver'] = NaverDataAdapter()\n        self.adapters['yahoo'] = YahooDataAdapter()\n        await self.connection_manager.initialize(self.adapters)\n        \n    async def subscribe(self, symbol, data_types=None):\n        # 다중 소스 종목 구독 로직 (ticker, orderbook, trade)\n        # 각 어댑터에 구독 요청 전달\n        \n    async def unsubscribe(self, symbol, data_types=None):\n        # 구독 해제 로직\n        \n    async def _process_data(self, source, data):\n        # 데이터 정규화 및 처리\n        normalized_data = self.normalizer.normalize(source, data)\n        \n        # Redis Rolling 업데이트 (종목별 최근 200개 캔들)\n        await self.redis_manager.update_market_data(normalized_data)\n        \n        # market_data_received 이벤트 발행\n        await self.event_manager.publish('market_data_received', normalized_data)\n        \n    async def start(self, symbols=None):\n        # 수집기 시작 로직\n        \n    async def stop(self):\n        # 수집기 중지 로직\n```\n\n2. 주요 컴포넌트 구현:\n```python\nclass KISDataAdapter:\n    # 한국투자증권 WebSocket/REST API 어댑터\n    \nclass NaverDataAdapter:\n    # 네이버 금융 데이터 어댑터\n    \nclass YahooDataAdapter:\n    # 야후 파이낸스 데이터 어댑터\n    \nclass DataNormalizer:\n    # 다양한 소스의 데이터를 표준 형식으로 정규화\n    \nclass ConnectionManager:\n    # 연결 관리 및 자동 재연결 로직\n```\n\n3. 다양한 실시간 데이터 타입 처리:\n   - 현재가/체결 (ticker)\n   - 호가 (orderbook)\n   - 체결 내역 (trade)\n\n4. 데이터 품질 관리:\n   - 데이터 유효성 검증 및 이상치 탐지\n   - 소스 간 데이터 일관성 검증\n   - 누락 데이터 처리 전략\n\n5. Redis 데이터 관리:\n   - 종목별 최근 200개 캔들 Rolling 업데이트\n   - 실시간 데이터 저장 및 발행\n   - 캐싱 전략 최적화\n\n6. 장애 처리 및 복원력:\n   - 자동 재연결 메커니즘 구현\n   - 데이터 소스 장애 시 대체 소스 활용\n   - 장애 로깅 및 알림\n\n7. 성능 최적화:\n   - 비동기 처리\n   - 배치 처리\n   - 메모리 사용량 최적화\n\n8. 이벤트 발행:\n   - market_data_received 이벤트 발행\n   - 이벤트 기반 아키텍처 통합",
        "testStrategy": "1. 다중 데이터 소스 연결 및 인증 테스트\n2. 다양한 종목 구독/해제 테스트\n3. 실시간 데이터 수신 및 파싱 정확성 테스트\n4. 데이터 정규화 및 품질 검증 테스트\n5. Redis Rolling 업데이트 테스트 (200개 캔들 제한)\n6. market_data_received 이벤트 발행 및 수신 테스트\n7. 네트워크 장애 시뮬레이션 및 재연결 테스트\n8. 데이터 소스 장애 시 대체 소스 활용 테스트\n9. 장시간 실행 안정성 테스트\n10. 메모리 사용량 모니터링\n11. 다중 종목 동시 구독 성능 테스트\n12. 소스 간 데이터 일관성 검증 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "DataCollector 엔진 클래스 구현",
            "description": "이벤트 기반 아키텍처를 지원하는 메인 데이터 수집기 엔진 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "KISDataAdapter 구현",
            "description": "한국투자증권 WebSocket/REST API 연동 어댑터 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "NaverDataAdapter 및 YahooDataAdapter 구현",
            "description": "보조 데이터 소스로 네이버 금융과 야후 파이낸스 어댑터 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "DataNormalizer 구현",
            "description": "다양한 소스의 데이터를 표준 형식으로 정규화하는 컴포넌트 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "ConnectionManager 구현",
            "description": "연결 관리 및 자동 재연결 로직을 담당하는 컴포넌트 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Redis Rolling 업데이트 구현",
            "description": "종목별 최근 200개 캔들만 유지하는 Rolling 업데이트 메커니즘 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "market_data_received 이벤트 발행 구현",
            "description": "데이터 수신 및 처리 후 이벤트를 발행하는 로직 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "데이터 품질 검증 및 이상치 탐지 구현",
            "description": "수신된 데이터의 유효성 검증 및 이상치 탐지 로직 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 24,
        "title": "과거 데이터 수집 및 관리 시스템",
        "description": "한국투자증권 API와 보조 데이터 소스를 활용한 과거 주가 데이터 수집, 정규화 및 저장 시스템 구현",
        "status": "pending",
        "dependencies": [
          20,
          22
        ],
        "priority": "low",
        "details": "1. 과거 데이터 수집기 구현 (collectors/historical_collector.py):\n```python\nclass HistoricalCollector:\n    def __init__(self, kis_client, db_session):\n        self.kis_client = kis_client\n        self.db_session = db_session\n        self.backup_sources = {\n            'naver': NaverFinanceCollector(),\n            'yfinance': YFinanceCollector()\n        }\n        \n    async def collect_daily_data(self, symbol, start_date, end_date=None):\n        # 일봉 데이터 수집 로직\n        \n    async def collect_minute_data(self, symbol, interval=1, days=5):\n        # 분봉 데이터 수집 로직\n        \n    async def collect_multiple_symbols(self, symbols, interval='1d', start_date=None):\n        # 다중 종목 수집 로직 (병렬 처리)\n        \n    async def _normalize_and_save(self, data, symbol, interval_type):\n        # 데이터 정규화 및 저장 로직\n        \n    async def backfill_missing_data(self, symbol, interval_type, start_date, end_date):\n        # 누락 데이터 보완 로직 (보조 소스 활용)\n```\n2. 다양한 시간 프레임 지원:\n   - 1분봉, 5분봉, 일봉\n3. 보조 데이터 소스 구현:\n   - 네이버 금융 크롤러\n   - yfinance API 클라이언트\n4. 데이터 정규화 및 검증 로직:\n   - 이상치 탐지 및 처리\n   - 누락 데이터 보완\n5. 효율적인 데이터 저장 (배치 삽입)\n6. 주기적 데이터 수집 스케줄러 구현\n7. 글로벌 지수 데이터 수집 (yfinance 활용)\n8. 기업 정보 및 재무제표 데이터 수집 (DART API 활용)\n9. 데이터 품질 모니터링 시스템\n\n참고: 이 시스템은 백테스팅을 위한 것으로, 실제 매매 시스템 구축 후 나중에 개발할 예정입니다. 현재는 실시간 데이터만으로도 충분히 매매가 가능합니다.",
        "testStrategy": "1. 다양한 시간 프레임 데이터 수집 테스트\n2. 데이터 정규화 및 저장 정확성 테스트\n3. 보조 데이터 소스 활용 테스트\n4. 이상치 탐지 및 처리 테스트\n5. 누락 데이터 보완 테스트\n6. 대량 데이터 수집 성능 테스트\n7. 스케줄러 작동 테스트\n8. 데이터베이스 저장 효율성 테스트\n9. 장기간 데이터 수집 안정성 테스트",
        "subtasks": []
      },
      {
        "id": 25,
        "title": "전략 엔진 플러그인 아키텍처 구현",
        "description": "다양한 트레이딩 전략을 쉽게 추가하고 교체할 수 있는 이벤트 기반 플러그인 아키텍처 설계 및 구현",
        "status": "done",
        "dependencies": [
          19,
          20
        ],
        "priority": "high",
        "details": "1. BaseStrategy 추상 클래스 (strategies/base.py):\n```python\nfrom abc import ABC, abstractmethod\n\nclass BaseStrategy(ABC):\n    def __init__(self, params=None):\n        self.params = params or {}\n        self.name = self.__class__.__name__\n    \n    @abstractmethod\n    async def analyze(self, market_data):\n        \"\"\"시장 데이터를 분석하여 매매 신호 생성\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_parameters(self):\n        \"\"\"전략 파라미터 반환\"\"\"\n        return self.params\n    \n    @abstractmethod\n    def set_parameters(self, params):\n        \"\"\"전략 파라미터 설정\"\"\"\n        self.params = params\n    \n    @abstractmethod\n    def get_description(self):\n        \"\"\"전략 설명 반환\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_required_indicators(self):\n        \"\"\"전략에 필요한 기술 지표 목록 반환\"\"\"\n        pass\n```\n\n2. StrategyLoader 구현 (strategies/loader.py):\n```python\nimport importlib\nimport inspect\nimport os\nfrom typing import Dict, Type, List\nfrom .base import BaseStrategy\n\nclass StrategyLoader:\n    def __init__(self, strategies_dir=\"strategies\"):\n        self.strategies_dir = strategies_dir\n        self.available_strategies: Dict[str, Type[BaseStrategy]] = {}\n        self.loaded_strategies: Dict[str, BaseStrategy] = {}\n    \n    def discover_strategies(self) -> List[str]:\n        \"\"\"전략 디렉토리에서 사용 가능한 전략 클래스 탐색\"\"\"\n        # 구현 로직\n        \n    def load_strategy(self, strategy_name: str, params=None) -> BaseStrategy:\n        \"\"\"전략 이름으로 전략 인스턴스 로드\"\"\"\n        # 구현 로직\n        \n    def unload_strategy(self, strategy_name: str) -> bool:\n        \"\"\"로드된 전략 언로드\"\"\"\n        # 구현 로직\n```\n\n3. StrategyEngine 구현 (strategies/engine.py):\n```python\nfrom typing import Dict, List\nfrom .loader import StrategyLoader\nfrom .base import BaseStrategy\nfrom ..utils.redis_manager import RedisManager\nfrom ..utils.event_bus import EventBus\n\nclass StrategyEngine:\n    def __init__(self, redis_manager: RedisManager, event_bus: EventBus):\n        self.redis = redis_manager\n        self.event_bus = event_bus\n        self.strategy_loader = StrategyLoader()\n        self.active_strategies: Dict[str, BaseStrategy] = {}\n        self.performance_tracker = StrategyPerformanceTracker(redis_manager)\n        \n        # 이벤트 구독 설정\n        self.event_bus.subscribe(\"market_data_received\", self.on_market_data)\n    \n    async def on_market_data(self, data):\n        \"\"\"시장 데이터 수신 시 모든 활성 전략 실행\"\"\"\n        symbol = data.get(\"symbol\")\n        \n        # Redis에서 필요한 기술 지표 데이터 조회\n        indicators = await self.fetch_indicators(symbol)\n        \n        # 각 활성 전략 실행\n        for strategy_name, strategy in self.active_strategies.items():\n            signals = await strategy.analyze({**data, \"indicators\": indicators})\n            if signals:\n                # 매매 신호 발행\n                await self.publish_trading_signals(strategy_name, symbol, signals)\n                # 성과 추적\n                await self.performance_tracker.record_signal(strategy_name, symbol, signals)\n    \n    async def fetch_indicators(self, symbol):\n        \"\"\"Redis에서 기술 지표 데이터 조회\"\"\"\n        # 구현 로직\n        \n    async def publish_trading_signals(self, strategy_name, symbol, signals):\n        \"\"\"매매 신호 이벤트 발행\"\"\"\n        await self.event_bus.publish(\"trading_signal\", {\n            \"strategy\": strategy_name,\n            \"symbol\": symbol,\n            \"signals\": signals,\n            \"timestamp\": # 현재 시간\n        })\n    \n    def activate_strategy(self, strategy_name, params=None):\n        \"\"\"전략 활성화\"\"\"\n        # 구현 로직\n        \n    def deactivate_strategy(self, strategy_name):\n        \"\"\"전략 비활성화\"\"\"\n        # 구현 로직\n```\n\n4. 전략 성과 추적기 (strategies/performance.py):\n```python\nclass StrategyPerformanceTracker:\n    def __init__(self, redis_manager):\n        self.redis = redis_manager\n    \n    async def record_signal(self, strategy_name, symbol, signals):\n        \"\"\"전략 신호 기록\"\"\"\n        # 구현 로직\n        \n    async def get_strategy_performance(self, strategy_name, timeframe=\"1d\"):\n        \"\"\"전략 성과 조회\"\"\"\n        # 구현 로직\n```\n\n5. 샘플 전략 구현:\n\n```python\n# strategies/moving_average.py\nfrom .base import BaseStrategy\n\nclass MovingAverageCrossover(BaseStrategy):\n    def __init__(self, params=None):\n        default_params = {\n            \"short_period\": 10,\n            \"long_period\": 30\n        }\n        super().__init__(params or default_params)\n    \n    async def analyze(self, market_data):\n        indicators = market_data.get(\"indicators\", {})\n        symbol = market_data.get(\"symbol\")\n        \n        # 필요한 이동평균 데이터 확인\n        ma_short = indicators.get(f\"ma_{self.params['short_period']}\")\n        ma_long = indicators.get(f\"ma_{self.params['long_period']}\")\n        \n        if ma_short is None or ma_long is None:\n            return None\n        \n        # 골든 크로스 (단기 > 장기)\n        if ma_short > ma_long and indicators.get(\"prev_ma_short\", 0) <= indicators.get(\"prev_ma_long\", 0):\n            return {\"action\": \"buy\", \"reason\": \"golden_cross\"}\n        \n        # 데드 크로스 (단기 < 장기)\n        if ma_short < ma_long and indicators.get(\"prev_ma_short\", 0) >= indicators.get(\"prev_ma_long\", 0):\n            return {\"action\": \"sell\", \"reason\": \"dead_cross\"}\n        \n        return None\n    \n    def get_parameters(self):\n        return self.params\n    \n    def set_parameters(self, params):\n        self.params.update(params)\n    \n    def get_description(self):\n        return f\"이동평균 교차 전략 (단기: {self.params['short_period']}, 장기: {self.params['long_period']})\"\n    \n    def get_required_indicators(self):\n        return [f\"ma_{self.params['short_period']}\", f\"ma_{self.params['long_period']}\", \n                \"prev_ma_short\", \"prev_ma_long\"]\n```",
        "testStrategy": "1. 전략 인터페이스 구현 테스트\n2. 전략 로드/언로드 테스트\n3. 이벤트 구독 및 발행 테스트\n4. Redis에서 기술지표 데이터 조회 테스트\n5. 샘플 전략 신호 생성 정확성 테스트\n6. 파라미터 설정/조회 테스트\n7. 런타임 전략 교체 테스트\n8. 전략 성과 추적 테스트\n9. 다양한 시장 상황에서의 전략 동작 테스트\n10. 이벤트 기반 아키텍처 통합 테스트\n11. 여러 전략 동시 실행 테스트\n12. 전략 설정 파일 로드/저장 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "BaseStrategy 추상 클래스 구현",
            "description": "전략 인터페이스 정의 및 기본 메서드 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "StrategyLoader 구현",
            "description": "동적으로 전략 클래스를 발견하고 로드/언로드하는 기능 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "StrategyEngine 구현",
            "description": "이벤트 구독 및 전략 실행 엔진 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "전략 성과 추적기 구현",
            "description": "전략별 성과를 추적하고 기록하는 시스템 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "샘플 전략 구현",
            "description": "이동평균 교차, RSI, 볼린저 밴드 등 샘플 전략 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "이벤트 기반 통합 테스트",
            "description": "market_data_received 이벤트부터 trading_signal 발행까지 전체 흐름 테스트",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 26,
        "title": "기술적 분석 지표 라이브러리 구현",
        "description": "트레이딩 전략에 활용할 다양한 기술적 분석 지표 계산 라이브러리 구현 및 독립적인 기술 분석 엔진으로 구성",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "high",
        "details": "1. TechnicalAnalyzer 엔진 클래스 구현 (analysis/technical_analyzer.py):\n```python\nclass TechnicalAnalyzer:\n    def __init__(self, redis_client):\n        self.redis_client = redis_client\n        self.indicator_calculator = IndicatorCalculator()\n        self.event_bus = EventBus()\n        \n    def start(self):\n        \"\"\"이벤트 구독 및 분석 엔진 시작\"\"\"\n        self.event_bus.subscribe('market_data_received', self.process_market_data)\n        \n    def process_market_data(self, data):\n        \"\"\"시장 데이터 수신 시 지표 계산 및 이벤트 발행\"\"\"\n        symbol = data['symbol']\n        timeframe = data['timeframe']\n        \n        # Redis에서 캔들 데이터 조회\n        candles = self.get_candles_from_redis(symbol, timeframe)\n        \n        # 지표 계산\n        indicators = self.calculate_indicators(symbol, candles)\n        \n        # Redis에 지표 캐싱\n        self.cache_indicators(symbol, indicators)\n        \n        # 지표 업데이트 이벤트 발행\n        self.event_bus.publish('indicators_updated', {\n            'symbol': symbol,\n            'timeframe': timeframe,\n            'indicators': indicators\n        })\n```\n\n2. IndicatorCalculator 클래스 구현 (analysis/indicators.py):\n```python\nclass IndicatorCalculator:\n    def __init__(self):\n        self.ta_lib_available = self._check_talib()\n    \n    def _check_talib(self):\n        \"\"\"TA-Lib 사용 가능 여부 확인\"\"\"\n        try:\n            import talib\n            return True\n        except ImportError:\n            return False\n    \n    def sma(self, data, period=20):\n        \"\"\"단순 이동평균\"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.SMA(data, timeperiod=period)\n        return data.rolling(window=period).mean()\n    \n    def ema(self, data, period=20):\n        \"\"\"지수 이동평균\"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.EMA(data, timeperiod=period)\n        return data.ewm(span=period, adjust=False).mean()\n    \n    def bollinger_bands(self, data, period=20, std_dev=2):\n        \"\"\"볼린저 밴드\"\"\"\n        if self.ta_lib_available:\n            import talib\n            upper, middle, lower = talib.BBANDS(data, timeperiod=period, nbdevup=std_dev, nbdevdn=std_dev)\n            return upper, middle, lower\n        \n        sma = self.sma(data, period)\n        std = data.rolling(window=period).std()\n        upper_band = sma + (std * std_dev)\n        lower_band = sma - (std * std_dev)\n        return upper_band, sma, lower_band\n        \n    def rsi(self, data, period=14):\n        \"\"\"상대강도지수(RSI)\"\"\"\n        if self.ta_lib_available:\n            import talib\n            return talib.RSI(data, timeperiod=period)\n        # 순수 Python 구현\n        delta = data.diff()\n        gain = delta.where(delta > 0, 0)\n        loss = -delta.where(delta < 0, 0)\n        avg_gain = gain.rolling(window=period).mean()\n        avg_loss = loss.rolling(window=period).mean()\n        rs = avg_gain / avg_loss\n        return 100 - (100 / (1 + rs))\n    \n    def macd(self, data, fast_period=12, slow_period=26, signal_period=9):\n        \"\"\"MACD(이동평균수렴확산지수)\"\"\"\n        if self.ta_lib_available:\n            import talib\n            macd, signal, hist = talib.MACD(data, fastperiod=fast_period, slowperiod=slow_period, signalperiod=signal_period)\n            return macd, signal, hist\n        \n        ema_fast = self.ema(data, fast_period)\n        ema_slow = self.ema(data, slow_period)\n        macd_line = ema_fast - ema_slow\n        signal_line = self.ema(macd_line, signal_period)\n        histogram = macd_line - signal_line\n        return macd_line, signal_line, histogram\n```\n\n3. Redis 지표 캐싱 시스템 구현 (analysis/cache_manager.py):\n```python\nclass IndicatorCacheManager:\n    def __init__(self, redis_client):\n        self.redis = redis_client\n        self.expiry = 3600  # 1시간 캐시 유효기간\n    \n    def get_cached_indicator(self, symbol, indicator_name, params=None):\n        \"\"\"Redis에서 캐시된 지표 조회\"\"\"\n        cache_key = self._build_cache_key(symbol, indicator_name, params)\n        cached_data = self.redis.hget(f\"indicators:{symbol}\", cache_key)\n        if cached_data:\n            return json.loads(cached_data)\n        return None\n    \n    def cache_indicator(self, symbol, indicator_name, data, params=None):\n        \"\"\"지표 계산 결과 Redis에 캐싱\"\"\"\n        cache_key = self._build_cache_key(symbol, indicator_name, params)\n        self.redis.hset(f\"indicators:{symbol}\", cache_key, json.dumps(data))\n        self.redis.expire(f\"indicators:{symbol}\", self.expiry)\n    \n    def _build_cache_key(self, symbol, indicator_name, params=None):\n        \"\"\"캐시 키 생성\"\"\"\n        if not params:\n            return f\"{indicator_name}\"\n        param_str = \"_\".join([f\"{k}:{v}\" for k, v in params.items()])\n        return f\"{indicator_name}_{param_str}\"\n    \n    def invalidate_cache(self, symbol):\n        \"\"\"심볼에 대한 모든 캐시 무효화\"\"\"\n        self.redis.delete(f\"indicators:{symbol}\")\n```\n\n4. 이벤트 기반 아키텍처 구현 (utils/event_bus.py):\n```python\nclass EventBus:\n    def __init__(self, redis_client=None):\n        self.redis = redis_client\n        self.local_subscribers = {}\n    \n    def publish(self, event_name, data):\n        \"\"\"이벤트 발행\"\"\"\n        message = json.dumps({\n            'event': event_name,\n            'data': data,\n            'timestamp': time.time()\n        })\n        \n        # Redis Pub/Sub 사용 (분산 환경)\n        if self.redis:\n            self.redis.publish(event_name, message)\n        \n        # 로컬 이벤트 처리 (단일 프로세스 환경)\n        if event_name in self.local_subscribers:\n            for callback in self.local_subscribers[event_name]:\n                callback(data)\n    \n    def subscribe(self, event_name, callback):\n        \"\"\"이벤트 구독\"\"\"\n        if event_name not in self.local_subscribers:\n            self.local_subscribers[event_name] = []\n        self.local_subscribers[event_name].append(callback)\n        \n        # Redis Pub/Sub 구독 설정\n        if self.redis:\n            thread = threading.Thread(target=self._listen_for_redis_events, args=(event_name,))\n            thread.daemon = True\n            thread.start()\n    \n    def _listen_for_redis_events(self, event_name):\n        \"\"\"Redis 이벤트 리스너\"\"\"\n        pubsub = self.redis.pubsub()\n        pubsub.subscribe(event_name)\n        \n        for message in pubsub.listen():\n            if message['type'] == 'message':\n                data = json.loads(message['data'])\n                if event_name in self.local_subscribers:\n                    for callback in self.local_subscribers[event_name]:\n                        callback(data['data'])\n```\n\n5. 커스텀 지표 추가 지원 (analysis/custom_indicators.py):\n```python\nclass CustomIndicatorRegistry:\n    def __init__(self):\n        self.indicators = {}\n    \n    def register(self, name, calculation_func, description=\"\"):\n        \"\"\"커스텀 지표 등록\"\"\"\n        self.indicators[name] = {\n            'function': calculation_func,\n            'description': description\n        }\n        return True\n    \n    def get_indicator(self, name):\n        \"\"\"등록된 커스텀 지표 조회\"\"\"\n        return self.indicators.get(name, {}).get('function')\n    \n    def calculate(self, name, data, **params):\n        \"\"\"커스텀 지표 계산\"\"\"\n        indicator_func = self.get_indicator(name)\n        if not indicator_func:\n            raise ValueError(f\"Unknown indicator: {name}\")\n        return indicator_func(data, **params)\n    \n    def list_indicators(self):\n        \"\"\"등록된 모든 커스텀 지표 목록 반환\"\"\"\n        return {\n            name: info['description'] \n            for name, info in self.indicators.items()\n        }\n```\n\n6. 지표 계산 성능 최적화 (analysis/performance.py):\n```python\nclass IndicatorPerformanceOptimizer:\n    def __init__(self, cache_manager):\n        self.cache_manager = cache_manager\n        self.calculation_stats = {}\n    \n    def optimize_calculation(self, symbol, indicator_name, data, calculation_func, params=None):\n        \"\"\"지표 계산 최적화 (캐싱 및 성능 측정)\"\"\"\n        # 캐시 확인\n        cached_result = self.cache_manager.get_cached_indicator(symbol, indicator_name, params)\n        if cached_result is not None:\n            return cached_result\n        \n        # 성능 측정 및 계산\n        start_time = time.time()\n        result = calculation_func(data, **params) if params else calculation_func(data)\n        calc_time = time.time() - start_time\n        \n        # 성능 통계 업데이트\n        if indicator_name not in self.calculation_stats:\n            self.calculation_stats[indicator_name] = []\n        self.calculation_stats[indicator_name].append(calc_time)\n        \n        # 결과 캐싱\n        self.cache_manager.cache_indicator(symbol, indicator_name, result, params)\n        \n        return result\n    \n    def get_performance_stats(self):\n        \"\"\"지표별 계산 성능 통계 반환\"\"\"\n        stats = {}\n        for indicator, times in self.calculation_stats.items():\n            stats[indicator] = {\n                'avg_time': sum(times) / len(times),\n                'min_time': min(times),\n                'max_time': max(times),\n                'calls': len(times)\n            }\n        return stats\n```",
        "testStrategy": "1. 이벤트 기반 아키텍처 테스트:\n   - market_data_received 이벤트 발행 및 구독 테스트\n   - indicators_updated 이벤트 발행 및 구독 테스트\n   - 이벤트 처리 흐름 검증\n\n2. 지표 계산 정확성 테스트:\n   - 각 지표 계산 결과 검증\n   - TA-Lib 결과와 비교 검증\n   - 커스텀 지표 계산 검증\n\n3. Redis 캐싱 시스템 테스트:\n   - 지표 캐싱 및 조회 테스트\n   - 캐시 만료 정책 테스트\n   - 캐시 무효화 테스트\n\n4. 성능 테스트:\n   - 대용량 데이터 처리 성능 테스트\n   - 실시간 업데이트 성능 테스트\n   - 캐싱 메커니즘 효율성 테스트\n   - 메모리 사용량 최적화 테스트\n\n5. 통합 테스트:\n   - 전체 이벤트 흐름 테스트 (market_data_received → 지표 계산 → Redis 캐싱 → indicators_updated 발행)\n   - 다양한 시장 상황에서의 지표 동작 테스트\n   - 여러 심볼 동시 처리 테스트\n\n6. 커스텀 지표 프레임워크 테스트:\n   - 커스텀 지표 등록 및 계산 테스트\n   - 커스텀 지표 성능 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "TechnicalAnalyzer 엔진 클래스 구현",
            "description": "이벤트 기반 기술적 분석 엔진 구현 (market_data_received 이벤트 구독, indicators_updated 이벤트 발행)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "IndicatorCalculator 클래스 구현",
            "description": "TA-Lib 래퍼 및 순수 Python 구현을 포함한 주요 기술적 지표 계산 클래스 구현 (RSI, MACD, 볼린저밴드, 이동평균 등)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Redis 지표 캐싱 시스템 구현",
            "description": "계산된 지표를 Redis에 캐싱하고 관리하는 시스템 구현 (중복 계산 방지)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "이벤트 기반 아키텍처 구현",
            "description": "Redis Pub/Sub을 활용한 이벤트 버스 시스템 구현 (market_data_received, indicators_updated 등)",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "커스텀 지표 추가 지원 구현",
            "description": "사용자 정의 기술적 지표를 등록하고 계산할 수 있는 프레임워크 구현",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "지표 계산 성능 최적화",
            "description": "캐싱, 벡터화, 병렬 처리 등을 활용한 지표 계산 성능 최적화",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "단위 테스트 작성",
            "description": "각 지표 계산 및 캐싱 시스템에 대한 단위 테스트 작성",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "통합 테스트 작성",
            "description": "전체 이벤트 흐름 및 시스템 통합 테스트 작성",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 27,
        "title": "백테스팅 엔진 구현",
        "description": "과거 데이터를 활용한 트레이딩 전략 백테스팅 엔진 구현 및 성과 분석 시스템 개발",
        "status": "pending",
        "dependencies": [
          24,
          25,
          26
        ],
        "priority": "low",
        "details": "1. 백테스팅 엔진 클래스 구현 (backtesting/engine.py):\n```python\nclass BacktestEngine:\n    def __init__(self, strategy, initial_capital=2000000):\n        self.strategy = strategy\n        self.initial_capital = initial_capital\n        self.current_capital = initial_capital\n        self.positions = {}\n        self.trades = []\n        self.equity_curve = []\n        \n    async def run(self, data, commission=0.00015):\n        # 백테스트 실행 로직\n        \n    def calculate_metrics(self):\n        # 성과 지표 계산 로직\n        # - 총 수익률\n        # - 샤프 비율\n        # - 최대 낙폭 (MDD)\n        # - 승률\n        # - 손익비\n        \n    def plot_results(self):\n        # 결과 시각화 로직\n        \n    def export_results(self, filename):\n        # 결과 내보내기 로직\n```\n2. 현실적인 거래 시뮬레이션:\n   - 슬리피지 모델링\n   - 거래 수수료 반영\n   - 부분 체결 시뮬레이션\n3. 다양한 성과 지표 계산:\n   - 총 수익률, 연간 수익률\n   - 샤프 비율, 소르티노 비율\n   - 최대 낙폭 (MDD)\n   - 승률, 손익비\n   - 일일/월간 수익률 분포\n4. 결과 시각화 도구:\n   - 자본 곡선\n   - 수익률 분포\n   - 월간/연간 성과 히트맵\n5. 몬테카를로 시뮬레이션 기능\n6. 파라미터 최적화 (그리드 서치, 유전 알고리즘)\n7. 워크포워드 분석 (과적합 방지)\n8. 결과 내보내기 (CSV, JSON, HTML 보고서)\n\n참고: 실제 트레이딩 시스템 구축이 우선순위이며, 백테스팅은 부가기능으로 실제 매매 시스템 구축 후 나중에 개발할 예정입니다. 소액 거래 시스템이므로 백테스팅보다는 실전에서 검증하는 것이 더 효율적일 수 있습니다.",
        "testStrategy": "1. 다양한 전략으로 백테스트 실행 테스트\n2. 수동 계산 결과와 비교하여 정확성 검증\n3. 성과 지표 계산 정확성 테스트\n4. 슬리피지 및 수수료 모델링 테스트\n5. 대용량 데이터 처리 성능 테스트\n6. 파라미터 최적화 기능 테스트\n7. 결과 시각화 및 내보내기 테스트\n8. 워크포워드 분석 유효성 테스트",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "주문 관리 시스템 구현",
        "description": "이벤트 기반 주문 엔진을 통한 주문 생성, 실행, 취소 및 포지션 관리 시스템 구현",
        "status": "pending",
        "dependencies": [
          22,
          20
        ],
        "priority": "high",
        "details": "1. OrderEngine 클래스 구현 (orders/engine.py):\n```python\nclass OrderEngine:\n    def __init__(self, kis_broker_client, db_session, risk_manager=None, event_bus=None):\n        self.broker_client = kis_broker_client\n        self.db_session = db_session\n        self.risk_manager = risk_manager\n        self.event_bus = event_bus\n        self.order_queue = OrderQueue()\n        self.position_manager = PositionManager()\n        self.commission_calculator = CommissionCalculator()\n        \n    async def start(self):\n        # 이벤트 구독 설정\n        await self.event_bus.subscribe('trading_signal', self.handle_trading_signal)\n        \n    async def handle_trading_signal(self, signal):\n        # 트레이딩 시그널 처리\n        # 1. 리스크 체크\n        # 2. 주문 생성\n        # 3. 주문 큐에 추가\n        # 4. 주문 실행\n        \n    async def execute_order(self, order):\n        # 주문 실행 로직\n        try:\n            result = await self.broker_client.place_order(order)\n            # 주문 성공 시 이벤트 발행\n            await self.event_bus.publish('order_executed', result)\n        except Exception as e:\n            # 주문 실패 시 이벤트 발행\n            await self.event_bus.publish('order_failed', {'order': order, 'error': str(e)})\n        \n    async def cancel_order(self, order_id):\n        # 주문 취소 로직\n        \n    async def update_order(self, order_id, new_price=None, new_quantity=None):\n        # 주문 수정 로직\n        \n    async def get_order_status(self, order_id):\n        # 주문 상태 조회 로직\n        \n    async def handle_execution_report(self, report):\n        # 체결 보고서 처리\n        # 1. 포지션 업데이트\n        # 2. 부분/완전 체결 처리\n        # 3. 이벤트 발행\n```\n\n2. KISBrokerClient 클래스 구현 (brokers/kis_broker.py):\n```python\nclass KISBrokerClient:\n    def __init__(self, kis_client):\n        self.kis_client = kis_client\n        \n    async def place_order(self, order):\n        # 한국투자증권 API를 통한 주문 실행\n        \n    async def cancel_order(self, order_id):\n        # 주문 취소 요청\n        \n    async def get_order_status(self, order_id):\n        # 주문 상태 조회\n        \n    async def get_positions(self):\n        # 현재 포지션 조회\n```\n\n3. OrderQueue 클래스 구현 (orders/queue.py):\n```python\nclass OrderQueue:\n    def __init__(self):\n        self.queue = asyncio.Queue()\n        self.processing = False\n        \n    async def add_order(self, order):\n        # 주문 큐에 추가\n        \n    async def process_queue(self):\n        # 큐에 있는 주문 순차적 처리\n```\n\n4. PositionManager 클래스 구현 (orders/position.py):\n```python\nclass PositionManager:\n    def __init__(self):\n        self.positions = {}\n        \n    async def update_position(self, symbol, quantity, price, side):\n        # 포지션 업데이트\n        \n    async def get_position(self, symbol):\n        # 특정 종목 포지션 조회\n        \n    async def get_all_positions(self):\n        # 모든 포지션 조회\n        \n    async def calculate_unrealized_pnl(self, symbol, current_price):\n        # 미실현 손익 계산\n```\n\n5. CommissionCalculator 클래스 구현 (orders/commission.py):\n```python\nclass CommissionCalculator:\n    def __init__(self, commission_rates=None):\n        self.commission_rates = commission_rates or {\n            'stock': 0.00015,  # 기본 주식 수수료\n            'etf': 0.00010,    # ETF 수수료\n        }\n        \n    def calculate_commission(self, order_type, price, quantity):\n        # 수수료 계산\n```\n\n6. 주문 타입 지원:\n   - 시장가 주문\n   - 지정가 주문\n   - 조건부 주문 (스탑, OCO)\n\n7. 이벤트 기반 주문 처리 흐름:\n   - trading_signal 이벤트 수신\n   - 리스크 체크 및 주문 생성\n   - 주문 큐에 추가 및 처리\n   - 주문 실행 및 결과 이벤트 발행 (order_executed, order_failed)\n   - 체결 보고서 처리 및 포지션 업데이트\n\n8. 체결 관리:\n   - 부분 체결 처리\n   - 미체결 주문 추적 및 관리\n   - 체결 이벤트 발행\n\n9. 포지션 관리:\n   - 실시간 포지션 추적\n   - 평균 매수가 계산\n   - 미실현 손익 계산\n\n10. 거래 기록 저장 및 분석\n\n11. 주문 실패 처리 및 재시도 메커니즘",
        "testStrategy": "1. 이벤트 기반 주문 처리 테스트:\n   - trading_signal 이벤트 발행 시 주문 생성 검증\n   - order_executed, order_failed 이벤트 발행 검증\n\n2. 한국투자증권 API 연동 테스트:\n   - 실제 주문 실행 테스트 (모의투자 환경)\n   - API 오류 처리 테스트\n\n3. 주문 큐 시스템 테스트:\n   - 다중 주문 동시 처리 테스트\n   - 주문 우선순위 처리 검증\n\n4. 체결 관리 테스트:\n   - 부분 체결 처리 정확성 테스트\n   - 미체결 주문 추적 테스트\n\n5. 포지션 관리 테스트:\n   - 포지션 업데이트 정확성 테스트\n   - 평균 매수가 계산 검증\n   - 미실현 손익 계산 검증\n\n6. 수수료 계산 테스트:\n   - 다양한 주문 타입별 수수료 계산 정확성 검증\n\n7. 다양한 주문 타입 테스트:\n   - 시장가, 지정가, 조건부 주문 실행 테스트\n\n8. 주문 취소 및 수정 테스트\n\n9. 에러 상황 시뮬레이션 및 재시도 로직 테스트\n\n10. 리스크 관리 연동 테스트\n\n11. 장시간 실행 안정성 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "OrderEngine 클래스 구현",
            "description": "이벤트 기반 주문 처리를 위한 OrderEngine 클래스 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "KISBrokerClient 클래스 구현",
            "description": "한국투자증권 API를 통한 실제 거래 실행을 담당하는 브로커 클라이언트 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "OrderQueue 클래스 구현",
            "description": "주문 순서 관리 및 동시 주문 처리를 위한 큐 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "PositionManager 클래스 구현",
            "description": "실시간 포지션 추적 및 관리 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "CommissionCalculator 클래스 구현",
            "description": "거래 수수료 계산 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "이벤트 구독 및 발행 시스템 구현",
            "description": "trading_signal 이벤트 구독 및 order_executed, order_failed 이벤트 발행 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "체결 관리 시스템 구현",
            "description": "부분/완전 체결 처리 및 미체결 주문 추적 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "단위 테스트 작성",
            "description": "각 컴포넌트별 단위 테스트 작성",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "통합 테스트 작성",
            "description": "전체 주문 처리 흐름에 대한 통합 테스트 작성",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 29,
        "title": "리스크 관리 시스템 구현",
        "description": "포지션 크기 제한, 손절/익절, 일일/월간 손실 한도 등 리스크 관리 시스템 구현. RPC 스타일 리스크 엔진으로 구현하여 실시간 리스크 체크 및 자동 손절/익절 기능 제공.",
        "status": "pending",
        "dependencies": [
          20,
          28
        ],
        "priority": "high",
        "details": "1. RiskEngine 클래스 구현 (risk/engine.py):\n```python\nclass RiskEngine:\n    def __init__(self, db_session, config=None):\n        self.db_session = db_session\n        self.config = config or self.default_config()\n        self.daily_pnl = 0\n        self.monthly_pnl = 0\n        self.consecutive_losses = 0\n        self.risk_rules = self._init_risk_rules()\n        self.stop_loss_manager = AutoStopLoss(self)\n        self.risk_monitor = RiskMonitor(self)\n        self.emergency_stop = EmergencyStop(self)\n        \n    @staticmethod\n    def default_config():\n        return {\n            'max_position_size': 0.2,  # 종목당 최대 투자 비율\n            'max_sector_exposure': 0.3,  # 섹터별 최대 투자 비율\n            'stop_loss_pct': 0.03,  # 종목별 손절 비율\n            'trailing_stop_pct': 0.02,  # 트레일링 스탑 비율\n            'take_profit_pct': 0.05,  # 익절 비율\n            'max_daily_loss': 10000,  # 일일 최대 손실 금액\n            'max_monthly_loss': 100000,  # 월간 최대 손실 금액\n            'max_trades_per_day': 10,  # 하루 최대 거래 횟수\n            'min_rebuy_interval': 60,  # 동일 종목 재매수 대기 시간(분)\n            'risk_alert_threshold': 0.8  # 리스크 한도 알림 임계값\n        }\n    \n    def _init_risk_rules(self):\n        # 리스크 규칙 초기화\n        return [\n            PositionSizeRule(self),\n            SectorExposureRule(self),\n            DailyLossRule(self),\n            MonthlyLossRule(self),\n            CashReserveRule(self),\n            TradeFrequencyRule(self)\n        ]\n        \n    async def check_order(self, symbol, side, quantity, price):\n        # RPC 스타일: 주문 실행 전 리스크 체크 로직\n        # 모든 리스크 규칙 검증 후 승인/거부 응답\n        for rule in self.risk_rules:\n            result = await rule.validate(symbol, side, quantity, price)\n            if not result['approved']:\n                await self._publish_risk_alert(result['message'], symbol)\n                return {\n                    'approved': False,\n                    'reason': result['message']\n                }\n        \n        return {'approved': True}\n        \n    async def update_position_risk(self, symbol, current_price):\n        # 포지션 리스크 업데이트 및 자동 손절/익절 체크\n        return await self.stop_loss_manager.check_positions(symbol, current_price)\n        \n    async def update_daily_pnl(self, trade_pnl):\n        # 일일 손익 업데이트 및 한도 체크\n        self.daily_pnl += trade_pnl\n        if trade_pnl < 0:\n            self.consecutive_losses += 1\n        else:\n            self.consecutive_losses = 0\n            \n        # 일일 손실 한도 접근 시 알림\n        if abs(self.daily_pnl) > self.config['max_daily_loss'] * self.config['risk_alert_threshold']:\n            await self._publish_risk_alert(f\"일일 손실 한도 {self.config['risk_alert_threshold']*100}% 접근\", \"SYSTEM\")\n            \n        return self.daily_pnl < -self.config['max_daily_loss']\n        \n    async def update_monthly_pnl(self, trade_pnl):\n        # 월간 손익 업데이트 및 한도 체크\n        self.monthly_pnl += trade_pnl\n        \n        # 월간 손실 한도 접근 시 알림\n        if abs(self.monthly_pnl) > self.config['max_monthly_loss'] * self.config['risk_alert_threshold']:\n            await self._publish_risk_alert(f\"월간 손실 한도 {self.config['risk_alert_threshold']*100}% 접근\", \"SYSTEM\")\n            \n        return self.monthly_pnl < -self.config['max_monthly_loss']\n        \n    async def should_stop_trading(self):\n        # 거래 중단 여부 결정 로직\n        return await self.emergency_stop.check_conditions()\n        \n    async def _publish_risk_alert(self, message, symbol):\n        # risk_alert 이벤트 발행\n        event = {\n            'type': 'risk_alert',\n            'message': message,\n            'symbol': symbol,\n            'timestamp': datetime.now().isoformat()\n        }\n        # Redis Pub/Sub으로 이벤트 발행\n        # await redis_client.publish('risk_alerts', json.dumps(event))\n```\n\n2. RiskRules 클래스 구현 (risk/rules.py):\n```python\nclass BaseRiskRule:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        \n    async def validate(self, symbol, side, quantity, price):\n        raise NotImplementedError()\n\nclass PositionSizeRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 종목당 최대 투자 비율 검증\n        pass\n        \nclass SectorExposureRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 섹터별 최대 투자 비율 검증\n        pass\n\nclass DailyLossRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 일일 손실 한도 검증\n        pass\n\nclass MonthlyLossRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 월간 손실 한도 검증\n        pass\n        \nclass CashReserveRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 현금 보유량 검증\n        pass\n        \nclass TradeFrequencyRule(BaseRiskRule):\n    async def validate(self, symbol, side, quantity, price):\n        # 거래 빈도 제한 검증\n        pass\n```\n\n3. AutoStopLoss 클래스 구현 (risk/stop_loss.py):\n```python\nclass AutoStopLoss:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.trailing_stops = {}\n        \n    async def check_positions(self, symbol, current_price):\n        # 포지션 손절/익절 조건 확인 및 자동 주문 실행\n        position = await self._get_position(symbol)\n        if not position:\n            return None\n            \n        # 고정 손절/익절 체크\n        if self._check_fixed_stop_loss(position, current_price):\n            return await self._execute_stop_loss(symbol, position)\n            \n        # 익절 체크\n        if self._check_take_profit(position, current_price):\n            return await self._execute_take_profit(symbol, position)\n            \n        # 트레일링 스탑 업데이트 및 체크\n        if self._update_trailing_stop(symbol, position, current_price):\n            return await self._execute_trailing_stop(symbol, position)\n            \n        return None\n        \n    async def _get_position(self, symbol):\n        # DB에서 포지션 정보 조회\n        pass\n        \n    def _check_fixed_stop_loss(self, position, current_price):\n        # 고정 손절 조건 확인\n        pass\n        \n    def _check_take_profit(self, position, current_price):\n        # 익절 조건 확인\n        pass\n        \n    def _update_trailing_stop(self, symbol, position, current_price):\n        # 트레일링 스탑 업데이트 및 조건 확인\n        pass\n        \n    async def _execute_stop_loss(self, symbol, position):\n        # 손절 주문 실행\n        pass\n        \n    async def _execute_take_profit(self, symbol, position):\n        # 익절 주문 실행\n        pass\n        \n    async def _execute_trailing_stop(self, symbol, position):\n        # 트레일링 스탑 주문 실행\n        pass\n```\n\n4. RiskMonitor 클래스 구현 (risk/monitor.py):\n```python\nclass RiskMonitor:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.metrics = {}\n        \n    async def update_metrics(self):\n        # 리스크 지표 업데이트\n        await self._update_portfolio_metrics()\n        await self._update_exposure_metrics()\n        await self._update_pnl_metrics()\n        await self._check_risk_thresholds()\n        \n    async def _update_portfolio_metrics(self):\n        # 포트폴리오 리스크 지표 업데이트\n        pass\n        \n    async def _update_exposure_metrics(self):\n        # 익스포저 지표 업데이트\n        pass\n        \n    async def _update_pnl_metrics(self):\n        # 손익 지표 업데이트\n        pass\n        \n    async def _check_risk_thresholds(self):\n        # 리스크 임계값 확인 및 알림\n        pass\n        \n    async def get_risk_report(self):\n        # 리스크 보고서 생성\n        pass\n```\n\n5. EmergencyStop 클래스 구현 (risk/emergency.py):\n```python\nclass EmergencyStop:\n    def __init__(self, risk_engine):\n        self.risk_engine = risk_engine\n        self.is_active = False\n        self.reason = None\n        \n    async def check_conditions(self):\n        # 비상 정지 조건 확인\n        if self.is_active:\n            return True\n            \n        # 일일 손실 한도 초과 확인\n        if await self._check_daily_loss_limit():\n            return await self._activate(\"일일 손실 한도 초과\")\n            \n        # 월간 손실 한도 초과 확인\n        if await self._check_monthly_loss_limit():\n            return await self._activate(\"월간 손실 한도 초과\")\n            \n        # 연속 손실 확인\n        if await self._check_consecutive_losses():\n            return await self._activate(\"연속 손실 발생\")\n            \n        # 시스템 이상 확인\n        if await self._check_system_anomalies():\n            return await self._activate(\"시스템 이상 감지\")\n            \n        return False\n        \n    async def _check_daily_loss_limit(self):\n        # 일일 손실 한도 초과 확인\n        return self.risk_engine.daily_pnl < -self.risk_engine.config['max_daily_loss']\n        \n    async def _check_monthly_loss_limit(self):\n        # 월간 손실 한도 초과 확인\n        return self.risk_engine.monthly_pnl < -self.risk_engine.config['max_monthly_loss']\n        \n    async def _check_consecutive_losses(self):\n        # 연속 손실 확인\n        return self.risk_engine.consecutive_losses >= 5\n        \n    async def _check_system_anomalies(self):\n        # 시스템 이상 확인\n        pass\n        \n    async def _activate(self, reason):\n        # 비상 정지 활성화\n        self.is_active = True\n        self.reason = reason\n        await self._notify_emergency_stop()\n        return True\n        \n    async def reset(self):\n        # 비상 정지 해제\n        self.is_active = False\n        self.reason = None\n        \n    async def _notify_emergency_stop(self):\n        # 비상 정지 알림\n        event = {\n            'type': 'emergency_stop',\n            'reason': self.reason,\n            'timestamp': datetime.now().isoformat()\n        }\n        # Redis Pub/Sub으로 이벤트 발행\n        # await redis_client.publish('risk_alerts', json.dumps(event))\n```\n\n6. 이벤트 흐름 구현:\n   - 주문 요청 → 리스크 체크 (RPC) → 승인/거부 응답 → risk_alert 발행\n   - 실시간 포지션 모니터링 → 손절/익절 조건 확인 → 자동 주문 실행\n   - 리스크 지표 모니터링 → 임계값 접근 시 알림 발행\n   - 비상 정지 조건 확인 → 비상 정지 활성화 → 알림 발행\n\n7. 포지션 크기 관리:\n   - Kelly Criterion 구현\n   - 고정 비율/금액 방식\n   - 변동성 기반 포지션 크기 조절\n\n8. 포트폴리오 리스크 관리:\n   - 종목별 최대 투자 비율\n   - 섹터별 분산 투자\n   - 상관관계 분석",
        "testStrategy": "1. RPC 스타일 리스크 체크 테스트:\n   - 다양한 주문 시나리오에 대한 승인/거부 응답 테스트\n   - 리스크 규칙별 검증 로직 테스트\n   - 응답 시간 성능 테스트 (10ms 이내 목표)\n\n2. 자동 손절/익절 테스트:\n   - 고정 손절/익절 조건 테스트\n   - 트레일링 스탑 로직 테스트\n   - 자동 주문 실행 테스트\n\n3. 리스크 알림 테스트:\n   - risk_alert 이벤트 발행 테스트\n   - 알림 임계값 설정 테스트\n   - 알림 메시지 포맷 및 내용 검증\n\n4. 비상 정지 시스템 테스트:\n   - 다양한 비상 정지 조건 테스트\n   - 비상 정지 활성화 및 해제 테스트\n   - 비상 정지 알림 테스트\n\n5. 포지션 크기 계산 정확성 테스트\n6. 손절/익절 로직 테스트\n7. 일일/월간 손실 한도 관리 테스트\n8. 포트폴리오 분산 투자 로직 테스트\n9. 거래 빈도 제한 테스트\n10. 다양한 시장 상황 시뮬레이션\n11. 리스크 설정 변경 테스트\n12. 리스크 지표 계산 및 모니터링 테스트\n13. 알림 시스템 연동 테스트\n14. 통합 테스트: 전체 리스크 관리 시스템 흐름 검증",
        "subtasks": [
          {
            "id": 1,
            "title": "RiskEngine 클래스 구현",
            "description": "RPC 스타일 리스크 체크 기능을 제공하는 RiskEngine 클래스 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "RiskRules 클래스 구현",
            "description": "다양한 리스크 규칙을 검증하는 RiskRules 클래스 구현 (포지션 크기, 섹터 익스포저, 손실 한도 등)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "AutoStopLoss/TakeProfit 클래스 구현",
            "description": "자동 손절/익절 기능을 제공하는 클래스 구현 (고정 손절/익절, 트레일링 스탑)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "RiskMonitor 클래스 구현",
            "description": "실시간 리스크 모니터링 및 알림 기능을 제공하는 클래스 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "EmergencyStop 클래스 구현",
            "description": "비상 정지 시스템 구현 (일일/월간 손실 한도 초과, 연속 손실, 시스템 이상 등)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "이벤트 발행 시스템 구현",
            "description": "risk_alert 및 emergency_stop 이벤트 발행 시스템 구현 (Redis Pub/Sub 활용)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "포지션 크기 관리 알고리즘 구현",
            "description": "Kelly Criterion, 고정 비율/금액, 변동성 기반 포지션 크기 조절 알고리즘 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "포트폴리오 리스크 관리 기능 구현",
            "description": "종목별 최대 투자 비율, 섹터별 분산 투자, 상관관계 분석 기능 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "통합 테스트 및 성능 최적화",
            "description": "전체 리스크 관리 시스템 통합 테스트 및 성능 최적화",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 30,
        "title": "FastAPI 백엔드 서버 구현",
        "description": "시스템 제어, 데이터 조회, 전략 관리를 위한 RESTful API 서버 구현",
        "status": "pending",
        "dependencies": [
          19,
          23,
          25,
          28,
          29
        ],
        "priority": "medium",
        "details": "1. FastAPI 애플리케이션 설정 (api/app.py):\n```python\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(title=\"QB Trading API\", version=\"1.0.0\")\n\n# CORS 설정\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# 라우터 등록\nfrom api.routers import data, strategies, orders, system\n\napp.include_router(data.router, prefix=\"/api/data\", tags=[\"data\"])\napp.include_router(strategies.router, prefix=\"/api/strategies\", tags=[\"strategies\"])\napp.include_router(orders.router, prefix=\"/api/orders\", tags=[\"orders\"])\napp.include_router(system.router, prefix=\"/api/system\", tags=[\"system\"])\n```\n2. 주요 API 엔드포인트 구현:\n   - 데이터 조회 API\n   - 전략 관리 API\n   - 주문 관리 API\n   - 시스템 제어 API\n3. 인증 및 권한 관리:\n   - JWT 기반 인증\n   - API 키 인증\n4. 요청 검증 및 에러 처리\n5. API 문서화 (Swagger/ReDoc)\n6. 웹소켓 엔드포인트 구현:\n   - 실시간 가격 데이터\n   - 실시간 포트폴리오 업데이트\n   - 시스템 알림\n7. 비동기 작업 처리 (Background Tasks)\n8. 로깅 및 모니터링 미들웨어\n9. 속도 제한 및 캐싱 구현\n10. 프론트엔드 지원 및 시스템 모니터링/관리 기능 통합",
        "testStrategy": "1. 각 API 엔드포인트 기능 테스트\n2. 인증 및 권한 관리 테스트\n3. 에러 처리 테스트\n4. 웹소켓 연결 및 데이터 전송 테스트\n5. 비동기 작업 처리 테스트\n6. 로깅 및 모니터링 테스트\n7. 속도 제한 및 캐싱 테스트\n8. 부하 테스트 (동시 요청 처리)\n9. API 문서 정확성 테스트\n10. 프론트엔드 연동 테스트\n11. 시스템 모니터링 및 관리 기능 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "기본 FastAPI 애플리케이션 설정",
            "description": "FastAPI 기본 설정, CORS 미들웨어 및 라우터 구조 설정",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "데이터 조회 API 엔드포인트 구현",
            "description": "시장 데이터, 차트 데이터, 종목 정보 등 조회 API 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "전략 관리 API 엔드포인트 구현",
            "description": "전략 생성, 수정, 삭제, 활성화/비활성화 API 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "시스템 모니터링 및 관리 API 구현",
            "description": "시스템 상태 모니터링, 로그 조회, 설정 변경 API 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "인증 및 권한 관리 시스템 구현",
            "description": "JWT 기반 인증 및 API 키 인증 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "웹소켓 엔드포인트 구현",
            "description": "실시간 데이터 전송을 위한 웹소켓 엔드포인트 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 31,
        "title": "Next.js 프론트엔드 기본 구조 구현",
        "description": "Next.js 14와 TypeScript를 활용한 웹 대시보드 기본 구조 및 레이아웃 구현",
        "status": "pending",
        "dependencies": [
          19
        ],
        "priority": "low",
        "details": "1. Next.js 14 프로젝트 설정:\n```bash\nnpx create-next-app@latest qb-dashboard --typescript --tailwind --eslint\ncd qb-dashboard\nnpm install shadcn-ui @radix-ui/react-icons\n```\n2. 프로젝트 구조 설계:\n```\nsrc/\n  ├── app/             # Next.js 14 App Router\n  ├── components/      # UI 컴포넌트\n  ├── lib/             # 유틸리티 함수\n  ├── hooks/           # 커스텀 훅\n  ├── api/             # API 클라이언트\n  └── types/           # TypeScript 타입 정의\n```\n3. Shadcn UI 및 Tailwind CSS 설정:\n```bash\nnpx shadcn-ui@latest init\n```\n4. 기본 레이아웃 구현:\n   - 헤더/푸터\n   - 사이드바 네비게이션\n   - 다크/라이트 테마 지원\n5. 주요 페이지 구조 설계:\n   - 대시보드 홈\n   - 포트폴리오 현황\n   - 전략 관리\n   - 거래 내역\n   - 설정\n6. 반응형 디자인 구현\n7. 인증 시스템 구현 (NextAuth.js)\n8. API 클라이언트 설정 (axios 또는 fetch 래퍼)\n9. 상태 관리 설정 (React Context 또는 Zustand)\n\n참고: 백엔드 트레이딩 시스템 완성 후 개발 예정. 프론트엔드는 시각적 요소로 실제 매매 시작에는 필수적이지 않음.",
        "testStrategy": "1. 프로젝트 구조 및 설정 검증\n2. 컴포넌트 렌더링 테스트\n3. 반응형 디자인 테스트\n4. 테마 전환 기능 테스트\n5. 네비게이션 기능 테스트\n6. API 클라이언트 연결 테스트\n7. 인증 시스템 테스트\n8. 상태 관리 테스트\n9. 접근성 (a11y) 테스트",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "실시간 차트 및 데이터 시각화 구현",
        "description": "TradingView Charting Library 또는 Chart.js를 활용한 실시간 차트 및 데이터 시각화 컴포넌트 구현",
        "status": "pending",
        "dependencies": [
          31,
          30
        ],
        "priority": "low",
        "details": "1. TradingView Charting Library 통합:\n```typescript\n// components/TradingViewChart.tsx\nimport { useEffect, useRef } from 'react';\nimport { widget } from '../lib/charting_library/charting_library.min';\n\ninterface ChartProps {\n  symbol: string;\n  interval: string;\n  containerId: string;\n}\n\nexport default function TradingViewChart({ symbol, interval, containerId }: ChartProps) {\n  const chartRef = useRef<any>(null);\n\n  useEffect(() => {\n    const widgetOptions = {\n      symbol: symbol,\n      datafeed: new CustomDatafeed(),\n      interval: interval,\n      container: containerId,\n      library_path: '/charting_library/',\n      locale: 'ko',\n      timezone: 'Asia/Seoul',\n      // 추가 옵션 설정\n    };\n\n    chartRef.current = new widget(widgetOptions);\n\n    return () => {\n      if (chartRef.current) {\n        chartRef.current.remove();\n        chartRef.current = null;\n      }\n    };\n  }, [symbol, interval, containerId]);\n\n  return <div id={containerId} className=\"h-[500px] w-full\" />;\n}\n```\n2. 커스텀 데이터피드 구현:\n   - 실시간 WebSocket 데이터 연동\n   - 과거 데이터 로딩\n   - 기술적 지표 계산 및 표시\n3. 대체 차트 라이브러리 (Chart.js) 구현:\n   - 캔들스틱 차트\n   - 기술적 지표 오버레이\n   - 실시간 업데이트\n4. 추가 데이터 시각화 컴포넌트:\n   - 포트폴리오 구성 파이/도넛 차트\n   - 수익률 라인/바 차트\n   - 히트맵 (월간/연간 성과)\n   - 거래 분포 히스토그램\n5. 대시보드 위젯 구현:\n   - 실시간 포트폴리오 가치\n   - 일일/월간 수익률\n   - 주요 지표 요약\n   - 최근 거래 내역\n6. 차트 상호작용 기능:\n   - 줌인/줌아웃\n   - 시간 범위 선택\n   - 지표 추가/제거\n   - 주문 표시 및 생성\n\n참고: 이 기능은 실제 매매 시스템 완성 후 나중에 개발할 부가 기능으로 설정되었습니다. 핵심 트레이딩 기능이 우선적으로 개발되어야 합니다.",
        "testStrategy": "1. 차트 렌더링 테스트\n2. 실시간 데이터 업데이트 테스트\n3. 과거 데이터 로딩 테스트\n4. 다양한 기술적 지표 표시 테스트\n5. 차트 상호작용 기능 테스트\n6. 다양한 시간 프레임 전환 테스트\n7. 대시보드 위젯 렌더링 테스트\n8. 성능 및 메모리 사용량 테스트\n9. 다양한 브라우저/기기 호환성 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "개발 우선순위 조정",
            "description": "실시간 차트 및 데이터 시각화는 부가기능으로 실제 매매 시스템 완성 후 개발하도록 우선순위 조정",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 33,
        "title": "WebSocket 실시간 통신 구현",
        "description": "프론트엔드와 백엔드 간 WebSocket을 활용한 실시간 데이터 통신 시스템 구현",
        "status": "pending",
        "dependencies": [
          30,
          31
        ],
        "priority": "low",
        "details": "1. 백엔드 WebSocket 서버 구현 (api/websocket.py):\n```python\nfrom fastapi import WebSocket, WebSocketDisconnect\nfrom typing import Dict, List, Any\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: Dict[str, List[WebSocket]] = {}\n        \n    async def connect(self, websocket: WebSocket, client_id: str, channel: str):\n        await websocket.accept()\n        if channel not in self.active_connections:\n            self.active_connections[channel] = []\n        self.active_connections[channel].append((client_id, websocket))\n        \n    def disconnect(self, websocket: WebSocket, client_id: str, channel: str):\n        if channel in self.active_connections:\n            self.active_connections[channel] = [\n                (cid, ws) for cid, ws in self.active_connections[channel] \n                if cid != client_id\n            ]\n            \n    async def broadcast(self, message: Any, channel: str):\n        if channel in self.active_connections:\n            for client_id, connection in self.active_connections[channel]:\n                try:\n                    await connection.send_json(message)\n                except WebSocketDisconnect:\n                    self.disconnect(connection, client_id, channel)\n\nmanager = ConnectionManager()\n```\n2. WebSocket 엔드포인트 구현:\n   - 실시간 가격 데이터 채널\n   - 포트폴리오 업데이트 채널\n   - 주문 상태 채널\n   - 시스템 알림 채널\n3. 프론트엔드 WebSocket 클라이언트 구현 (hooks/useWebSocket.ts):\n```typescript\nimport { useState, useEffect, useCallback } from 'react';\n\ninterface WebSocketOptions {\n  url: string;\n  onMessage?: (data: any) => void;\n  onOpen?: () => void;\n  onClose?: () => void;\n  onError?: (error: Event) => void;\n  reconnect?: boolean;\n  reconnectInterval?: number;\n  maxReconnectAttempts?: number;\n}\n\nexport function useWebSocket(options: WebSocketOptions) {\n  const [socket, setSocket] = useState<WebSocket | null>(null);\n  const [isConnected, setIsConnected] = useState(false);\n  const [reconnectAttempts, setReconnectAttempts] = useState(0);\n  \n  // WebSocket 연결 함수\n  const connect = useCallback(() => {\n    const ws = new WebSocket(options.url);\n    \n    ws.onopen = () => {\n      setIsConnected(true);\n      setReconnectAttempts(0);\n      if (options.onOpen) options.onOpen();\n    };\n    \n    ws.onmessage = (event) => {\n      if (options.onMessage) {\n        try {\n          const data = JSON.parse(event.data);\n          options.onMessage(data);\n        } catch (error) {\n          options.onMessage(event.data);\n        }\n      }\n    };\n    \n    ws.onclose = () => {\n      setIsConnected(false);\n      if (options.onClose) options.onClose();\n      \n      // 재연결 로직\n      if (options.reconnect && \n          reconnectAttempts < (options.maxReconnectAttempts || 5)) {\n        setTimeout(() => {\n          setReconnectAttempts(prev => prev + 1);\n          connect();\n        }, options.reconnectInterval || 3000);\n      }\n    };\n    \n    ws.onerror = (error) => {\n      if (options.onError) options.onError(error);\n    };\n    \n    setSocket(ws);\n  }, [options, reconnectAttempts]);\n  \n  // 메시지 전송 함수\n  const sendMessage = useCallback((data: any) => {\n    if (socket && isConnected) {\n      socket.send(typeof data === 'string' ? data : JSON.stringify(data));\n      return true;\n    }\n    return false;\n  }, [socket, isConnected]);\n  \n  // 연결 종료 함수\n  const disconnect = useCallback(() => {\n    if (socket) {\n      socket.close();\n      setSocket(null);\n      setIsConnected(false);\n    }\n  }, [socket]);\n  \n  // 컴포넌트 마운트 시 연결\n  useEffect(() => {\n    connect();\n    return () => {\n      if (socket) socket.close();\n    };\n  }, [connect]);\n  \n  return { isConnected, sendMessage, disconnect };\n}\n```\n4. 실시간 데이터 구독 관리 시스템\n5. 연결 상태 모니터링 및 자동 재연결\n6. 메시지 큐 및 배치 처리 최적화\n7. 인증 및 권한 관리\n8. 실시간 알림 시스템 구현\n\n참고: 이 기능은 트레이딩 시스템 완성 후 나중에 개발할 예정입니다. 프론트엔드용 WebSocket 통신으로, 실제 트레이딩 시작을 위해 우선순위가 낮아졌습니다.",
        "testStrategy": "1. WebSocket 연결 및 통신 테스트\n2. 다양한 채널 구독/해제 테스트\n3. 실시간 데이터 수신 및 처리 테스트\n4. 연결 끊김 및 재연결 테스트\n5. 대량 메시지 처리 성능 테스트\n6. 인증 및 권한 관리 테스트\n7. 다중 클라이언트 동시 연결 테스트\n8. 메모리 누수 테스트\n9. 브라우저 호환성 테스트",
        "subtasks": []
      },
      {
        "id": 34,
        "title": "포트폴리오 및 거래 내역 관리 구현",
        "description": "현재 포트폴리오 상태, 거래 내역, 성과 분석을 위한 관리 시스템 구현",
        "status": "pending",
        "dependencies": [
          28,
          29,
          30,
          31
        ],
        "priority": "low",
        "details": "1. 포트폴리오 관리 클래스 구현 (orders/portfolio.py):\n```python\nclass Portfolio:\n    def __init__(self, db_session, account_id):\n        self.db_session = db_session\n        self.account_id = account_id\n        self.positions = {}\n        self.cash = 0\n        self.initial_capital = 0\n        self.last_updated = None\n        \n    async def load_from_database(self):\n        # DB에서 포트폴리오 정보 로드\n        \n    async def update_from_api(self, kis_client):\n        # API에서 최신 포트폴리오 정보 업데이트\n        \n    async def add_position(self, symbol, quantity, price):\n        # 포지션 추가 로직\n        \n    async def update_position(self, symbol, quantity, price):\n        # 포지션 업데이트 로직\n        \n    async def remove_position(self, symbol):\n        # 포지션 제거 로직\n        \n    async def calculate_metrics(self):\n        # 포트폴리오 지표 계산 (총 가치, 수익률, 섹터 분포 등)\n        \n    async def save_to_database(self):\n        # 포트폴리오 정보 DB 저장\n```\n2. 거래 내역 관리 시스템 구현:\n   - 거래 기록 저장 및 조회\n   - 거래별 수익/손실 계산\n   - 거래 통계 분석\n3. 성과 분석 시스템 구현:\n   - 일/주/월/연 단위 수익률 계산\n   - 주요 성과 지표 계산 (샤프 비율, MDD 등)\n   - 벤치마크 대비 성과 비교\n4. 포트폴리오 최적화 기능:\n   - 섹터별 분산 투자 분석\n   - 상관관계 분석\n   - 리밸런싱 추천\n5. 세금 및 수수료 계산 시스템\n6. 포트폴리오 내보내기/가져오기 기능\n7. 백엔드 API 엔드포인트 구현:\n   - 포트폴리오 조회/업데이트 API\n   - 거래 내역 조회 API\n   - 성과 분석 API\n8. 프론트엔드 컴포넌트 구현 (실제 매매 시스템 완성 후 나중에 개발):\n   - 포트폴리오 요약 대시보드\n   - 포지션 목록 테이블\n   - 거래 내역 테이블\n   - 성과 분석 차트",
        "testStrategy": "1. 포트폴리오 관리 기능 테스트\n2. 거래 내역 저장 및 조회 테스트\n3. 성과 지표 계산 정확성 테스트\n4. 포트폴리오 최적화 기능 테스트\n5. 세금 및 수수료 계산 정확성 테스트\n6. 내보내기/가져오기 기능 테스트\n7. API 엔드포인트 기능 테스트\n8. 프론트엔드 컴포넌트 렌더링 테스트 (실제 매매 시스템 완성 후 진행)\n9. 실시간 업데이트 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "포트폴리오 관리 클래스 기본 구현",
            "description": "Portfolio 클래스의 기본 구조 및 핵심 메서드 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "거래 내역 관리 시스템 구현",
            "description": "거래 기록 저장, 조회 및 분석 기능 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "백엔드 API 엔드포인트 구현",
            "description": "포트폴리오 및 거래 내역 관련 API 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "프론트엔드 컴포넌트 구현",
            "description": "실제 매매 시스템 완성 후 UI 컴포넌트 개발 (후순위)",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 35,
        "title": "알림 및 리포팅 시스템 구현",
        "description": "중요 이벤트 알림, 일일 거래 요약, 성과 리포트 등 알림 및 리포팅 시스템 구현",
        "status": "pending",
        "dependencies": [
          28,
          29,
          30,
          31
        ],
        "priority": "low",
        "details": "1. 알림 시스템 클래스 구현 (utils/notification.py):\n```python\nclass NotificationSystem:\n    def __init__(self, config=None):\n        self.config = config or {}\n        self.handlers = {\n            'email': EmailNotifier(self.config.get('email')),\n            'slack': SlackNotifier(self.config.get('slack')),\n            'telegram': TelegramNotifier(self.config.get('telegram')),\n            'web': WebNotifier()\n        }\n        \n    async def send_notification(self, message, level='info', channels=None):\n        # 알림 전송 로직\n        channels = channels or ['web']\n        for channel in channels:\n            if channel in self.handlers:\n                await self.handlers[channel].send(message, level)\n                \n    async def send_trade_notification(self, trade_data):\n        # 거래 알림 전송\n        \n    async def send_risk_alert(self, risk_data):\n        # 리스크 알림 전송\n        \n    async def send_system_alert(self, system_data):\n        # 시스템 알림 전송\n        \n    async def send_daily_report(self, report_data):\n        # 일일 리포트 전송\n```\n2. 다양한 알림 채널 구현:\n   - 이메일 알림\n   - Slack/Discord 알림\n   - Telegram 알림\n   - 웹 푸시 알림\n3. 알림 우선순위 및 필터링 시스템:\n   - 중요도별 알림 분류\n   - 사용자 설정 기반 필터링\n4. 주요 알림 이벤트 구현:\n   - 거래 실행/체결 알림\n   - 손절/익절 알림\n   - 리스크 한도 접근/초과 알림\n   - 시스템 오류 알림\n5. 정기 리포트 생성 시스템:\n   - 일일 거래 요약 리포트\n   - 주간/월간 성과 리포트\n   - 리스크 분석 리포트\n6. 리포트 템플릿 시스템:\n   - HTML 이메일 템플릿\n   - PDF 리포트 생성\n   - 대시보드 내 리포트 뷰\n7. 알림 설정 관리 인터페이스\n8. 알림 이력 저장 및 조회 기능\n\n참고: 이 기능은 실제 매매 시스템 완성 후 나중에 개발할 부가 기능으로 분류됩니다.",
        "testStrategy": "1. 다양한 알림 채널 전송 테스트\n2. 알림 우선순위 및 필터링 테스트\n3. 주요 알림 이벤트 트리거 테스트\n4. 정기 리포트 생성 및 전송 테스트\n5. 리포트 템플릿 렌더링 테스트\n6. 알림 설정 관리 테스트\n7. 알림 이력 저장 및 조회 테스트\n8. 대량 알림 처리 성능 테스트\n9. 알림 전송 실패 시 재시도 로직 테스트",
        "subtasks": []
      },
      {
        "id": 36,
        "title": "시스템 모니터링 및 로깅 구현",
        "description": "시스템 상태 모니터링, 성능 추적, 로깅 및 오류 처리 시스템 구현",
        "status": "pending",
        "dependencies": [
          19,
          30,
          31
        ],
        "priority": "medium",
        "details": "1. 로깅 시스템 구현 (utils/logging.py):\n```python\nimport logging\nimport sys\nfrom pathlib import Path\nfrom logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\n\nclass LoggingSystem:\n    def __init__(self, log_dir='logs', app_name='qb'):\n        self.log_dir = Path(log_dir)\n        self.log_dir.mkdir(exist_ok=True)\n        self.app_name = app_name\n        self.loggers = {}\n        \n    def get_logger(self, name, level=logging.INFO):\n        if name in self.loggers:\n            return self.loggers[name]\n            \n        logger = logging.getLogger(f\"{self.app_name}.{name}\")\n        logger.setLevel(level)\n        \n        # 콘솔 핸들러\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(self._get_formatter())\n        logger.addHandler(console_handler)\n        \n        # 파일 핸들러\n        file_handler = RotatingFileHandler(\n            self.log_dir / f\"{name}.log\",\n            maxBytes=10*1024*1024,  # 10MB\n            backupCount=5\n        )\n        file_handler.setFormatter(self._get_formatter())\n        logger.addHandler(file_handler)\n        \n        # 에러 파일 핸들러\n        error_handler = RotatingFileHandler(\n            self.log_dir / f\"{name}_error.log\",\n            maxBytes=10*1024*1024,\n            backupCount=5\n        )\n        error_handler.setLevel(logging.ERROR)\n        error_handler.setFormatter(self._get_formatter())\n        logger.addHandler(error_handler)\n        \n        self.loggers[name] = logger\n        return logger\n        \n    def _get_formatter(self):\n        return logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n```\n2. 시스템 모니터링 구현:\n   - CPU/메모리 사용량 추적\n   - 데이터베이스 성능 모니터링\n   - API 응답 시간 추적\n   - 주문 처리 시간 모니터링\n3. 헬스체크 시스템 구현:\n   - 주요 서비스 상태 확인\n   - 외부 API 연결 상태 확인\n   - 데이터베이스 연결 확인\n   - 정기적인 자가 진단\n4. 오류 처리 및 복구 시스템:\n   - 예외 캡처 및 로깅\n   - 자동 재시작 메커니즘\n   - 장애 복구 프로세스\n5. 성능 지표 수집 및 분석:\n   - 주요 작업 실행 시간 측정\n   - 병목 지점 식별\n   - 리소스 사용량 추세 분석\n6. 대시보드 모니터링 페이지 구현:\n   - 시스템 상태 요약\n   - 로그 뷰어\n   - 성능 그래프\n   - 알림 이력",
        "testStrategy": "1. 로깅 시스템 기능 테스트\n2. 시스템 모니터링 지표 수집 테스트\n3. 헬스체크 시스템 작동 테스트\n4. 오류 발생 시 처리 및 복구 테스트\n5. 성능 지표 수집 및 분석 테스트\n6. 대시보드 모니터링 페이지 렌더링 테스트\n7. 로그 로테이션 및 관리 테스트\n8. 장기간 실행 시 안정성 테스트\n9. 대용량 로그 처리 성능 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "로깅 시스템 구현",
            "description": "utils/logging.py에 LoggingSystem 클래스 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "시스템 모니터링 구현",
            "description": "CPU/메모리 사용량, DB 성능, API 응답 시간, 주문 처리 시간 등 모니터링 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "헬스체크 시스템 구현",
            "description": "주요 서비스, 외부 API, DB 연결 상태 확인 및 자가 진단 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "오류 처리 및 복구 시스템 구현",
            "description": "예외 캡처, 로깅, 자동 재시작 및 장애 복구 프로세스 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "성능 지표 수집 및 분석 시스템 구현",
            "description": "주요 작업 실행 시간 측정, 병목 지점 식별, 리소스 사용량 추세 분석 기능 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "대시보드 모니터링 페이지 구현",
            "description": "시스템 상태 요약, 로그 뷰어, 성능 그래프, 알림 이력 등을 표시하는 대시보드 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 37,
        "title": "GCP Compute Engine 기반 트레이딩 시스템 배포 인프라 설계 및 구축",
        "description": "GCP Compute Engine e2-standard-2 VM에 PostgreSQL+TimescaleDB, Redis, Python 백엔드, Next.js 프론트엔드를 Docker Compose로 구성하여 24/7 안정적 운영 환경 구축",
        "status": "pending",
        "dependencies": [
          19,
          20,
          33,
          36
        ],
        "priority": "low",
        "details": "1. GCP Compute Engine 인프라 설계:\n   - e2-standard-2 VM 인스턴스 프로비저닝 (2 vCPU, 8GB RAM)\n   - 영구 디스크 설정: 100GB SSD (데이터베이스 및 로그 저장용)\n   - 네트워크 설정: 정적 IP 할당, 방화벽 규칙 구성 (80, 443, 22 포트 개방)\n   - 부하 분산 및 자동 확장 설정 검토\n\n2. Docker Compose 기반 배포 환경 구성:\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  db:\n    image: timescale/timescaledb:latest-pg15\n    restart: always\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./init-scripts:/docker-entrypoint-initdb.d\n    environment:\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_USER: ${DB_USER}\n      POSTGRES_DB: qb_trading\n    ports:\n      - \"5432:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USER} -d qb_trading\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    restart: always\n    volumes:\n      - redis_data:/data\n    ports:\n      - \"6379:6379\"\n    command: redis-server --appendonly yes\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    environment:\n      - DB_HOST=db\n      - DB_PORT=5432\n      - DB_USER=${DB_USER}\n      - DB_PASSWORD=${DB_PASSWORD}\n      - DB_NAME=qb_trading\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n      - API_KEY=${KIS_API_KEY}\n      - API_SECRET=${KIS_API_SECRET}\n    volumes:\n      - ./backend:/app\n      - ./logs:/app/logs\n    ports:\n      - \"8000:8000\"\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - backend\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NEXT_PUBLIC_API_URL=http://backend:8000\n\n  nginx:\n    image: nginx:alpine\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/conf:/etc/nginx/conf.d\n      - ./nginx/certbot/conf:/etc/letsencrypt\n      - ./nginx/certbot/www:/var/www/certbot\n    depends_on:\n      - frontend\n      - backend\n\n  certbot:\n    image: certbot/certbot\n    volumes:\n      - ./nginx/certbot/conf:/etc/letsencrypt\n      - ./nginx/certbot/www:/var/www/certbot\n\nvolumes:\n  postgres_data:\n  redis_data:\n```\n\n3. 백엔드 Dockerfile 구성:\n```dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n4. 프론트엔드 Dockerfile 구성:\n```dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package.json package-lock.json ./\nRUN npm ci\n\nCOPY . .\n\nRUN npm run build\n\nCMD [\"npm\", \"start\"]\n```\n\n5. Nginx 설정 구성:\n```nginx\n# nginx/conf/default.conf\nserver {\n    listen 80;\n    server_name trading.example.com;\n    \n    location /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n    \n    location / {\n        return 301 https://$host$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl;\n    server_name trading.example.com;\n    \n    ssl_certificate /etc/letsencrypt/live/trading.example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/trading.example.com/privkey.pem;\n    \n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n    \n    location /api {\n        proxy_pass http://backend:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n    \n    location /ws {\n        proxy_pass http://backend:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n    }\n}\n```\n\n6. 시스템 모니터링 및 로깅 설정:\n   - Prometheus + Grafana 모니터링 스택 구성\n   - 로그 집계 및 분석을 위한 ELK 스택 또는 Loki 설정\n   - 시스템 상태 알림 설정 (Slack, 이메일)\n\n7. 백업 및 복구 전략:\n   - 데이터베이스 자동 백업 스크립트 구현\n   - GCP Cloud Storage를 활용한 백업 저장\n   - 장애 복구 절차 문서화\n\n8. CI/CD 파이프라인 구성:\n   - GitHub Actions 또는 GitLab CI를 활용한 자동 배포\n   - 테스트 자동화 및 배포 전 검증\n   - 롤백 전략 수립\n\n9. 보안 강화:\n   - 환경 변수를 통한 민감 정보 관리\n   - 방화벽 규칙 최소화\n   - 정기적인 보안 업데이트 적용 계획\n   - SSL/TLS 인증서 자동 갱신 설정\n\n10. 운영 문서 작성:\n    - 시스템 아키텍처 다이어그램\n    - 배포 및 업데이트 절차\n    - 문제 해결 가이드\n    - 모니터링 대시보드 사용법",
        "testStrategy": "1. GCP 인프라 검증:\n   - VM 인스턴스 프로비저닝 및 접속 테스트\n   - 디스크 마운트 및 성능 테스트 (dd, fio 도구 활용)\n   - 네트워크 연결성 및 방화벽 규칙 테스트\n\n2. Docker Compose 환경 테스트:\n   - `docker-compose up -d` 명령으로 전체 스택 실행 테스트\n   - 각 컨테이너 상태 확인: `docker-compose ps`\n   - 컨테이너 간 네트워크 연결성 테스트\n   - 컨테이너 로그 확인: `docker-compose logs`\n\n3. 데이터베이스 검증:\n   - PostgreSQL 연결 테스트: `psql -h localhost -U <user> -d qb_trading`\n   - TimescaleDB 확장 활성화 확인: `SELECT * FROM pg_extension;`\n   - 테이블 및 하이퍼테이블 생성 테스트\n   - 데이터 삽입 및 쿼리 성능 테스트\n\n4. Redis 검증:\n   - Redis 연결 테스트: `redis-cli ping`\n   - 데이터 저장 및 조회 테스트\n   - 영속성 설정 검증 (재시작 후 데이터 유지 여부)\n\n5. 백엔드 API 테스트:\n   - 헬스체크 엔드포인트 테스트: `curl http://localhost:8000/health`\n   - 주요 API 엔드포인트 기능 테스트 (Postman 또는 curl 활용)\n   - WebSocket 연결 및 실시간 데이터 수신 테스트\n\n6. 프론트엔드 테스트:\n   - 웹 페이지 로딩 테스트: `curl http://localhost:3000`\n   - 브라우저에서 UI 렌더링 확인\n   - API 연동 및 데이터 표시 테스트\n   - 반응형 디자인 테스트 (다양한 화면 크기)\n\n7. Nginx 및 SSL 테스트:\n   - HTTP에서 HTTPS 리다이렉션 테스트\n   - SSL 인증서 유효성 확인: `openssl s_client -connect trading.example.com:443`\n   - 프록시 설정 테스트 (API 및 WebSocket 요청)\n\n8. 부하 테스트:\n   - 시스템 부하 테스트 (Apache Bench, JMeter 등 활용)\n   - 동시 사용자 접속 테스트\n   - 장시간 실행 안정성 테스트 (24시간 이상)\n\n9. 모니터링 및 로깅 테스트:\n   - Prometheus 메트릭 수집 확인\n   - Grafana 대시보드 접근 및 데이터 표시 테스트\n   - 로그 집계 시스템 작동 확인\n   - 알림 시스템 트리거 테스트\n\n10. 장애 복구 테스트:\n    - 컨테이너 장애 시뮬레이션 및 자동 복구 테스트\n    - 데이터베이스 백업 및 복원 테스트\n    - 전체 시스템 재시작 테스트\n    - 네트워크 단절 시뮬레이션 및 복구 테스트",
        "subtasks": [
          {
            "id": 1,
            "title": "배포 우선순위 조정 및 개발 완료 후 진행 계획 수립",
            "description": "실제 트레이딩 시작을 위해 배포 작업의 우선순위를 낮추고, 개발 완료 후 진행할 수 있도록 계획 수립",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 38,
        "title": "Docker Compose 기반 GCP 무료 VM 배포 시스템 구현",
        "description": "1GB RAM과 1 vCPU 제약사항을 고려하여 PostgreSQL, TimescaleDB, Redis, FastAPI, Next.js를 Docker 컨테이너로 구성하고 원클릭 배포가 가능한 최적화된 배포 시스템 구현. 아키텍처 설계 문서에 따라 8개의 이벤트 기반 마이크로서비스 엔진을 포함한 시스템 배포.",
        "status": "pending",
        "dependencies": [
          37,
          20,
          21,
          30,
          31,
          36
        ],
        "priority": "low",
        "details": "1. 리소스 최적화 Docker Compose 구성:\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  db:\n    image: timescale/timescaledb:latest-pg15\n    restart: always\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: ${DB_USER}\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_DB: ${DB_NAME}\n    command: >\n      postgres -c shared_buffers=128MB -c max_connections=20 \n              -c effective_cache_size=256MB -c work_mem=4MB\n              -c maintenance_work_mem=32MB -c random_page_cost=1.1\n    deploy:\n      resources:\n        limits:\n          memory: 300M\n          cpus: '0.3'\n\n  redis:\n    image: redis:7-alpine\n    restart: always\n    volumes:\n      - redis_data:/data\n    command: redis-server --save 60 1 --loglevel warning --maxmemory 100mb --maxmemory-policy allkeys-lru\n    deploy:\n      resources:\n        limits:\n          memory: 150M\n          cpus: '0.1'\n\n  api:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENV_FILE=.env\n    volumes:\n      - ./backend:/app\n      - ./logs:/app/logs\n    deploy:\n      resources:\n        limits:\n          memory: 250M\n          cpus: '0.3'\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - api\n    environment:\n      - NEXT_PUBLIC_API_URL=http://api:8000\n    volumes:\n      - ./frontend:/app\n    deploy:\n      resources:\n        limits:\n          memory: 200M\n          cpus: '0.2'\n\n  nginx:\n    image: nginx:alpine\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./nginx/conf.d:/etc/nginx/conf.d\n      - ./certbot/conf:/etc/letsencrypt\n      - ./certbot/www:/var/www/certbot\n    depends_on:\n      - api\n      - frontend\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.1'\n\n  # 이벤트 기반 마이크로서비스 엔진들\n  market_data_engine:\n    build:\n      context: ./engines/market_data\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${MARKET_DATA_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  signal_engine:\n    build:\n      context: ./engines/signal\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${SIGNAL_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  strategy_engine:\n    build:\n      context: ./engines/strategy\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${STRATEGY_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  risk_engine:\n    build:\n      context: ./engines/risk\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${RISK_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  order_engine:\n    build:\n      context: ./engines/order\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${ORDER_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  execution_engine:\n    build:\n      context: ./engines/execution\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${EXECUTION_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  portfolio_engine:\n    build:\n      context: ./engines/portfolio\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${PORTFOLIO_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\n  analytics_engine:\n    build:\n      context: ./engines/analytics\n      dockerfile: Dockerfile\n    restart: always\n    depends_on:\n      - db\n      - redis\n    environment:\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}\n      - REDIS_URL=redis://redis:6379/0\n      - ENGINE_CONFIG=${ANALYTICS_CONFIG}\n    deploy:\n      resources:\n        limits:\n          memory: 50M\n          cpus: '0.05'\n\nvolumes:\n  postgres_data:\n  redis_data:\n```\n\n2. 최적화된 Dockerfile 구성:\n\n```dockerfile\n# backend/Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# 의존성 설치 레이어 최적화\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 애플리케이션 코드 복사\nCOPY . .\n\n# 실행 명령\nCMD [\"uvicorn\", \"api.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n```dockerfile\n# frontend/Dockerfile\nFROM node:18-alpine AS builder\n\nWORKDIR /app\n\n# 의존성 설치 레이어 최적화\nCOPY package.json package-lock.json ./\nRUN npm ci\n\n# 소스 코드 복사 및 빌드\nCOPY . .\nRUN npm run build\n\n# 실행 이미지 - 빌드 결과물만 포함\nFROM node:18-alpine\n\nWORKDIR /app\n\n# 빌드 결과물만 복사\nCOPY --from=builder /app/next.config.js ./\nCOPY --from=builder /app/public ./public\nCOPY --from=builder /app/.next ./.next\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/package.json ./\n\n# 실행 명령\nCMD [\"npm\", \"start\"]\n```\n\n```dockerfile\n# engines/base/Dockerfile (기본 엔진 템플릿)\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# 의존성 설치 레이어 최적화\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 애플리케이션 코드 복사\nCOPY . .\n\n# 실행 명령\nCMD [\"python\", \"main.py\"]\n```\n\n3. 원클릭 배포 스크립트 (setup.sh):\n\n```bash\n#!/bin/bash\nset -e\n\n# 색상 정의\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\necho -e \"${GREEN}===== QB Trading System 배포 스크립트 =====${NC}\"\n\n# 필수 패키지 설치\necho -e \"${YELLOW}필수 패키지 설치 중...${NC}\"\nsudo apt-get update\nsudo apt-get install -y docker.io docker-compose git curl\n\n# Docker 서비스 시작 및 자동 시작 설정\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# 현재 사용자를 docker 그룹에 추가\nsudo usermod -aG docker $USER\necho \"현재 사용자를 docker 그룹에 추가했습니다. 변경사항을 적용하려면 재로그인이 필요할 수 있습니다.\"\n\n# 프로젝트 클론\necho -e \"${YELLOW}프로젝트 저장소 클론 중...${NC}\"\ngit clone https://github.com/your-username/qb-trading.git\ncd qb-trading\n\n# 환경 변수 설정\necho -e \"${YELLOW}환경 변수 설정 중...${NC}\"\ncp .env.example .env\necho \"환경 변수 파일(.env)이 생성되었습니다. 필요한 경우 수정해주세요.\"\nread -p \"환경 변수를 수정하시겠습니까? (y/n): \" edit_env\nif [ \"$edit_env\" = \"y\" ]; then\n  nano .env\nfi\n\n# 엔진별 환경변수 설정\ncat >> .env << 'EOF'\n\n# 엔진별 설정\nMARKET_DATA_CONFIG='{\"sources\":[\"yahoo\",\"alphavantage\"],\"update_interval\":300}'\nSIGNAL_CONFIG='{\"indicators\":[\"macd\",\"rsi\",\"bollinger\"],\"timeframes\":[\"1m\",\"5m\",\"15m\",\"1h\",\"1d\"]}'\nSTRATEGY_CONFIG='{\"strategies\":[\"momentum\",\"mean_reversion\",\"trend_following\"],\"backtest_period\":30}'\nRISK_CONFIG='{\"max_position_size\":0.05,\"max_drawdown\":0.02,\"stop_loss\":0.01}'\nORDER_CONFIG='{\"default_order_type\":\"limit\",\"time_in_force\":\"gtc\"}'\nEXECUTION_CONFIG='{\"retry_attempts\":3,\"timeout\":10}'\nPORTFOLIO_CONFIG='{\"rebalance_interval\":86400,\"max_positions\":10}'\nANALYTICS_CONFIG='{\"metrics\":[\"sharpe\",\"sortino\",\"max_drawdown\",\"win_rate\"],\"report_interval\":86400}'\nEOF\n\n# 디렉토리 생성\nmkdir -p logs nginx/conf.d certbot/conf certbot/www\nmkdir -p engines/market_data engines/signal engines/strategy engines/risk\nmkdir -p engines/order engines/execution engines/portfolio engines/analytics\n\n# Nginx 설정 생성\ncat > nginx/conf.d/default.conf << 'EOF'\nserver {\n    listen 80;\n    server_name _;\n\n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    location /api {\n        proxy_pass http://api:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    location /ws {\n        proxy_pass http://api:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n    }\n}\nEOF\n\n# 시스템 모니터링 스크립트 생성\ncat > monitor.sh << 'EOF'\n#!/bin/bash\n\n# 시스템 상태 확인 및 로깅\nlog_file=\"logs/system_monitor.log\"\nmkdir -p logs\n\ncheck_system() {\n  echo \"===== $(date) =====\" >> $log_file\n  echo \"CPU 사용량:\" >> $log_file\n  top -bn1 | grep \"Cpu(s)\" >> $log_file\n  echo \"메모리 사용량:\" >> $log_file\n  free -m >> $log_file\n  echo \"디스크 사용량:\" >> $log_file\n  df -h >> $log_file\n  echo \"Docker 컨테이너 상태:\" >> $log_file\n  docker ps >> $log_file\n  echo \"컨테이너별 리소스 사용량:\" >> $log_file\n  docker stats --no-stream >> $log_file\n  echo \"\" >> $log_file\n}\n\n# 컨테이너 상태 확인 및 재시작\ncheck_containers() {\n  for container in $(docker-compose ps -q); do\n    if [ ! \"$(docker ps -q -f id=$container)\" ]; then\n      echo \"$(date) - 컨테이너 $container가 중지되었습니다. 재시작합니다.\" >> $log_file\n      docker-compose up -d\n      break\n    fi\n  done\n}\n\n# 엔진 상태 확인\ncheck_engines() {\n  engines=(\"market_data_engine\" \"signal_engine\" \"strategy_engine\" \"risk_engine\" \n          \"order_engine\" \"execution_engine\" \"portfolio_engine\" \"analytics_engine\")\n  \n  for engine in \"${engines[@]}\"; do\n    container_id=$(docker-compose ps -q $engine)\n    if [ -z \"$container_id\" ] || [ ! \"$(docker ps -q -f id=$container_id)\" ]; then\n      echo \"$(date) - $engine이 실행 중이 아닙니다. 재시작합니다.\" >> $log_file\n      docker-compose up -d $engine\n    fi\n  done\n}\n\n# 디스크 공간 정리\ncleanup_disk() {\n  # 로그 파일 로테이션\n  find logs -name \"*.log\" -size +100M -exec sh -c 'gzip -f \"{}\" && mv \"{}.gz\" \"{}.$(date +%Y%m%d).gz\"' \\;\n  \n  # 오래된 로그 파일 삭제\n  find logs -name \"*.gz\" -mtime +30 -delete\n  \n  # Docker 정리\n  docker system prune -af --volumes >> $log_file 2>&1\n}\n\n# 메인 실행\ncheck_system\ncheck_containers\ncheck_engines\n\n# 매주 일요일 디스크 정리\nif [ \"$(date +%u)\" = \"7\" ]; then\n  cleanup_disk\nfi\nEOF\n\nchmod +x monitor.sh\n\n# 백업 스크립트 생성\ncat > backup.sh << 'EOF'\n#!/bin/bash\n\n# 설정\nBACKUP_DIR=\"backups\"\nDB_CONTAINER=\"qb-trading_db_1\"\nDB_USER=\"${DB_USER:-postgres}\"\nDB_NAME=\"${DB_NAME:-qb_trading}\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"$BACKUP_DIR/db_backup_$TIMESTAMP.sql.gz\"\nRETENTION_DAYS=14\n\n# 백업 디렉토리 생성\nmkdir -p $BACKUP_DIR\n\n# 데이터베이스 백업\necho \"데이터베이스 백업 중...\"\ndocker exec $DB_CONTAINER pg_dump -U $DB_USER $DB_NAME | gzip > $BACKUP_FILE\n\n# 백업 파일 정보 출력\necho \"백업 완료: $BACKUP_FILE ($(du -h $BACKUP_FILE | cut -f1))\"\n\n# 오래된 백업 파일 삭제\nfind $BACKUP_DIR -name \"db_backup_*.sql.gz\" -mtime +$RETENTION_DAYS -delete\necho \"$RETENTION_DAYS일 이상 지난 백업 파일 삭제 완료\"\nEOF\n\nchmod +x backup.sh\n\n# 복원 스크립트 생성\ncat > restore.sh << 'EOF'\n#!/bin/bash\n\n# 설정\nBACKUP_DIR=\"backups\"\nDB_CONTAINER=\"qb-trading_db_1\"\nDB_USER=\"${DB_USER:-postgres}\"\nDB_NAME=\"${DB_NAME:-qb_trading}\"\n\n# 사용 가능한 백업 파일 목록 표시\necho \"사용 가능한 백업 파일:\"\nls -lh $BACKUP_DIR | grep db_backup\n\n# 복원할 백업 파일 선택\nread -p \"복원할 백업 파일명을 입력하세요: \" BACKUP_FILE\n\nif [ ! -f \"$BACKUP_DIR/$BACKUP_FILE\" ]; then\n  echo \"오류: 파일을 찾을 수 없습니다.\"\n  exit 1\nfi\n\n# 복원 전 확인\nread -p \"기존 데이터베이스를 삭제하고 '$BACKUP_FILE'에서 복원하시겠습니까? (y/n): \" CONFIRM\nif [ \"$CONFIRM\" != \"y\" ]; then\n  echo \"복원 취소됨\"\n  exit 0\nfi\n\n# 데이터베이스 복원\necho \"데이터베이스 복원 중...\"\ngunzip -c \"$BACKUP_DIR/$BACKUP_FILE\" | docker exec -i $DB_CONTAINER psql -U $DB_USER -d $DB_NAME\n\necho \"복원 완료\"\nEOF\n\nchmod +x restore.sh\n\n# Cron 작업 설정\necho -e \"${YELLOW}Cron 작업 설정 중...${NC}\"\n(crontab -l 2>/dev/null; echo \"*/5 * * * * $(pwd)/monitor.sh\") | crontab -\n(crontab -l 2>/dev/null; echo \"0 1 * * * $(pwd)/backup.sh\") | crontab -\n\n# Docker Compose 실행\necho -e \"${YELLOW}Docker Compose 실행 중...${NC}\"\ndocker-compose up -d\n\n# GitHub Actions CI/CD 설정 파일 생성\nmkdir -p .github/workflows\ncat > .github/workflows/deploy.yml << 'EOF'\nname: Deploy to GCP VM\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      \n      - name: Set up SSH\n        uses: webfactory/ssh-agent@v0.7.0\n        with:\n          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}\n          \n      - name: Add host key\n        run: |\n          mkdir -p ~/.ssh\n          ssh-keyscan ${{ secrets.VM_HOST }} >> ~/.ssh/known_hosts\n          \n      - name: Deploy to VM\n        run: |\n          ssh ${{ secrets.VM_USER }}@${{ secrets.VM_HOST }} \"cd ~/qb-trading && git pull && docker-compose up -d --build\"\n          \n      - name: Check deployment status\n        run: |\n          ssh ${{ secrets.VM_USER }}@${{ secrets.VM_HOST }} \"cd ~/qb-trading && ./monitor.sh && cat logs/system_monitor.log | tail -n 30\"\nEOF\n\necho -e \"${GREEN}===== 배포 완료 =====${NC}\"\necho \"시스템이 성공적으로 배포되었습니다.\"\necho \"웹 대시보드: http://$(curl -s ifconfig.me)\"\necho \"\"\necho \"유용한 명령어:\"\necho \"  - 로그 확인: docker-compose logs -f\"\necho \"  - 시스템 상태 확인: ./monitor.sh\"\necho \"  - 데이터베이스 백업: ./backup.sh\"\necho \"  - 데이터베이스 복원: ./restore.sh\"\necho \"\"\necho \"GitHub Actions CI/CD 설정을 완료하려면 저장소에 다음 시크릿을 추가하세요:\"\necho \"  - SSH_PRIVATE_KEY: VM 접속용 SSH 개인 키\"\necho \"  - VM_HOST: VM의 IP 주소\"\necho \"  - VM_USER: VM 접속 사용자명\"",
        "testStrategy": "1. GCP 무료 VM 환경 테스트:\n   - e2-micro 인스턴스(1 vCPU, 1GB RAM)에서 배포 스크립트 실행\n   - 메모리 사용량 모니터링: `free -m` 및 `docker stats`\n   - CPU 사용량 모니터링: `top` 및 `docker stats`\n   - 디스크 사용량 확인: `df -h`\n\n2. Docker Compose 구성 테스트:\n   - `docker-compose up -d` 명령으로 전체 스택 실행\n   - 각 컨테이너 리소스 제한 준수 확인: `docker stats`\n   - 컨테이너 간 네트워크 연결성 테스트: `docker exec -it api ping db`\n   - 로그 확인: `docker-compose logs -f`\n\n3. 데이터베이스 성능 테스트:\n   - PostgreSQL 최적화 설정 검증: `docker exec -it db psql -U postgres -c \"SHOW shared_buffers;\"`\n   - TimescaleDB 기능 테스트: 하이퍼테이블 생성 및 쿼리\n   - 메모리 사용량 모니터링: `docker stats db`\n\n4. Redis 성능 테스트:\n   - 메모리 제한 준수 확인: `docker exec -it redis redis-cli info memory`\n   - 캐시 작동 테스트: 데이터 저장 및 조회\n   - 메모리 정책 테스트: 최대 메모리 도달 시 동작 확인\n\n5. 백엔드 API 테스트:\n   - 엔드포인트 접근성 테스트: `curl http://localhost/api/health`\n   - 메모리 사용량 모니터링: `docker stats api`\n   - 로그 생성 및 저장 확인\n\n6. 프론트엔드 테스트:\n   - 웹 페이지 로딩 테스트: 브라우저에서 접속\n   - 반응형 디자인 테스트: 다양한 화면 크기에서 확인\n   - API 연동 테스트: 데이터 조회 및 표시\n\n7. 배포 스크립트 테스트:\n   - 클린 VM에서 원클릭 배포 테스트\n   - 환경 변수 설정 검증\n   - 오류 처리 및 복구 기능 테스트\n\n8. 모니터링 및 유지보수 테스트:\n   - 모니터링 스크립트 실행 및 로그 확인\n   - 컨테이너 강제 종료 후 자동 재시작 확인\n   - 디스크 정리 기능 테스트\n\n9. 백업 및 복원 테스트:\n   - 백업 스크립트 실행 및 백업 파일 생성 확인\n   - 복원 스크립트로 데이터베이스 복원 테스트\n   - 백업 파일 자동 정리 기능 테스트\n\n10. CI/CD 파이프라인 테스트:\n    - GitHub 저장소 설정 및 시크릿 추가\n    - 코드 변경 후 자동 배포 테스트\n    - 롤백 절차 테스트\n\n11. 마이크로서비스 엔진 테스트:\n    - 각 엔진별 독립 실행 테스트\n    - 엔진 간 이벤트 기반 통신 테스트\n    - 엔진 장애 시 자동 복구 테스트\n    - 엔진별 로그 생성 및 모니터링 확인\n\n12. 통합 성능 테스트:\n    - 전체 시스템 부하 테스트\n    - 메모리 누수 확인: 장시간 실행 후 메모리 사용량 모니터링\n    - 리소스 사용량 최적화 검증: 전체 메모리 사용량이 1GB 이내 유지되는지 확인",
        "subtasks": [
          {
            "id": 1,
            "title": "Docker Compose 리소스 최적화 구성",
            "description": "1GB RAM과 1 vCPU 제약사항에 맞게 각 서비스별 리소스 제한 설정",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "8개 마이크로서비스 엔진 구현",
            "description": "이벤트 기반 마이크로서비스 아키텍처에 따른 8개 엔진 구현 및 배포 설정",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "엔진별 환경변수 설정 구현",
            "description": "각 엔진별 설정을 환경변수로 관리하는 시스템 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "모니터링 스크립트 엔진 지원 기능 추가",
            "description": "모니터링 스크립트에 8개 엔진 상태 확인 및 자동 복구 기능 추가",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "GitHub Actions CI/CD 파이프라인 구현",
            "description": "코드 변경 시 자동 배포 및 상태 확인을 위한 GitHub Actions 워크플로우 구현",
            "status": "pending",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "개발 완료 후 배포 계획 수립",
            "description": "실제 트레이딩 시스템 개발이 완료된 후 Docker 배포를 위한 계획 및 일정 수립",
            "status": "pending",
            "dependencies": [],
            "details": "1. 개발 완료 기준 정의\n2. 배포 전 테스트 계획 수립\n3. 배포 일정 및 담당자 지정\n4. 배포 후 모니터링 계획 수립",
            "testStrategy": "1. 개발 완료 기준 충족 여부 확인\n2. 테스트 환경에서의 배포 테스트 실행\n3. 배포 계획 문서 검토 및 승인"
          }
        ]
      },
      {
        "id": 39,
        "title": "Redis Pub/Sub 기반 이벤트 버스 시스템 구현",
        "description": "Redis Pub/Sub을 활용한 비동기 이벤트 통신 시스템 구현으로 시스템 전체 이벤트 중계, 라우팅, 필터링 및 이벤트 기록 메커니즘 제공",
        "details": "1. EventBus 클래스 구현 (utils/event_bus.py):\n```python\nimport json\nimport asyncio\nimport logging\nfrom typing import Dict, List, Callable, Any, Optional, Union\nfrom redis.asyncio import Redis\n\nclass EventBus:\n    def __init__(self, redis_client: Redis):\n        self.redis = redis_client\n        self.logger = logging.getLogger(\"event_bus\")\n        self.subscribers = {}\n        self.pubsub = self.redis.pubsub()\n        self.running = False\n        self.event_history = {}  # 최근 이벤트 기록\n        self.request_handlers = {}  # Request/Response 핸들러\n        self.request_futures = {}  # 응답 대기 Future 객체\n        \n    async def start(self):\n        \"\"\"이벤트 버스 시작\"\"\"\n        if self.running:\n            return\n        self.running = True\n        asyncio.create_task(self._message_listener())\n        self.logger.info(\"EventBus started\")\n        \n    async def stop(self):\n        \"\"\"이벤트 버스 중지\"\"\"\n        self.running = False\n        await self.pubsub.unsubscribe()\n        await self.pubsub.close()\n        self.logger.info(\"EventBus stopped\")\n        \n    async def publish(self, event_type: str, data: Any, retain: bool = False):\n        \"\"\"이벤트 발행\"\"\"\n        message = {\n            \"type\": event_type,\n            \"data\": data,\n            \"timestamp\": asyncio.get_event_loop().time()\n        }\n        \n        serialized = json.dumps(message)\n        await self.redis.publish(event_type, serialized)\n        \n        if retain:\n            # 이벤트 기록 보존\n            self.event_history[event_type] = message\n            # Redis에도 최근 이벤트 저장 (TTL 설정)\n            await self.redis.set(f\"event_history:{event_type}\", serialized, ex=3600)\n            \n        self.logger.debug(f\"Published event: {event_type}\")\n        \n    async def subscribe(self, event_type: str, callback: Callable):\n        \"\"\"이벤트 구독\"\"\"\n        if event_type not in self.subscribers:\n            self.subscribers[event_type] = []\n            await self.pubsub.subscribe(event_type)\n            \n        self.subscribers[event_type].append(callback)\n        self.logger.debug(f\"Subscribed to event: {event_type}\")\n        \n        # 보존된 이벤트가 있으면 즉시 전달\n        if event_type in self.event_history:\n            await callback(self.event_history[event_type])\n            \n    async def unsubscribe(self, event_type: str, callback: Callable = None):\n        \"\"\"이벤트 구독 취소\"\"\"\n        if event_type not in self.subscribers:\n            return\n            \n        if callback is None:\n            self.subscribers[event_type] = []\n        else:\n            self.subscribers[event_type] = [cb for cb in self.subscribers[event_type] if cb != callback]\n            \n        if not self.subscribers[event_type]:\n            await self.pubsub.unsubscribe(event_type)\n            self.subscribers.pop(event_type)\n            \n        self.logger.debug(f\"Unsubscribed from event: {event_type}\")\n        \n    async def _message_listener(self):\n        \"\"\"메시지 리스너 루프\"\"\"\n        while self.running:\n            try:\n                message = await self.pubsub.get_message(ignore_subscribe_messages=True)\n                if message is not None:\n                    channel = message[\"channel\"].decode(\"utf-8\")\n                    data = json.loads(message[\"data\"].decode(\"utf-8\"))\n                    \n                    # Request/Response 패턴 처리\n                    if channel.startswith(\"request:\"):\n                        await self._handle_request(channel, data)\n                    elif channel.startswith(\"response:\"):\n                        await self._handle_response(channel, data)\n                    # 일반 이벤트 처리\n                    elif channel in self.subscribers:\n                        for callback in self.subscribers[channel]:\n                            try:\n                                await callback(data)\n                            except Exception as e:\n                                self.logger.error(f\"Error in event handler: {e}\")\n                                \n                await asyncio.sleep(0.001)  # CPU 부하 방지\n            except Exception as e:\n                self.logger.error(f\"Error in message listener: {e}\")\n                await asyncio.sleep(1)  # 오류 발생 시 잠시 대기\n                \n    # Request/Response 패턴 구현\n    async def register_request_handler(self, request_type: str, handler: Callable):\n        \"\"\"요청 핸들러 등록\"\"\"\n        full_channel = f\"request:{request_type}\"\n        if full_channel not in self.request_handlers:\n            self.request_handlers[full_channel] = []\n            await self.pubsub.subscribe(full_channel)\n            \n        self.request_handlers[full_channel].append(handler)\n        \n    async def _handle_request(self, channel: str, data: Dict):\n        \"\"\"요청 메시지 처리\"\"\"\n        if channel not in self.request_handlers:\n            return\n            \n        request_id = data.get(\"request_id\")\n        if not request_id:\n            return\n            \n        for handler in self.request_handlers[channel]:\n            try:\n                response = await handler(data[\"data\"])\n                # 응답 발행\n                response_channel = f\"response:{channel.split(':', 1)[1]}\"\n                response_data = {\n                    \"request_id\": request_id,\n                    \"data\": response,\n                    \"timestamp\": asyncio.get_event_loop().time()\n                }\n                await self.redis.publish(response_channel, json.dumps(response_data))\n            except Exception as e:\n                self.logger.error(f\"Error in request handler: {e}\")\n                \n    async def send_request(self, request_type: str, data: Any, timeout: float = 5.0) -> Any:\n        \"\"\"요청 전송 및 응답 대기\"\"\"\n        request_id = f\"{request_type}:{id(data)}:{asyncio.get_event_loop().time()}\"\n        response_channel = f\"response:{request_type}\"\n        \n        # 응답 대기 Future 생성\n        future = asyncio.get_event_loop().create_future()\n        self.request_futures[request_id] = future\n        \n        # 응답 채널 구독\n        if response_channel not in self.subscribers:\n            await self.pubsub.subscribe(response_channel)\n            self.subscribers[response_channel] = []\n            \n        # 응답 핸들러 등록\n        async def response_handler(response_data):\n            if response_data.get(\"request_id\") == request_id and not future.done():\n                future.set_result(response_data.get(\"data\"))\n                \n        self.subscribers[response_channel].append(response_handler)\n        \n        # 요청 발행\n        request_data = {\n            \"request_id\": request_id,\n            \"data\": data,\n            \"timestamp\": asyncio.get_event_loop().time()\n        }\n        await self.redis.publish(f\"request:{request_type}\", json.dumps(request_data))\n        \n        try:\n            # 타임아웃과 함께 응답 대기\n            return await asyncio.wait_for(future, timeout)\n        except asyncio.TimeoutError:\n            self.logger.warning(f\"Request timed out: {request_type}\")\n            raise TimeoutError(f\"Request {request_type} timed out\")\n        finally:\n            # 정리\n            self.request_futures.pop(request_id, None)\n            if response_channel in self.subscribers:\n                self.subscribers[response_channel] = [\n                    cb for cb in self.subscribers[response_channel] if cb != response_handler\n                ]\n                \n    async def _handle_response(self, channel: str, data: Dict):\n        \"\"\"응답 메시지 처리\"\"\"\n        request_id = data.get(\"request_id\")\n        if not request_id or request_id not in self.request_futures:\n            return\n            \n        future = self.request_futures[request_id]\n        if not future.done():\n            future.set_result(data.get(\"data\"))\n```\n\n2. EventRouter 클래스 구현 (utils/event_router.py):\n```python\nfrom typing import Dict, List, Callable, Pattern, Any\nimport re\nimport asyncio\nimport logging\nfrom .event_bus import EventBus\n\nclass EventRouter:\n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self.routes = {}  # 이벤트 타입 -> 핸들러 매핑\n        self.pattern_routes = []  # (패턴, 핸들러) 튜플 리스트\n        self.logger = logging.getLogger(\"event_router\")\n        \n    async def start(self):\n        \"\"\"라우터 시작 및 이벤트 구독\"\"\"\n        for event_type in self.routes:\n            await self.event_bus.subscribe(event_type, self._create_handler(event_type))\n            \n        # 패턴 기반 라우팅을 위한 와일드카드 구독\n        await self.event_bus.subscribe(\"*\", self._pattern_handler)\n        \n    async def add_route(self, event_type: str, handler: Callable):\n        \"\"\"특정 이벤트 타입에 대한 핸들러 등록\"\"\"\n        if event_type not in self.routes:\n            self.routes[event_type] = []\n            await self.event_bus.subscribe(event_type, self._create_handler(event_type))\n            \n        self.routes[event_type].append(handler)\n        self.logger.debug(f\"Added route for event: {event_type}\")\n        \n    async def add_pattern_route(self, pattern: str, handler: Callable):\n        \"\"\"정규식 패턴 기반 이벤트 라우팅 등록\"\"\"\n        compiled_pattern = re.compile(pattern)\n        self.pattern_routes.append((compiled_pattern, handler))\n        self.logger.debug(f\"Added pattern route: {pattern}\")\n        \n    def _create_handler(self, event_type: str):\n        \"\"\"특정 이벤트 타입에 대한 핸들러 생성\"\"\"\n        async def handler(event_data):\n            if event_type in self.routes:\n                for route_handler in self.routes[event_type]:\n                    try:\n                        await route_handler(event_data)\n                    except Exception as e:\n                        self.logger.error(f\"Error in event handler for {event_type}: {e}\")\n        return handler\n        \n    async def _pattern_handler(self, event_data):\n        \"\"\"패턴 기반 이벤트 핸들러\"\"\"\n        event_type = event_data.get(\"type\", \"\")\n        for pattern, handler in self.pattern_routes:\n            if pattern.match(event_type):\n                try:\n                    await handler(event_data)\n                except Exception as e:\n                    self.logger.error(f\"Error in pattern handler for {event_type}: {e}\")\n```\n\n3. EventLogger 클래스 구현 (utils/event_logger.py):\n```python\nimport json\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.future import select\nfrom sqlalchemy import insert\nfrom .event_bus import EventBus\nfrom database.models import EventLog\n\nclass EventLogger:\n    def __init__(self, event_bus: EventBus, db_session_maker, log_level: str = \"INFO\"):\n        self.event_bus = event_bus\n        self.db_session_maker = db_session_maker\n        self.logger = logging.getLogger(\"event_logger\")\n        self.log_level = getattr(logging, log_level.upper())\n        self.buffer = []\n        self.buffer_size = 100\n        self.flush_interval = 5  # 초\n        self.running = False\n        self.event_types_to_log = set()  # 로깅할 이벤트 타입\n        \n    async def start(self):\n        \"\"\"이벤트 로거 시작\"\"\"\n        if self.running:\n            return\n            \n        self.running = True\n        # 모든 이벤트 구독\n        await self.event_bus.subscribe(\"*\", self._log_event)\n        # 주기적 버퍼 플러시 태스크 시작\n        asyncio.create_task(self._periodic_flush())\n        self.logger.info(\"EventLogger started\")\n        \n    async def stop(self):\n        \"\"\"이벤트 로거 중지\"\"\"\n        self.running = False\n        await self._flush_buffer()\n        self.logger.info(\"EventLogger stopped\")\n        \n    def add_event_type(self, event_type: str):\n        \"\"\"로깅할 이벤트 타입 추가\"\"\"\n        self.event_types_to_log.add(event_type)\n        \n    def remove_event_type(self, event_type: str):\n        \"\"\"로깅할 이벤트 타입 제거\"\"\"\n        self.event_types_to_log.discard(event_type)\n        \n    async def _log_event(self, event_data: Dict):\n        \"\"\"이벤트 로깅\"\"\"\n        event_type = event_data.get(\"type\", \"\")\n        \n        # 특정 이벤트 타입만 로깅하거나, 설정이 없으면 모두 로깅\n        if self.event_types_to_log and event_type not in self.event_types_to_log:\n            return\n            \n        # 로그 레벨에 따라 로깅\n        log_entry = {\n            \"event_type\": event_type,\n            \"data\": json.dumps(event_data.get(\"data\", {})),\n            \"timestamp\": datetime.utcnow(),\n            \"metadata\": json.dumps({\n                \"source\": event_data.get(\"source\", \"unknown\"),\n                \"correlation_id\": event_data.get(\"correlation_id\", None)\n            })\n        }\n        \n        # 버퍼에 추가\n        self.buffer.append(log_entry)\n        \n        # 버퍼 크기 초과 시 플러시\n        if len(self.buffer) >= self.buffer_size:\n            await self._flush_buffer()\n            \n    async def _flush_buffer(self):\n        \"\"\"버퍼 내용을 데이터베이스에 저장\"\"\"\n        if not self.buffer:\n            return\n            \n        buffer_to_flush = self.buffer.copy()\n        self.buffer = []\n        \n        try:\n            async with self.db_session_maker() as session:\n                await session.execute(insert(EventLog).values(buffer_to_flush))\n                await session.commit()\n                self.logger.debug(f\"Flushed {len(buffer_to_flush)} events to database\")\n        except Exception as e:\n            self.logger.error(f\"Error flushing event buffer: {e}\")\n            # 실패한 이벤트 다시 버퍼에 추가\n            self.buffer.extend(buffer_to_flush)\n            \n    async def _periodic_flush(self):\n        \"\"\"주기적으로 버퍼 플러시\"\"\"\n        while self.running:\n            await asyncio.sleep(self.flush_interval)\n            await self._flush_buffer()\n            \n    async def get_recent_events(self, event_type: Optional[str] = None, limit: int = 100) -> List[Dict]:\n        \"\"\"최근 이벤트 조회\"\"\"\n        async with self.db_session_maker() as session:\n            query = select(EventLog).order_by(EventLog.timestamp.desc()).limit(limit)\n            \n            if event_type:\n                query = query.where(EventLog.event_type == event_type)\n                \n            result = await session.execute(query)\n            events = result.scalars().all()\n            \n            return [\n                {\n                    \"id\": event.id,\n                    \"event_type\": event.event_type,\n                    \"data\": json.loads(event.data),\n                    \"timestamp\": event.timestamp.isoformat(),\n                    \"metadata\": json.loads(event.metadata)\n                }\n                for event in events\n            ]\n```\n\n4. RequestResponseManager 클래스 구현 (utils/request_response.py):\n```python\nimport asyncio\nimport logging\nimport uuid\nfrom typing import Dict, Any, Callable, Optional\nfrom .event_bus import EventBus\n\nclass RequestResponseManager:\n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self.logger = logging.getLogger(\"request_response\")\n        self.handlers = {}  # 요청 타입 -> 핸들러 매핑\n        \n    async def start(self):\n        \"\"\"요청/응답 관리자 시작\"\"\"\n        # 이벤트 버스에 요청 핸들러 등록\n        for request_type in self.handlers:\n            await self.event_bus.register_request_handler(\n                request_type, \n                self._create_request_handler(request_type)\n            )\n        self.logger.info(\"RequestResponseManager started\")\n        \n    async def register_handler(self, request_type: str, handler: Callable):\n        \"\"\"요청 핸들러 등록\"\"\"\n        if request_type not in self.handlers:\n            self.handlers[request_type] = []\n            await self.event_bus.register_request_handler(\n                request_type,\n                self._create_request_handler(request_type)\n            )\n            \n        self.handlers[request_type].append(handler)\n        self.logger.debug(f\"Registered handler for request type: {request_type}\")\n        \n    def _create_request_handler(self, request_type: str):\n        \"\"\"요청 핸들러 생성\"\"\"\n        async def handler(request_data: Any) -> Any:\n            if request_type in self.handlers:\n                # 첫 번째 핸들러만 사용 (요청은 단일 응답만 가능)\n                try:\n                    return await self.handlers[request_type][0](request_data)\n                except Exception as e:\n                    self.logger.error(f\"Error in request handler for {request_type}: {e}\")\n                    return {\"error\": str(e)}\n            return None\n        return handler\n        \n    async def send_request(self, request_type: str, data: Any, timeout: float = 5.0) -> Any:\n        \"\"\"요청 전송 및 응답 대기\"\"\"\n        try:\n            return await self.event_bus.send_request(request_type, data, timeout)\n        except TimeoutError:\n            self.logger.warning(f\"Request timed out: {request_type}\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Error sending request {request_type}: {e}\")\n            raise\n```\n\n5. 이벤트 정의 및 상수 (utils/event_types.py):\n```python\n# 시장 데이터 이벤트\nMARKET_DATA_RECEIVED = \"market_data_received\"\nINDICATORS_UPDATED = \"indicators_updated\"\nCANDLE_CLOSED = \"candle_closed\"\nPRICE_ALERT = \"price_alert\"\n\n# 거래 이벤트\nTRADING_SIGNAL = \"trading_signal\"\nORDER_PLACED = \"order_placed\"\nORDER_EXECUTED = \"order_executed\"\nORDER_FAILED = \"order_failed\"\nORDER_CANCELED = \"order_canceled\"\nPOSITION_OPENED = \"position_opened\"\nPOSITION_CLOSED = \"position_closed\"\nPOSITION_UPDATED = \"position_updated\"\n\n# 리스크 이벤트\nRISK_ALERT = \"risk_alert\"\nSTOP_LOSS_TRIGGERED = \"stop_loss_triggered\"\nTAKE_PROFIT_TRIGGERED = \"take_profit_triggered\"\nRISK_LIMIT_REACHED = \"risk_limit_reached\"\n\n# 시스템 이벤트\nSYSTEM_ERROR = \"system_error\"\nENGINE_STARTED = \"engine_started\"\nENGINE_STOPPED = \"engine_stopped\"\nCONFIG_UPDATED = \"config_updated\"\nHEALTH_CHECK = \"health_check\"\n```\n\n6. 이벤트 버스 초기화 및 통합 (utils/event_system.py):\n```python\nimport logging\nfrom redis.asyncio import Redis\nfrom .event_bus import EventBus\nfrom .event_router import EventRouter\nfrom .event_logger import EventLogger\nfrom .request_response import RequestResponseManager\nfrom database.session import async_session_maker\n\nclass EventSystem:\n    def __init__(self, redis_client: Redis):\n        self.logger = logging.getLogger(\"event_system\")\n        self.event_bus = EventBus(redis_client)\n        self.event_router = EventRouter(self.event_bus)\n        self.event_logger = EventLogger(self.event_bus, async_session_maker)\n        self.request_response = RequestResponseManager(self.event_bus)\n        \n    async def start(self):\n        \"\"\"이벤트 시스템 시작\"\"\"\n        await self.event_bus.start()\n        await self.event_router.start()\n        await self.event_logger.start()\n        await self.request_response.start()\n        self.logger.info(\"Event system started\")\n        \n    async def stop(self):\n        \"\"\"이벤트 시스템 중지\"\"\"\n        await self.event_logger.stop()\n        await self.event_bus.stop()\n        self.logger.info(\"Event system stopped\")\n        \n    # 편의 메서드들\n    async def publish(self, event_type: str, data: any, retain: bool = False):\n        \"\"\"이벤트 발행\"\"\"\n        await self.event_bus.publish(event_type, data, retain)\n        \n    async def subscribe(self, event_type: str, callback):\n        \"\"\"이벤트 구독\"\"\"\n        await self.event_bus.subscribe(event_type, callback)\n        \n    async def add_route(self, event_type: str, handler):\n        \"\"\"이벤트 라우팅 추가\"\"\"\n        await self.event_router.add_route(event_type, handler)\n        \n    async def add_pattern_route(self, pattern: str, handler):\n        \"\"\"패턴 기반 이벤트 라우팅 추가\"\"\"\n        await self.event_router.add_pattern_route(pattern, handler)\n        \n    async def register_request_handler(self, request_type: str, handler):\n        \"\"\"요청 핸들러 등록\"\"\"\n        await self.request_response.register_handler(request_type, handler)\n        \n    async def send_request(self, request_type: str, data: any, timeout: float = 5.0):\n        \"\"\"요청 전송 및 응답 대기\"\"\"\n        return await self.request_response.send_request(request_type, data, timeout)\n```\n\n7. 데이터베이스 이벤트 로그 모델 (database/models.py에 추가):\n```python\nfrom sqlalchemy import Column, Integer, String, DateTime, Text\nfrom sqlalchemy.sql import func\nfrom .base import Base\n\nclass EventLog(Base):\n    __tablename__ = \"event_logs\"\n    \n    id = Column(Integer, primary_key=True)\n    event_type = Column(String(100), index=True, nullable=False)\n    data = Column(Text, nullable=False)  # JSON 문자열\n    timestamp = Column(DateTime(timezone=True), server_default=func.now(), index=True)\n    metadata = Column(Text, nullable=False)  # JSON 문자열\n```\n\n8. 이벤트 버스 사용 예시:\n```python\nimport asyncio\nfrom redis.asyncio import Redis\nfrom utils.event_system import EventSystem\nfrom utils.event_types import *\n\nasync def main():\n    # Redis 클라이언트 생성\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    \n    # 이벤트 시스템 초기화\n    event_system = EventSystem(redis)\n    await event_system.start()\n    \n    # 이벤트 핸들러 등록\n    async def handle_market_data(event_data):\n        print(f\"Market data received: {event_data}\")\n        \n    async def handle_trading_signals(event_data):\n        print(f\"Trading signal received: {event_data}\")\n        \n    # 이벤트 구독\n    await event_system.subscribe(MARKET_DATA_RECEIVED, handle_market_data)\n    await event_system.subscribe(TRADING_SIGNAL, handle_trading_signals)\n    \n    # 이벤트 발행\n    await event_system.publish(MARKET_DATA_RECEIVED, {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.25,\n        \"timestamp\": \"2023-10-25T12:34:56Z\"\n    })\n    \n    # 요청/응답 패턴 사용\n    async def handle_price_request(request_data):\n        symbol = request_data.get(\"symbol\")\n        # 실제로는 데이터베이스나 다른 소스에서 가격 조회\n        return {\"symbol\": symbol, \"price\": 150.25}\n    \n    # 요청 핸들러 등록\n    await event_system.register_request_handler(\"get_price\", handle_price_request)\n    \n    # 요청 전송 및 응답 대기\n    response = await event_system.send_request(\"get_price\", {\"symbol\": \"AAPL\"})\n    print(f\"Price response: {response}\")\n    \n    # 정리\n    await event_system.stop()\n    await redis.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n9. 구현 시 고려사항:\n   - Redis 연결 풀 관리: 다수의 이벤트 발행/구독 시 연결 관리 중요\n   - 메시지 직렬화/역직렬화: JSON 사용, 필요시 MessagePack 등 고려\n   - 오류 처리 및 재시도: 네트워크 오류, Redis 연결 문제 등 처리\n   - 이벤트 로깅: 디버깅 및 감사를 위한 이벤트 기록\n   - 성능 최적화: 대량 이벤트 처리 시 버퍼링 및 배치 처리\n   - 메모리 관리: 이벤트 기록 보존 시 메모리 사용량 제한\n   - 보안: 민감한 데이터 처리 시 암호화 고려",
        "testStrategy": "1. 기본 기능 테스트:\n   - EventBus 초기화 및 시작/중지 테스트\n   - 이벤트 발행/구독 기본 기능 테스트\n   - 이벤트 라우팅 테스트\n   - 요청/응답 패턴 테스트\n   - 이벤트 로깅 테스트\n\n2. 이벤트 발행/구독 테스트:\n```python\nimport pytest\nimport asyncio\nfrom redis.asyncio import Redis\nfrom utils.event_bus import EventBus\n\n@pytest.mark.asyncio\nasync def test_event_publish_subscribe():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    received_events = []\n    \n    async def event_handler(event_data):\n        received_events.append(event_data)\n        \n    # 이벤트 구독\n    await event_bus.subscribe(\"test_event\", event_handler)\n    \n    # 이벤트 발행\n    test_data = {\"message\": \"Hello, World!\"}\n    await event_bus.publish(\"test_event\", test_data)\n    \n    # 이벤트 수신 대기\n    await asyncio.sleep(0.1)\n    \n    # 검증\n    assert len(received_events) == 1\n    assert received_events[0][\"data\"] == test_data\n    \n    # 정리\n    await event_bus.stop()\n    await redis.close()\n```\n\n3. 이벤트 라우팅 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_event_routing():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    event_router = EventRouter(event_bus)\n    await event_bus.start()\n    await event_router.start()\n    \n    route_called = False\n    pattern_route_called = False\n    \n    async def route_handler(event_data):\n        nonlocal route_called\n        route_called = True\n        \n    async def pattern_handler(event_data):\n        nonlocal pattern_route_called\n        pattern_route_called = True\n        \n    # 라우트 등록\n    await event_router.add_route(\"specific_event\", route_handler)\n    await event_router.add_pattern_route(\"pattern_.*\", pattern_handler)\n    \n    # 이벤트 발행\n    await event_bus.publish(\"specific_event\", {\"test\": \"data\"})\n    await event_bus.publish(\"pattern_test\", {\"test\": \"data\"})\n    \n    # 이벤트 처리 대기\n    await asyncio.sleep(0.1)\n    \n    # 검증\n    assert route_called\n    assert pattern_route_called\n    \n    # 정리\n    await event_bus.stop()\n    await redis.close()\n```\n\n4. 요청/응답 패턴 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_request_response():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    req_res_manager = RequestResponseManager(event_bus)\n    await event_bus.start()\n    await req_res_manager.start()\n    \n    # 요청 핸들러 등록\n    async def price_handler(request_data):\n        symbol = request_data.get(\"symbol\")\n        return {\"symbol\": symbol, \"price\": 150.25}\n        \n    await req_res_manager.register_handler(\"get_price\", price_handler)\n    \n    # 요청 전송\n    response = await req_res_manager.send_request(\"get_price\", {\"symbol\": \"AAPL\"})\n    \n    # 검증\n    assert response[\"symbol\"] == \"AAPL\"\n    assert response[\"price\"] == 150.25\n    \n    # 타임아웃 테스트\n    with pytest.raises(TimeoutError):\n        await req_res_manager.send_request(\"non_existent\", {}, timeout=0.1)\n        \n    # 정리\n    await event_bus.stop()\n    await redis.close()\n```\n\n5. 이벤트 로깅 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_event_logging():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    event_logger = EventLogger(event_bus, async_session_maker)\n    await event_bus.start()\n    await event_logger.start()\n    \n    # 로깅할 이벤트 타입 추가\n    event_logger.add_event_type(\"test_event\")\n    \n    # 이벤트 발행\n    await event_bus.publish(\"test_event\", {\"message\": \"Test message\"})\n    \n    # 로그 플러시 대기\n    await asyncio.sleep(0.1)\n    await event_logger._flush_buffer()\n    \n    # 로그 조회\n    logs = await event_logger.get_recent_events(\"test_event\", limit=1)\n    \n    # 검증\n    assert len(logs) == 1\n    assert logs[0][\"event_type\"] == \"test_event\"\n    assert logs[0][\"data\"][\"message\"] == \"Test message\"\n    \n    # 정리\n    await event_logger.stop()\n    await event_bus.stop()\n    await redis.close()\n```\n\n6. 통합 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_event_system_integration():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_system = EventSystem(redis)\n    await event_system.start()\n    \n    # 테스트 데이터\n    test_events = []\n    \n    # 이벤트 핸들러\n    async def market_data_handler(event_data):\n        test_events.append((\"market\", event_data))\n        \n    async def trading_handler(event_data):\n        test_events.append((\"trading\", event_data))\n        \n    # 요청 핸들러\n    async def data_request_handler(request_data):\n        return {\"result\": f\"Processed {request_data}\"}\n        \n    # 핸들러 등록\n    await event_system.subscribe(MARKET_DATA_RECEIVED, market_data_handler)\n    await event_system.subscribe(TRADING_SIGNAL, trading_handler)\n    await event_system.register_request_handler(\"data_request\", data_request_handler)\n    \n    # 이벤트 발행\n    market_data = {\"symbol\": \"AAPL\", \"price\": 150.25}\n    trading_data = {\"symbol\": \"AAPL\", \"action\": \"BUY\", \"quantity\": 10}\n    \n    await event_system.publish(MARKET_DATA_RECEIVED, market_data)\n    await event_system.publish(TRADING_SIGNAL, trading_data)\n    \n    # 요청 전송\n    response = await event_system.send_request(\"data_request\", {\"query\": \"test\"})\n    \n    # 이벤트 처리 대기\n    await asyncio.sleep(0.1)\n    \n    # 검증\n    assert len(test_events) == 2\n    assert test_events[0][0] == \"market\"\n    assert test_events[0][1][\"data\"] == market_data\n    assert test_events[1][0] == \"trading\"\n    assert test_events[1][1][\"data\"] == trading_data\n    assert \"result\" in response\n    \n    # 정리\n    await event_system.stop()\n    await redis.close()\n```\n\n7. 성능 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_event_bus_performance():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    # 카운터\n    received_count = 0\n    \n    async def event_handler(event_data):\n        nonlocal received_count\n        received_count += 1\n        \n    # 이벤트 구독\n    await event_bus.subscribe(\"perf_test\", event_handler)\n    \n    # 대량 이벤트 발행 (1000개)\n    start_time = asyncio.get_event_loop().time()\n    for i in range(1000):\n        await event_bus.publish(\"perf_test\", {\"index\": i})\n        \n    # 모든 이벤트 처리 대기\n    while received_count < 1000:\n        await asyncio.sleep(0.01)\n        \n    end_time = asyncio.get_event_loop().time()\n    duration = end_time - start_time\n    \n    # 검증 (초당 최소 500개 이상 처리)\n    events_per_second = 1000 / duration\n    assert events_per_second >= 500, f\"Performance too low: {events_per_second:.2f} events/sec\"\n    \n    print(f\"Performance: {events_per_second:.2f} events/sec\")\n    \n    # 정리\n    await event_bus.stop()\n    await redis.close()\n```\n\n8. 오류 복구 테스트:\n```python\n@pytest.mark.asyncio\nasync def test_error_recovery():\n    redis = Redis(host=\"localhost\", port=6379, db=0)\n    event_bus = EventBus(redis)\n    await event_bus.start()\n    \n    error_count = 0\n    success_count = 0\n    \n    async def failing_handler(event_data):\n        nonlocal error_count, success_count\n        if event_data[\"data\"][\"index\"] % 2 == 0:\n            error_count += 1\n            raise Exception(\"Simulated error\")\n        else:\n            success_count += 1\n            \n    # 이벤트 구독\n    await event_bus.subscribe(\"error_test\", failing_handler)\n    \n    # 이벤트 발행 (100개)\n    for i in range(100):\n        await event_bus.publish(\"error_test\", {\"index\": i})\n        \n    # 이벤트 처리 대기\n    await asyncio.sleep(0.5)\n    \n    # 검증 (오류가 있어도 계속 처리)\n    assert error_count == 50  # 짝수 인덱스에서 오류\n    assert success_count == 50  # 홀수 인덱스는 성공\n    \n    # 정리\n    await event_bus.stop()\n    await redis.close()\n```\n\n9. 시스템 통합 테스트:\n   - 실제 시스템 컴포넌트들과 통합하여 이벤트 버스 작동 확인\n   - 시장 데이터 수신 → 신호 생성 → 주문 실행 흐름 테스트\n   - 오류 발생 시 이벤트 기록 및 알림 확인\n   - 시스템 시작/중지 시 이벤트 발행 확인\n\n10. 부하 테스트:\n    - 초당 1000개 이상의 이벤트 처리 성능 확인\n    - 메모리 사용량 모니터링 (Redis 메모리 사용량 < 100MB)\n    - 장시간 실행 시 안정성 테스트 (24시간 연속 운영)",
        "status": "pending",
        "dependencies": [
          21,
          19,
          36
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-25T04:33:23.955Z",
      "updated": "2025-07-27T00:41:59.323Z",
      "description": "Tasks for master context"
    }
  }
}